{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T22:10:37.946552Z",
     "start_time": "2024-11-14T22:10:37.838766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from car_racing import CarRacing\n",
    "!python --version"
   ],
   "id": "b9c2b69cdf29ac07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T22:13:29.806256Z",
     "start_time": "2024-11-14T22:13:26.367150Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117",
   "id": "8f28ba19399ead69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:07:20.321247Z",
     "start_time": "2024-11-18T22:07:19.105268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import gnwrapper\n",
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "\n",
    "gymlogger.set_level(30)\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import base64\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import time\n",
    "import torch\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "from merger import MultiCarRacing\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "343c306719deb09a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:07:20.336953Z",
     "start_time": "2024-11-18T22:07:20.326240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gym.register(\n",
    "    id='MultiCarRacing-v0',\n",
    "    entry_point='merger:MultiCarRacing',\n",
    "    max_episode_steps=1000,\n",
    "    reward_threshold=900\n",
    ")\n",
    "\n",
    "gym.register(\n",
    "    id='CarRacingDiscrete-v0',\n",
    "    entry_point='merger:CarRacingDiscrete',\n",
    "    max_episode_steps=1000,\n",
    "    reward_threshold=900\n",
    ")\n"
   ],
   "id": "b6c671275f1309a6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:07:20.462438Z",
     "start_time": "2024-11-18T22:07:20.447432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = gym.make('MultiCarRacing-v0', num_agents=1)\n",
    "env_2 = gym.make('CarRacingDiscrete-v0')\n",
    "print(\"Observation Space Size: \", env_2.observation_space)\n",
    "print(\"Action Space Size: \", env_2.action_space)\n",
    "print(\"Observation Space Size: \", env.observation_space)\n",
    "print(\"Action Space Size: \", env.action_space)\n",
    "env.close()"
   ],
   "id": "8cce796d6ab3c029",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space Size:  Box(96, 96, 3)\n",
      "Action Space Size:  Discrete(5)\n",
      "Observation Space Size:  Box(96, 96, 3)\n",
      "Action Space Size:  Discrete(5)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:07:21.080044Z",
     "start_time": "2024-11-18T22:07:20.812540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import time\n",
    "import numpy as np  # Ensure numpy is imported\n",
    "\n",
    "\n",
    "class ProgressCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    A custom callback that displays training progress, tracks the best mean reward,\n",
    "    and automatically saves the model every 10 log intervals.\n",
    "\n",
    "    Args:\n",
    "        total_timesteps (int): The total number of timesteps in the training run.\n",
    "        log_interval (int): The interval (in timesteps) at which to log progress.\n",
    "        save_path (str): The path to save the model (this file will be overwritten each time).\n",
    "        verbose (int): Verbosity level (0: no output, 1: default output).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, total_timesteps, log_interval=1000, save_path=\"model\", verbose=1):\n",
    "        super(ProgressCallback, self).__init__(verbose)\n",
    "        self.start_time = time.time()\n",
    "        self.total_timesteps = total_timesteps\n",
    "        self.current_timesteps = 0\n",
    "        self.episode_rewards = []\n",
    "        self.log_interval = log_interval\n",
    "        self.best_mean_reward = -np.inf\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        self.current_timesteps += 1\n",
    "\n",
    "        try:  # Try to access the reward; if it fails, it's likely the last step of training.\n",
    "            reward = self.locals[\"rewards\"][0]\n",
    "            self.episode_rewards.append(reward)\n",
    "        except Exception as e:\n",
    "            if self.verbose > 0:\n",
    "                print(e)\n",
    "            pass  # Ignore the exception if reward isn't available (likely end of training).\n",
    "\n",
    "        if self.n_calls % self.log_interval == 0:\n",
    "            elapsed_time = time.time() - self.start_time\n",
    "            remaining_timesteps = self.total_timesteps - self.current_timesteps\n",
    "\n",
    "            if self.current_timesteps > 0:\n",
    "                remaining_time = elapsed_time * (remaining_timesteps / self.current_timesteps)\n",
    "            else:\n",
    "                remaining_time = 0\n",
    "\n",
    "            remaining_time_hours = int(remaining_time // 3600)\n",
    "            remaining_time_minutes = int((remaining_time % 3600) // 60)\n",
    "            remaining_time_seconds = int(remaining_time % 60)\n",
    "\n",
    "            elapsed_time_hours = int(elapsed_time // 3600)\n",
    "            elapsed_time_minutes = int((elapsed_time % 3600) // 60)\n",
    "            elapsed_time_seconds = int(elapsed_time % 60)\n",
    "\n",
    "            mean_reward = np.mean(self.episode_rewards) if self.episode_rewards else None\n",
    "            self.episode_rewards = []\n",
    "\n",
    "            print(f\"Timesteps: {self.current_timesteps}/{self.total_timesteps}, \"\n",
    "                  f\"Remaining Timesteps: {remaining_timesteps}, \"\n",
    "                  f\"Elapsed Time: {elapsed_time_hours:02}:{elapsed_time_minutes:02}:{elapsed_time_seconds:02}, \"\n",
    "                  f\"Estimated Time Remaining: {remaining_time_hours:02}:{remaining_time_minutes:02}:{remaining_time_seconds:02}\")\n",
    "\n",
    "            if mean_reward is not None:\n",
    "                print(f\"Mean Reward (last {self.log_interval} steps): {mean_reward:.5f}\")\n",
    "\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    print(f\"New best mean reward: {self.best_mean_reward:.5f}\")\n",
    "\n",
    "            # Save the model every 10 log intervals (log_interval * 10)\n",
    "            if self.n_calls % (self.log_interval * 10) == 0:\n",
    "                if self.model is not None:\n",
    "                    self.model.save(self.save_path)\n",
    "                    print(f\"Model saved to {self.save_path} (overwritten)\")\n",
    "\n",
    "        return True\n"
   ],
   "id": "bbbe22b54ad3dfe8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:07:41.209719Z",
     "start_time": "2024-11-18T22:07:41.199279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MonitorCustom(gym.wrappers.Monitor):\n",
    "    def __init__(self, env):\n",
    "        super(MonitorCustom, self).__init__(env, './video', force=True)"
   ],
   "id": "a4b9efa033570584",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:23:11.912954Z",
     "start_time": "2024-11-17T16:09:00.109877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.dqn import CnnPolicy\n",
    "from merger import CarRacingDiscrete, MultiCarRacing\n",
    "import gym\n",
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "VERSION = \"2M\"\n",
    "NUM_OF_STEPS = 2_000_000\n",
    "LOG_INTERVAL = 1000\n",
    "# BUFFER_SIZE = 150000\n",
    "LEARNING_STARTS = 5000\n",
    "MODEL_SAVE_NAME = \"PPO_RL_\" + str(VERSION)\n",
    "SAVED_MODEL_VERSION = \"latest\"\n",
    "LOAD_SAVED_MODEL = False\n",
    "\n",
    "env = gym.make(\"MultiCarRacing-v0\",\n",
    "               num_agents=1, verbose=0, use_ego_color=True,\n",
    "               continuous_actions=[True])\n",
    "\n",
    "env = MonitorCustom(env)\n",
    "\n",
    "if LOAD_SAVED_MODEL:\n",
    "    try:\n",
    "\n",
    "        PPOmodel = PPO.load(MODEL_SAVE_NAME, env=env)\n",
    "        print(\"LOAD SAVED PPÎŸ MODEL\")\n",
    "\n",
    "    except:\n",
    "        print(\"NO MODEL FOUND\")\n",
    "else:\n",
    "    if 'PPOmodel' not in globals():\n",
    "        PPOmodel = PPO('CnnPolicy', env, verbose=1, ent_coef=0.005)\n",
    "        print(\"INITIALIZE NEW PPO MODEL\")\n",
    "    else:\n",
    "        PPOmodel = PPO.load(MODEL_SAVE_NAME, env=env)\n",
    "        print(\"CONTINUE PPO MODEL TRAINING\")\n",
    "\n",
    "progress_callback = ProgressCallback(total_timesteps=NUM_OF_STEPS, verbose=1, save_path=\"TRAIN_PPO_RL_\" + str(VERSION))\n",
    "\n",
    "PPOmodel.learn(total_timesteps=NUM_OF_STEPS, log_interval=LOG_INTERVAL, callback=progress_callback)\n",
    "PPOmodel.save(MODEL_SAVE_NAME)"
   ],
   "id": "dbecf2c4943733bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "INITIALIZE NEW PPO MODEL\n",
      "Timesteps: 1000/2000000, Remaining Timesteps: 1999000, Elapsed Time: 00:00:23, Estimated Time Remaining: 13:15:44\n",
      "Mean Reward (last 1000 steps): -0.06364\n",
      "New best mean reward: -0.06364\n",
      "Timesteps: 2000/2000000, Remaining Timesteps: 1998000, Elapsed Time: 00:00:46, Estimated Time Remaining: 12:56:26\n",
      "Mean Reward (last 1000 steps): -0.07020\n",
      "Timesteps: 3000/2000000, Remaining Timesteps: 1997000, Elapsed Time: 00:01:02, Estimated Time Remaining: 11:28:40\n",
      "Mean Reward (last 1000 steps): -0.05423\n",
      "New best mean reward: -0.05423\n",
      "Timesteps: 4000/2000000, Remaining Timesteps: 1996000, Elapsed Time: 00:01:12, Estimated Time Remaining: 10:04:57\n",
      "Mean Reward (last 1000 steps): -0.03774\n",
      "New best mean reward: -0.03774\n",
      "Timesteps: 5000/2000000, Remaining Timesteps: 1995000, Elapsed Time: 00:01:28, Estimated Time Remaining: 09:48:37\n",
      "Mean Reward (last 1000 steps): -0.05623\n",
      "Timesteps: 6000/2000000, Remaining Timesteps: 1994000, Elapsed Time: 00:01:40, Estimated Time Remaining: 09:15:57\n",
      "Mean Reward (last 1000 steps): -0.04526\n",
      "Timesteps: 7000/2000000, Remaining Timesteps: 1993000, Elapsed Time: 00:01:57, Estimated Time Remaining: 09:17:56\n",
      "Mean Reward (last 1000 steps): -0.05517\n",
      "Timesteps: 8000/2000000, Remaining Timesteps: 1992000, Elapsed Time: 00:02:09, Estimated Time Remaining: 08:55:48\n",
      "Mean Reward (last 1000 steps): -0.05053\n",
      "Timesteps: 9000/2000000, Remaining Timesteps: 1991000, Elapsed Time: 00:02:39, Estimated Time Remaining: 09:49:10\n",
      "Mean Reward (last 1000 steps): -0.05509\n",
      "Timesteps: 10000/2000000, Remaining Timesteps: 1990000, Elapsed Time: 00:02:51, Estimated Time Remaining: 09:30:03\n",
      "Mean Reward (last 1000 steps): -0.04502\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 11000/2000000, Remaining Timesteps: 1989000, Elapsed Time: 00:03:07, Estimated Time Remaining: 09:25:35\n",
      "Mean Reward (last 1000 steps): -0.03455\n",
      "New best mean reward: -0.03455\n",
      "Timesteps: 12000/2000000, Remaining Timesteps: 1988000, Elapsed Time: 00:03:18, Estimated Time Remaining: 09:08:20\n",
      "Mean Reward (last 1000 steps): -0.03898\n",
      "Timesteps: 13000/2000000, Remaining Timesteps: 1987000, Elapsed Time: 00:03:34, Estimated Time Remaining: 09:06:09\n",
      "Mean Reward (last 1000 steps): -0.05203\n",
      "Timesteps: 14000/2000000, Remaining Timesteps: 1986000, Elapsed Time: 00:03:46, Estimated Time Remaining: 08:54:29\n",
      "Mean Reward (last 1000 steps): -0.05082\n",
      "Timesteps: 15000/2000000, Remaining Timesteps: 1985000, Elapsed Time: 00:04:00, Estimated Time Remaining: 08:50:58\n",
      "Mean Reward (last 1000 steps): -0.04985\n",
      "Timesteps: 16000/2000000, Remaining Timesteps: 1984000, Elapsed Time: 00:04:11, Estimated Time Remaining: 08:39:19\n",
      "Mean Reward (last 1000 steps): -0.04702\n",
      "Timesteps: 17000/2000000, Remaining Timesteps: 1983000, Elapsed Time: 00:04:27, Estimated Time Remaining: 08:39:46\n",
      "Mean Reward (last 1000 steps): -0.04138\n",
      "Timesteps: 18000/2000000, Remaining Timesteps: 1982000, Elapsed Time: 00:04:37, Estimated Time Remaining: 08:29:31\n",
      "Mean Reward (last 1000 steps): -0.03962\n",
      "Timesteps: 19000/2000000, Remaining Timesteps: 1981000, Elapsed Time: 00:04:52, Estimated Time Remaining: 08:27:29\n",
      "Mean Reward (last 1000 steps): -0.05738\n",
      "Timesteps: 20000/2000000, Remaining Timesteps: 1980000, Elapsed Time: 00:05:02, Estimated Time Remaining: 08:18:40\n",
      "Mean Reward (last 1000 steps): -0.05817\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 21000/2000000, Remaining Timesteps: 1979000, Elapsed Time: 00:05:15, Estimated Time Remaining: 08:15:17\n",
      "Mean Reward (last 1000 steps): -0.01566\n",
      "New best mean reward: -0.01566\n",
      "Timesteps: 22000/2000000, Remaining Timesteps: 1978000, Elapsed Time: 00:05:26, Estimated Time Remaining: 08:09:17\n",
      "Mean Reward (last 1000 steps): -0.06979\n",
      "Timesteps: 23000/2000000, Remaining Timesteps: 1977000, Elapsed Time: 00:05:40, Estimated Time Remaining: 08:08:07\n",
      "Mean Reward (last 1000 steps): -0.05070\n",
      "Timesteps: 24000/2000000, Remaining Timesteps: 1976000, Elapsed Time: 00:05:51, Estimated Time Remaining: 08:01:44\n",
      "Mean Reward (last 1000 steps): -0.04565\n",
      "Timesteps: 25000/2000000, Remaining Timesteps: 1975000, Elapsed Time: 00:06:05, Estimated Time Remaining: 08:01:18\n",
      "Mean Reward (last 1000 steps): -0.05468\n",
      "Timesteps: 26000/2000000, Remaining Timesteps: 1974000, Elapsed Time: 00:06:15, Estimated Time Remaining: 07:55:35\n",
      "Mean Reward (last 1000 steps): -0.05789\n",
      "Timesteps: 27000/2000000, Remaining Timesteps: 1973000, Elapsed Time: 00:06:30, Estimated Time Remaining: 07:55:20\n",
      "Mean Reward (last 1000 steps): -0.05963\n",
      "Timesteps: 28000/2000000, Remaining Timesteps: 1972000, Elapsed Time: 00:06:52, Estimated Time Remaining: 08:03:51\n",
      "Mean Reward (last 1000 steps): -0.08099\n",
      "Timesteps: 29000/2000000, Remaining Timesteps: 1971000, Elapsed Time: 00:07:09, Estimated Time Remaining: 08:06:00\n",
      "Mean Reward (last 1000 steps): -0.02378\n",
      "Timesteps: 30000/2000000, Remaining Timesteps: 1970000, Elapsed Time: 00:07:19, Estimated Time Remaining: 08:00:56\n",
      "Mean Reward (last 1000 steps): -0.05455\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 31000/2000000, Remaining Timesteps: 1969000, Elapsed Time: 00:07:33, Estimated Time Remaining: 08:00:24\n",
      "Mean Reward (last 1000 steps): -0.02434\n",
      "Timesteps: 32000/2000000, Remaining Timesteps: 1968000, Elapsed Time: 00:07:45, Estimated Time Remaining: 07:56:44\n",
      "Mean Reward (last 1000 steps): -0.04982\n",
      "Timesteps: 33000/2000000, Remaining Timesteps: 1967000, Elapsed Time: 00:08:00, Estimated Time Remaining: 07:57:30\n",
      "Mean Reward (last 1000 steps): -0.02484\n",
      "Timesteps: 34000/2000000, Remaining Timesteps: 1966000, Elapsed Time: 00:08:11, Estimated Time Remaining: 07:53:54\n",
      "Mean Reward (last 1000 steps): -0.02674\n",
      "Timesteps: 35000/2000000, Remaining Timesteps: 1965000, Elapsed Time: 00:08:25, Estimated Time Remaining: 07:53:19\n",
      "Mean Reward (last 1000 steps): -0.04444\n",
      "Timesteps: 36000/2000000, Remaining Timesteps: 1964000, Elapsed Time: 00:08:36, Estimated Time Remaining: 07:49:26\n",
      "Mean Reward (last 1000 steps): -0.05205\n",
      "Timesteps: 37000/2000000, Remaining Timesteps: 1963000, Elapsed Time: 00:08:50, Estimated Time Remaining: 07:49:04\n",
      "Mean Reward (last 1000 steps): -0.04030\n",
      "Timesteps: 38000/2000000, Remaining Timesteps: 1962000, Elapsed Time: 00:09:00, Estimated Time Remaining: 07:45:32\n",
      "Mean Reward (last 1000 steps): -0.01729\n",
      "Timesteps: 39000/2000000, Remaining Timesteps: 1961000, Elapsed Time: 00:09:15, Estimated Time Remaining: 07:45:20\n",
      "Mean Reward (last 1000 steps): -0.01882\n",
      "Timesteps: 40000/2000000, Remaining Timesteps: 1960000, Elapsed Time: 00:09:25, Estimated Time Remaining: 07:42:09\n",
      "Mean Reward (last 1000 steps): -0.05539\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 41000/2000000, Remaining Timesteps: 1959000, Elapsed Time: 00:09:40, Estimated Time Remaining: 07:41:55\n",
      "Mean Reward (last 1000 steps): -0.03262\n",
      "Timesteps: 42000/2000000, Remaining Timesteps: 1958000, Elapsed Time: 00:09:50, Estimated Time Remaining: 07:39:09\n",
      "Mean Reward (last 1000 steps): -0.05484\n",
      "Timesteps: 43000/2000000, Remaining Timesteps: 1957000, Elapsed Time: 00:10:01, Estimated Time Remaining: 07:36:25\n",
      "Mean Reward (last 1000 steps): -0.04539\n",
      "Timesteps: 44000/2000000, Remaining Timesteps: 1956000, Elapsed Time: 00:10:16, Estimated Time Remaining: 07:37:07\n",
      "Mean Reward (last 1000 steps): -0.04490\n",
      "Timesteps: 45000/2000000, Remaining Timesteps: 1955000, Elapsed Time: 00:10:27, Estimated Time Remaining: 07:34:02\n",
      "Mean Reward (last 1000 steps): -0.04306\n",
      "Timesteps: 46000/2000000, Remaining Timesteps: 1954000, Elapsed Time: 00:10:40, Estimated Time Remaining: 07:33:48\n",
      "Mean Reward (last 1000 steps): -0.01809\n",
      "Timesteps: 47000/2000000, Remaining Timesteps: 1953000, Elapsed Time: 00:10:51, Estimated Time Remaining: 07:30:54\n",
      "Mean Reward (last 1000 steps): -0.04604\n",
      "Timesteps: 48000/2000000, Remaining Timesteps: 1952000, Elapsed Time: 00:11:05, Estimated Time Remaining: 07:31:01\n",
      "Mean Reward (last 1000 steps): -0.06333\n",
      "Timesteps: 49000/2000000, Remaining Timesteps: 1951000, Elapsed Time: 00:11:15, Estimated Time Remaining: 07:28:27\n",
      "Mean Reward (last 1000 steps): -0.03980\n",
      "Timesteps: 50000/2000000, Remaining Timesteps: 1950000, Elapsed Time: 00:11:29, Estimated Time Remaining: 07:28:24\n",
      "Mean Reward (last 1000 steps): -0.04014\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 51000/2000000, Remaining Timesteps: 1949000, Elapsed Time: 00:11:40, Estimated Time Remaining: 07:25:57\n",
      "Mean Reward (last 1000 steps): -0.03772\n",
      "Timesteps: 52000/2000000, Remaining Timesteps: 1948000, Elapsed Time: 00:11:55, Estimated Time Remaining: 07:26:26\n",
      "Mean Reward (last 1000 steps): -0.04333\n",
      "Timesteps: 53000/2000000, Remaining Timesteps: 1947000, Elapsed Time: 00:12:05, Estimated Time Remaining: 07:24:09\n",
      "Mean Reward (last 1000 steps): -0.04268\n",
      "Timesteps: 54000/2000000, Remaining Timesteps: 1946000, Elapsed Time: 00:12:20, Estimated Time Remaining: 07:24:50\n",
      "Mean Reward (last 1000 steps): -0.01724\n",
      "Timesteps: 55000/2000000, Remaining Timesteps: 1945000, Elapsed Time: 00:12:32, Estimated Time Remaining: 07:23:15\n",
      "Mean Reward (last 1000 steps): -0.02150\n",
      "Timesteps: 56000/2000000, Remaining Timesteps: 1944000, Elapsed Time: 00:12:47, Estimated Time Remaining: 07:24:09\n",
      "Mean Reward (last 1000 steps): -0.02138\n",
      "Timesteps: 57000/2000000, Remaining Timesteps: 1943000, Elapsed Time: 00:12:58, Estimated Time Remaining: 07:22:02\n",
      "Mean Reward (last 1000 steps): -0.03333\n",
      "Timesteps: 58000/2000000, Remaining Timesteps: 1942000, Elapsed Time: 00:13:12, Estimated Time Remaining: 07:22:29\n",
      "Mean Reward (last 1000 steps): -0.04737\n",
      "Timesteps: 59000/2000000, Remaining Timesteps: 1941000, Elapsed Time: 00:13:23, Estimated Time Remaining: 07:20:25\n",
      "Mean Reward (last 1000 steps): -0.01986\n",
      "Timesteps: 60000/2000000, Remaining Timesteps: 1940000, Elapsed Time: 00:13:38, Estimated Time Remaining: 07:21:05\n",
      "Mean Reward (last 1000 steps): -0.03857\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 61000/2000000, Remaining Timesteps: 1939000, Elapsed Time: 00:13:49, Estimated Time Remaining: 07:19:20\n",
      "Mean Reward (last 1000 steps): -0.04654\n",
      "Timesteps: 62000/2000000, Remaining Timesteps: 1938000, Elapsed Time: 00:14:04, Estimated Time Remaining: 07:19:57\n",
      "Mean Reward (last 1000 steps): -0.02258\n",
      "Timesteps: 63000/2000000, Remaining Timesteps: 1937000, Elapsed Time: 00:14:14, Estimated Time Remaining: 07:18:05\n",
      "Mean Reward (last 1000 steps): -0.01259\n",
      "New best mean reward: -0.01259\n",
      "Timesteps: 64000/2000000, Remaining Timesteps: 1936000, Elapsed Time: 00:14:30, Estimated Time Remaining: 07:18:45\n",
      "Mean Reward (last 1000 steps): -0.05686\n",
      "Timesteps: 65000/2000000, Remaining Timesteps: 1935000, Elapsed Time: 00:14:52, Estimated Time Remaining: 07:22:37\n",
      "Mean Reward (last 1000 steps): -0.00210\n",
      "New best mean reward: -0.00210\n",
      "Timesteps: 66000/2000000, Remaining Timesteps: 1934000, Elapsed Time: 00:15:08, Estimated Time Remaining: 07:23:54\n",
      "Mean Reward (last 1000 steps): -0.03134\n",
      "Timesteps: 67000/2000000, Remaining Timesteps: 1933000, Elapsed Time: 00:15:19, Estimated Time Remaining: 07:22:20\n",
      "Mean Reward (last 1000 steps): -0.06040\n",
      "Timesteps: 68000/2000000, Remaining Timesteps: 1932000, Elapsed Time: 00:15:34, Estimated Time Remaining: 07:22:44\n",
      "Mean Reward (last 1000 steps): -0.03980\n",
      "Timesteps: 69000/2000000, Remaining Timesteps: 1931000, Elapsed Time: 00:15:45, Estimated Time Remaining: 07:20:52\n",
      "Mean Reward (last 1000 steps): -0.04352\n",
      "Timesteps: 70000/2000000, Remaining Timesteps: 1930000, Elapsed Time: 00:16:00, Estimated Time Remaining: 07:21:16\n",
      "Mean Reward (last 1000 steps): -0.02901\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 71000/2000000, Remaining Timesteps: 1929000, Elapsed Time: 00:16:10, Estimated Time Remaining: 07:19:29\n",
      "Mean Reward (last 1000 steps): -0.02657\n",
      "Timesteps: 72000/2000000, Remaining Timesteps: 1928000, Elapsed Time: 00:16:25, Estimated Time Remaining: 07:19:46\n",
      "Mean Reward (last 1000 steps): -0.04137\n",
      "Timesteps: 73000/2000000, Remaining Timesteps: 1927000, Elapsed Time: 00:16:35, Estimated Time Remaining: 07:17:57\n",
      "Mean Reward (last 1000 steps): -0.02391\n",
      "Timesteps: 74000/2000000, Remaining Timesteps: 1926000, Elapsed Time: 00:16:50, Estimated Time Remaining: 07:18:23\n",
      "Mean Reward (last 1000 steps): -0.03814\n",
      "Timesteps: 75000/2000000, Remaining Timesteps: 1925000, Elapsed Time: 00:17:02, Estimated Time Remaining: 07:17:11\n",
      "Mean Reward (last 1000 steps): -0.02459\n",
      "Timesteps: 76000/2000000, Remaining Timesteps: 1924000, Elapsed Time: 00:17:17, Estimated Time Remaining: 07:17:39\n",
      "Mean Reward (last 1000 steps): -0.03031\n",
      "Timesteps: 77000/2000000, Remaining Timesteps: 1923000, Elapsed Time: 00:17:27, Estimated Time Remaining: 07:16:06\n",
      "Mean Reward (last 1000 steps): -0.01756\n",
      "Timesteps: 78000/2000000, Remaining Timesteps: 1922000, Elapsed Time: 00:17:43, Estimated Time Remaining: 07:16:40\n",
      "Mean Reward (last 1000 steps): -0.03891\n",
      "Timesteps: 79000/2000000, Remaining Timesteps: 1921000, Elapsed Time: 00:17:53, Estimated Time Remaining: 07:15:11\n",
      "Mean Reward (last 1000 steps): -0.02759\n",
      "Timesteps: 80000/2000000, Remaining Timesteps: 1920000, Elapsed Time: 00:18:08, Estimated Time Remaining: 07:15:31\n",
      "Mean Reward (last 1000 steps): -0.03680\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 81000/2000000, Remaining Timesteps: 1919000, Elapsed Time: 00:18:19, Estimated Time Remaining: 07:14:05\n",
      "Mean Reward (last 1000 steps): -0.03471\n",
      "Timesteps: 82000/2000000, Remaining Timesteps: 1918000, Elapsed Time: 00:18:35, Estimated Time Remaining: 07:14:44\n",
      "Mean Reward (last 1000 steps): -0.04231\n",
      "Timesteps: 83000/2000000, Remaining Timesteps: 1917000, Elapsed Time: 00:18:45, Estimated Time Remaining: 07:13:18\n",
      "Mean Reward (last 1000 steps): -0.03836\n",
      "Timesteps: 84000/2000000, Remaining Timesteps: 1916000, Elapsed Time: 00:18:59, Estimated Time Remaining: 07:13:22\n",
      "Mean Reward (last 1000 steps): -0.02857\n",
      "Timesteps: 85000/2000000, Remaining Timesteps: 1915000, Elapsed Time: 00:19:09, Estimated Time Remaining: 07:11:44\n",
      "Mean Reward (last 1000 steps): 0.02810\n",
      "New best mean reward: 0.02810\n",
      "Timesteps: 86000/2000000, Remaining Timesteps: 1914000, Elapsed Time: 00:19:20, Estimated Time Remaining: 07:10:32\n",
      "Mean Reward (last 1000 steps): -0.01935\n",
      "Timesteps: 87000/2000000, Remaining Timesteps: 1913000, Elapsed Time: 00:19:34, Estimated Time Remaining: 07:10:31\n",
      "Mean Reward (last 1000 steps): -0.01498\n",
      "Timesteps: 88000/2000000, Remaining Timesteps: 1912000, Elapsed Time: 00:19:44, Estimated Time Remaining: 07:09:00\n",
      "Mean Reward (last 1000 steps): -0.00385\n",
      "Timesteps: 89000/2000000, Remaining Timesteps: 1911000, Elapsed Time: 00:19:59, Estimated Time Remaining: 07:09:14\n",
      "Mean Reward (last 1000 steps): -0.03561\n",
      "Timesteps: 90000/2000000, Remaining Timesteps: 1910000, Elapsed Time: 00:20:09, Estimated Time Remaining: 07:07:54\n",
      "Mean Reward (last 1000 steps): -0.03382\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 91000/2000000, Remaining Timesteps: 1909000, Elapsed Time: 00:20:24, Estimated Time Remaining: 07:08:08\n",
      "Mean Reward (last 1000 steps): -0.01667\n",
      "Timesteps: 92000/2000000, Remaining Timesteps: 1908000, Elapsed Time: 00:20:34, Estimated Time Remaining: 07:06:50\n",
      "Mean Reward (last 1000 steps): -0.00706\n",
      "Timesteps: 93000/2000000, Remaining Timesteps: 1907000, Elapsed Time: 00:20:50, Estimated Time Remaining: 07:07:16\n",
      "Mean Reward (last 1000 steps): -0.04512\n",
      "Timesteps: 94000/2000000, Remaining Timesteps: 1906000, Elapsed Time: 00:21:00, Estimated Time Remaining: 07:05:58\n",
      "Mean Reward (last 1000 steps): -0.01034\n",
      "Timesteps: 95000/2000000, Remaining Timesteps: 1905000, Elapsed Time: 00:21:15, Estimated Time Remaining: 07:06:17\n",
      "Mean Reward (last 1000 steps): -0.01166\n",
      "Timesteps: 96000/2000000, Remaining Timesteps: 1904000, Elapsed Time: 00:21:26, Estimated Time Remaining: 07:05:17\n",
      "Mean Reward (last 1000 steps): 0.01268\n",
      "Timesteps: 97000/2000000, Remaining Timesteps: 1903000, Elapsed Time: 00:21:41, Estimated Time Remaining: 07:05:43\n",
      "Mean Reward (last 1000 steps): 0.19310\n",
      "New best mean reward: 0.19310\n",
      "Timesteps: 98000/2000000, Remaining Timesteps: 1902000, Elapsed Time: 00:21:52, Estimated Time Remaining: 07:04:38\n",
      "Mean Reward (last 1000 steps): -0.03645\n",
      "Timesteps: 99000/2000000, Remaining Timesteps: 1901000, Elapsed Time: 00:22:08, Estimated Time Remaining: 07:05:03\n",
      "Mean Reward (last 1000 steps): -0.02884\n",
      "Timesteps: 100000/2000000, Remaining Timesteps: 1900000, Elapsed Time: 00:22:19, Estimated Time Remaining: 07:04:11\n",
      "Mean Reward (last 1000 steps): -0.04462\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 101000/2000000, Remaining Timesteps: 1899000, Elapsed Time: 00:22:35, Estimated Time Remaining: 07:04:40\n",
      "Mean Reward (last 1000 steps): -0.03770\n",
      "Timesteps: 102000/2000000, Remaining Timesteps: 1898000, Elapsed Time: 00:22:45, Estimated Time Remaining: 07:03:27\n",
      "Mean Reward (last 1000 steps): -0.05984\n",
      "Timesteps: 103000/2000000, Remaining Timesteps: 1897000, Elapsed Time: 00:23:00, Estimated Time Remaining: 07:03:41\n",
      "Mean Reward (last 1000 steps): -0.03493\n",
      "Timesteps: 104000/2000000, Remaining Timesteps: 1896000, Elapsed Time: 00:23:10, Estimated Time Remaining: 07:02:38\n",
      "Mean Reward (last 1000 steps): -0.05636\n",
      "Timesteps: 105000/2000000, Remaining Timesteps: 1895000, Elapsed Time: 00:23:25, Estimated Time Remaining: 07:02:48\n",
      "Mean Reward (last 1000 steps): -0.03156\n",
      "Timesteps: 106000/2000000, Remaining Timesteps: 1894000, Elapsed Time: 00:23:37, Estimated Time Remaining: 07:02:16\n",
      "Mean Reward (last 1000 steps): 0.09335\n",
      "Timesteps: 107000/2000000, Remaining Timesteps: 1893000, Elapsed Time: 00:23:54, Estimated Time Remaining: 07:02:55\n",
      "Mean Reward (last 1000 steps): 0.02403\n",
      "Timesteps: 108000/2000000, Remaining Timesteps: 1892000, Elapsed Time: 00:24:05, Estimated Time Remaining: 07:02:03\n",
      "Mean Reward (last 1000 steps): 0.07219\n",
      "Timesteps: 109000/2000000, Remaining Timesteps: 1891000, Elapsed Time: 00:24:20, Estimated Time Remaining: 07:02:24\n",
      "Mean Reward (last 1000 steps): 0.09365\n",
      "Timesteps: 110000/2000000, Remaining Timesteps: 1890000, Elapsed Time: 00:24:31, Estimated Time Remaining: 07:01:17\n",
      "Mean Reward (last 1000 steps): -0.01398\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 111000/2000000, Remaining Timesteps: 1889000, Elapsed Time: 00:24:46, Estimated Time Remaining: 07:01:31\n",
      "Mean Reward (last 1000 steps): 0.07690\n",
      "Timesteps: 112000/2000000, Remaining Timesteps: 1888000, Elapsed Time: 00:24:56, Estimated Time Remaining: 07:00:34\n",
      "Mean Reward (last 1000 steps): -0.02282\n",
      "Timesteps: 113000/2000000, Remaining Timesteps: 1887000, Elapsed Time: 00:25:11, Estimated Time Remaining: 07:00:47\n",
      "Mean Reward (last 1000 steps): 0.12101\n",
      "Timesteps: 114000/2000000, Remaining Timesteps: 1886000, Elapsed Time: 00:25:22, Estimated Time Remaining: 06:59:43\n",
      "Mean Reward (last 1000 steps): 0.07949\n",
      "Timesteps: 115000/2000000, Remaining Timesteps: 1885000, Elapsed Time: 00:25:37, Estimated Time Remaining: 07:00:03\n",
      "Mean Reward (last 1000 steps): 0.18477\n",
      "Timesteps: 116000/2000000, Remaining Timesteps: 1884000, Elapsed Time: 00:25:48, Estimated Time Remaining: 06:59:07\n",
      "Mean Reward (last 1000 steps): 0.10505\n",
      "Timesteps: 117000/2000000, Remaining Timesteps: 1883000, Elapsed Time: 00:26:02, Estimated Time Remaining: 06:59:10\n",
      "Mean Reward (last 1000 steps): 0.23333\n",
      "New best mean reward: 0.23333\n",
      "Timesteps: 118000/2000000, Remaining Timesteps: 1882000, Elapsed Time: 00:26:12, Estimated Time Remaining: 06:58:00\n",
      "Mean Reward (last 1000 steps): 0.28550\n",
      "New best mean reward: 0.28550\n",
      "Timesteps: 119000/2000000, Remaining Timesteps: 1881000, Elapsed Time: 00:26:28, Estimated Time Remaining: 06:58:21\n",
      "Mean Reward (last 1000 steps): 0.24815\n",
      "Timesteps: 120000/2000000, Remaining Timesteps: 1880000, Elapsed Time: 00:26:38, Estimated Time Remaining: 06:57:21\n",
      "Mean Reward (last 1000 steps): -0.00645\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 121000/2000000, Remaining Timesteps: 1879000, Elapsed Time: 00:26:54, Estimated Time Remaining: 06:57:48\n",
      "Mean Reward (last 1000 steps): 0.18253\n",
      "Timesteps: 122000/2000000, Remaining Timesteps: 1878000, Elapsed Time: 00:27:04, Estimated Time Remaining: 06:56:39\n",
      "Mean Reward (last 1000 steps): 0.14590\n",
      "Timesteps: 123000/2000000, Remaining Timesteps: 1877000, Elapsed Time: 00:27:20, Estimated Time Remaining: 06:57:08\n",
      "Mean Reward (last 1000 steps): 0.04141\n",
      "Timesteps: 124000/2000000, Remaining Timesteps: 1876000, Elapsed Time: 00:27:30, Estimated Time Remaining: 06:56:14\n",
      "Mean Reward (last 1000 steps): -0.03691\n",
      "Timesteps: 125000/2000000, Remaining Timesteps: 1875000, Elapsed Time: 00:27:45, Estimated Time Remaining: 06:56:27\n",
      "Mean Reward (last 1000 steps): 0.01712\n",
      "Timesteps: 126000/2000000, Remaining Timesteps: 1874000, Elapsed Time: 00:28:09, Estimated Time Remaining: 06:58:52\n",
      "Mean Reward (last 1000 steps): -0.02453\n",
      "Timesteps: 127000/2000000, Remaining Timesteps: 1873000, Elapsed Time: 00:28:26, Estimated Time Remaining: 06:59:20\n",
      "Mean Reward (last 1000 steps): 0.13077\n",
      "Timesteps: 128000/2000000, Remaining Timesteps: 1872000, Elapsed Time: 00:28:36, Estimated Time Remaining: 06:58:23\n",
      "Mean Reward (last 1000 steps): 0.15256\n",
      "Timesteps: 129000/2000000, Remaining Timesteps: 1871000, Elapsed Time: 00:28:47, Estimated Time Remaining: 06:57:29\n",
      "Mean Reward (last 1000 steps): 0.25669\n",
      "Timesteps: 130000/2000000, Remaining Timesteps: 1870000, Elapsed Time: 00:29:01, Estimated Time Remaining: 06:57:37\n",
      "Mean Reward (last 1000 steps): 0.14579\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 131000/2000000, Remaining Timesteps: 1869000, Elapsed Time: 00:29:12, Estimated Time Remaining: 06:56:47\n",
      "Mean Reward (last 1000 steps): 0.14016\n",
      "Timesteps: 132000/2000000, Remaining Timesteps: 1868000, Elapsed Time: 00:29:28, Estimated Time Remaining: 06:57:12\n",
      "Mean Reward (last 1000 steps): 0.12333\n",
      "Timesteps: 133000/2000000, Remaining Timesteps: 1867000, Elapsed Time: 00:29:39, Estimated Time Remaining: 06:56:21\n",
      "Mean Reward (last 1000 steps): 0.45769\n",
      "New best mean reward: 0.45769\n",
      "Timesteps: 134000/2000000, Remaining Timesteps: 1866000, Elapsed Time: 00:29:55, Estimated Time Remaining: 06:56:45\n",
      "Mean Reward (last 1000 steps): 0.28403\n",
      "Timesteps: 135000/2000000, Remaining Timesteps: 1865000, Elapsed Time: 00:30:06, Estimated Time Remaining: 06:55:58\n",
      "Mean Reward (last 1000 steps): 0.34561\n",
      "Timesteps: 136000/2000000, Remaining Timesteps: 1864000, Elapsed Time: 00:30:21, Estimated Time Remaining: 06:56:07\n",
      "Mean Reward (last 1000 steps): 0.40725\n",
      "Timesteps: 137000/2000000, Remaining Timesteps: 1863000, Elapsed Time: 00:30:31, Estimated Time Remaining: 06:55:12\n",
      "Mean Reward (last 1000 steps): -0.00203\n",
      "Timesteps: 138000/2000000, Remaining Timesteps: 1862000, Elapsed Time: 00:30:46, Estimated Time Remaining: 06:55:20\n",
      "Mean Reward (last 1000 steps): 0.40842\n",
      "Timesteps: 139000/2000000, Remaining Timesteps: 1861000, Elapsed Time: 00:30:57, Estimated Time Remaining: 06:54:23\n",
      "Mean Reward (last 1000 steps): -0.02230\n",
      "Timesteps: 140000/2000000, Remaining Timesteps: 1860000, Elapsed Time: 00:31:11, Estimated Time Remaining: 06:54:24\n",
      "Mean Reward (last 1000 steps): 0.53071\n",
      "New best mean reward: 0.53071\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 141000/2000000, Remaining Timesteps: 1859000, Elapsed Time: 00:31:22, Estimated Time Remaining: 06:53:41\n",
      "Mean Reward (last 1000 steps): 0.22370\n",
      "Timesteps: 142000/2000000, Remaining Timesteps: 1858000, Elapsed Time: 00:31:39, Estimated Time Remaining: 06:54:10\n",
      "Mean Reward (last 1000 steps): 0.04603\n",
      "Timesteps: 143000/2000000, Remaining Timesteps: 1857000, Elapsed Time: 00:31:50, Estimated Time Remaining: 06:53:24\n",
      "Mean Reward (last 1000 steps): 0.55141\n",
      "New best mean reward: 0.55141\n",
      "Timesteps: 144000/2000000, Remaining Timesteps: 1856000, Elapsed Time: 00:32:05, Estimated Time Remaining: 06:53:38\n",
      "Mean Reward (last 1000 steps): 0.25857\n",
      "Timesteps: 145000/2000000, Remaining Timesteps: 1855000, Elapsed Time: 00:32:16, Estimated Time Remaining: 06:52:50\n",
      "Mean Reward (last 1000 steps): 0.20449\n",
      "Timesteps: 146000/2000000, Remaining Timesteps: 1854000, Elapsed Time: 00:32:31, Estimated Time Remaining: 06:52:56\n",
      "Mean Reward (last 1000 steps): 0.95515\n",
      "New best mean reward: 0.95515\n",
      "Timesteps: 147000/2000000, Remaining Timesteps: 1853000, Elapsed Time: 00:32:41, Estimated Time Remaining: 06:52:04\n",
      "Mean Reward (last 1000 steps): 0.28539\n",
      "Timesteps: 148000/2000000, Remaining Timesteps: 1852000, Elapsed Time: 00:32:55, Estimated Time Remaining: 06:52:01\n",
      "Mean Reward (last 1000 steps): -0.00389\n",
      "Timesteps: 149000/2000000, Remaining Timesteps: 1851000, Elapsed Time: 00:33:05, Estimated Time Remaining: 06:51:06\n",
      "Mean Reward (last 1000 steps): 0.40136\n",
      "Timesteps: 150000/2000000, Remaining Timesteps: 1850000, Elapsed Time: 00:33:20, Estimated Time Remaining: 06:51:11\n",
      "Mean Reward (last 1000 steps): 0.17045\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 151000/2000000, Remaining Timesteps: 1849000, Elapsed Time: 00:33:31, Estimated Time Remaining: 06:50:33\n",
      "Mean Reward (last 1000 steps): 0.28616\n",
      "Timesteps: 152000/2000000, Remaining Timesteps: 1848000, Elapsed Time: 00:33:46, Estimated Time Remaining: 06:50:41\n",
      "Mean Reward (last 1000 steps): 0.02936\n",
      "Timesteps: 153000/2000000, Remaining Timesteps: 1847000, Elapsed Time: 00:33:57, Estimated Time Remaining: 06:49:54\n",
      "Mean Reward (last 1000 steps): 0.36478\n",
      "Timesteps: 154000/2000000, Remaining Timesteps: 1846000, Elapsed Time: 00:34:11, Estimated Time Remaining: 06:49:53\n",
      "Mean Reward (last 1000 steps): 0.54346\n",
      "Timesteps: 155000/2000000, Remaining Timesteps: 1845000, Elapsed Time: 00:34:22, Estimated Time Remaining: 06:49:07\n",
      "Mean Reward (last 1000 steps): 0.39146\n",
      "Timesteps: 156000/2000000, Remaining Timesteps: 1844000, Elapsed Time: 00:34:37, Estimated Time Remaining: 06:49:21\n",
      "Mean Reward (last 1000 steps): 0.24117\n",
      "Timesteps: 157000/2000000, Remaining Timesteps: 1843000, Elapsed Time: 00:34:48, Estimated Time Remaining: 06:48:41\n",
      "Mean Reward (last 1000 steps): 0.05465\n",
      "Timesteps: 158000/2000000, Remaining Timesteps: 1842000, Elapsed Time: 00:35:04, Estimated Time Remaining: 06:48:53\n",
      "Mean Reward (last 1000 steps): 0.15686\n",
      "Timesteps: 159000/2000000, Remaining Timesteps: 1841000, Elapsed Time: 00:35:15, Estimated Time Remaining: 06:48:13\n",
      "Mean Reward (last 1000 steps): 0.66216\n",
      "Timesteps: 160000/2000000, Remaining Timesteps: 1840000, Elapsed Time: 00:35:30, Estimated Time Remaining: 06:48:22\n",
      "Mean Reward (last 1000 steps): 0.23838\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 161000/2000000, Remaining Timesteps: 1839000, Elapsed Time: 00:35:41, Estimated Time Remaining: 06:47:45\n",
      "Mean Reward (last 1000 steps): 0.85347\n",
      "Timesteps: 162000/2000000, Remaining Timesteps: 1838000, Elapsed Time: 00:35:57, Estimated Time Remaining: 06:47:54\n",
      "Mean Reward (last 1000 steps): 0.16517\n",
      "Timesteps: 163000/2000000, Remaining Timesteps: 1837000, Elapsed Time: 00:36:08, Estimated Time Remaining: 06:47:14\n",
      "Mean Reward (last 1000 steps): 0.15413\n",
      "Timesteps: 164000/2000000, Remaining Timesteps: 1836000, Elapsed Time: 00:36:23, Estimated Time Remaining: 06:47:21\n",
      "Mean Reward (last 1000 steps): 0.24766\n",
      "Timesteps: 165000/2000000, Remaining Timesteps: 1835000, Elapsed Time: 00:36:34, Estimated Time Remaining: 06:46:42\n",
      "Mean Reward (last 1000 steps): 0.23680\n",
      "Timesteps: 166000/2000000, Remaining Timesteps: 1834000, Elapsed Time: 00:36:49, Estimated Time Remaining: 06:46:47\n",
      "Mean Reward (last 1000 steps): 0.14926\n",
      "Timesteps: 167000/2000000, Remaining Timesteps: 1833000, Elapsed Time: 00:37:00, Estimated Time Remaining: 06:46:09\n",
      "Mean Reward (last 1000 steps): 0.15935\n",
      "Timesteps: 168000/2000000, Remaining Timesteps: 1832000, Elapsed Time: 00:37:14, Estimated Time Remaining: 06:46:07\n",
      "Mean Reward (last 1000 steps): 0.08200\n",
      "Timesteps: 169000/2000000, Remaining Timesteps: 1831000, Elapsed Time: 00:37:25, Estimated Time Remaining: 06:45:23\n",
      "Mean Reward (last 1000 steps): 0.28212\n",
      "Timesteps: 170000/2000000, Remaining Timesteps: 1830000, Elapsed Time: 00:37:40, Estimated Time Remaining: 06:45:29\n",
      "Mean Reward (last 1000 steps): 0.31416\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 171000/2000000, Remaining Timesteps: 1829000, Elapsed Time: 00:37:50, Estimated Time Remaining: 06:44:48\n",
      "Mean Reward (last 1000 steps): 0.65155\n",
      "Timesteps: 172000/2000000, Remaining Timesteps: 1828000, Elapsed Time: 00:38:02, Estimated Time Remaining: 06:44:17\n",
      "Mean Reward (last 1000 steps): 0.35629\n",
      "Timesteps: 173000/2000000, Remaining Timesteps: 1827000, Elapsed Time: 00:38:16, Estimated Time Remaining: 06:44:14\n",
      "Mean Reward (last 1000 steps): 0.69502\n",
      "Timesteps: 174000/2000000, Remaining Timesteps: 1826000, Elapsed Time: 00:38:27, Estimated Time Remaining: 06:43:39\n",
      "Mean Reward (last 1000 steps): 0.12780\n",
      "Timesteps: 175000/2000000, Remaining Timesteps: 1825000, Elapsed Time: 00:38:44, Estimated Time Remaining: 06:43:57\n",
      "Mean Reward (last 1000 steps): 0.28195\n",
      "Timesteps: 176000/2000000, Remaining Timesteps: 1824000, Elapsed Time: 00:38:55, Estimated Time Remaining: 06:43:27\n",
      "Mean Reward (last 1000 steps): 0.19480\n",
      "Timesteps: 177000/2000000, Remaining Timesteps: 1823000, Elapsed Time: 00:39:10, Estimated Time Remaining: 06:43:27\n",
      "Mean Reward (last 1000 steps): 0.38869\n",
      "Timesteps: 178000/2000000, Remaining Timesteps: 1822000, Elapsed Time: 00:39:22, Estimated Time Remaining: 06:43:00\n",
      "Mean Reward (last 1000 steps): 0.22956\n",
      "Timesteps: 179000/2000000, Remaining Timesteps: 1821000, Elapsed Time: 00:39:37, Estimated Time Remaining: 06:43:05\n",
      "Mean Reward (last 1000 steps): -0.03194\n",
      "Timesteps: 180000/2000000, Remaining Timesteps: 1820000, Elapsed Time: 00:39:48, Estimated Time Remaining: 06:42:32\n",
      "Mean Reward (last 1000 steps): 0.48788\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 181000/2000000, Remaining Timesteps: 1819000, Elapsed Time: 00:40:04, Estimated Time Remaining: 06:42:42\n",
      "Mean Reward (last 1000 steps): 0.34663\n",
      "Timesteps: 182000/2000000, Remaining Timesteps: 1818000, Elapsed Time: 00:40:15, Estimated Time Remaining: 06:42:08\n",
      "Mean Reward (last 1000 steps): 0.10966\n",
      "Timesteps: 183000/2000000, Remaining Timesteps: 1817000, Elapsed Time: 00:40:31, Estimated Time Remaining: 06:42:22\n",
      "Mean Reward (last 1000 steps): 0.47252\n",
      "Timesteps: 184000/2000000, Remaining Timesteps: 1816000, Elapsed Time: 00:40:42, Estimated Time Remaining: 06:41:44\n",
      "Mean Reward (last 1000 steps): 1.00799\n",
      "New best mean reward: 1.00799\n",
      "Timesteps: 185000/2000000, Remaining Timesteps: 1815000, Elapsed Time: 00:40:56, Estimated Time Remaining: 06:41:38\n",
      "Mean Reward (last 1000 steps): 0.59424\n",
      "Timesteps: 186000/2000000, Remaining Timesteps: 1814000, Elapsed Time: 00:41:07, Estimated Time Remaining: 06:41:05\n",
      "Mean Reward (last 1000 steps): 0.29824\n",
      "Timesteps: 187000/2000000, Remaining Timesteps: 1813000, Elapsed Time: 00:41:23, Estimated Time Remaining: 06:41:21\n",
      "Mean Reward (last 1000 steps): -0.00344\n",
      "Timesteps: 188000/2000000, Remaining Timesteps: 1812000, Elapsed Time: 00:41:36, Estimated Time Remaining: 06:40:59\n",
      "Mean Reward (last 1000 steps): 0.39689\n",
      "Timesteps: 189000/2000000, Remaining Timesteps: 1811000, Elapsed Time: 00:41:52, Estimated Time Remaining: 06:41:10\n",
      "Mean Reward (last 1000 steps): 0.10935\n",
      "Timesteps: 190000/2000000, Remaining Timesteps: 1810000, Elapsed Time: 00:42:03, Estimated Time Remaining: 06:40:36\n",
      "Mean Reward (last 1000 steps): 0.19331\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 191000/2000000, Remaining Timesteps: 1809000, Elapsed Time: 00:42:18, Estimated Time Remaining: 06:40:46\n",
      "Mean Reward (last 1000 steps): 0.69078\n",
      "Timesteps: 192000/2000000, Remaining Timesteps: 1808000, Elapsed Time: 00:42:30, Estimated Time Remaining: 06:40:14\n",
      "Mean Reward (last 1000 steps): 0.34831\n",
      "Timesteps: 193000/2000000, Remaining Timesteps: 1807000, Elapsed Time: 00:42:45, Estimated Time Remaining: 06:40:22\n",
      "Mean Reward (last 1000 steps): 0.44238\n",
      "Timesteps: 194000/2000000, Remaining Timesteps: 1806000, Elapsed Time: 00:42:57, Estimated Time Remaining: 06:39:51\n",
      "Mean Reward (last 1000 steps): 0.33848\n",
      "Timesteps: 195000/2000000, Remaining Timesteps: 1805000, Elapsed Time: 00:43:12, Estimated Time Remaining: 06:39:55\n",
      "Mean Reward (last 1000 steps): 0.37225\n",
      "Timesteps: 196000/2000000, Remaining Timesteps: 1804000, Elapsed Time: 00:43:23, Estimated Time Remaining: 06:39:25\n",
      "Mean Reward (last 1000 steps): 0.28959\n",
      "Timesteps: 197000/2000000, Remaining Timesteps: 1803000, Elapsed Time: 00:43:39, Estimated Time Remaining: 06:39:32\n",
      "Mean Reward (last 1000 steps): 0.45597\n",
      "Timesteps: 198000/2000000, Remaining Timesteps: 1802000, Elapsed Time: 00:43:50, Estimated Time Remaining: 06:39:01\n",
      "Mean Reward (last 1000 steps): 0.35903\n",
      "Timesteps: 199000/2000000, Remaining Timesteps: 1801000, Elapsed Time: 00:44:05, Estimated Time Remaining: 06:39:04\n",
      "Mean Reward (last 1000 steps): 0.42884\n",
      "Timesteps: 200000/2000000, Remaining Timesteps: 1800000, Elapsed Time: 00:44:16, Estimated Time Remaining: 06:38:32\n",
      "Mean Reward (last 1000 steps): 0.31671\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 201000/2000000, Remaining Timesteps: 1799000, Elapsed Time: 00:44:31, Estimated Time Remaining: 06:38:29\n",
      "Mean Reward (last 1000 steps): 0.31750\n",
      "Timesteps: 202000/2000000, Remaining Timesteps: 1798000, Elapsed Time: 00:44:42, Estimated Time Remaining: 06:37:52\n",
      "Mean Reward (last 1000 steps): 0.18642\n",
      "Timesteps: 203000/2000000, Remaining Timesteps: 1797000, Elapsed Time: 00:44:58, Estimated Time Remaining: 06:38:10\n",
      "Mean Reward (last 1000 steps): 0.35793\n",
      "Timesteps: 204000/2000000, Remaining Timesteps: 1796000, Elapsed Time: 00:45:10, Estimated Time Remaining: 06:37:44\n",
      "Mean Reward (last 1000 steps): 0.24615\n",
      "Timesteps: 205000/2000000, Remaining Timesteps: 1795000, Elapsed Time: 00:45:25, Estimated Time Remaining: 06:37:44\n",
      "Mean Reward (last 1000 steps): 0.49443\n",
      "Timesteps: 206000/2000000, Remaining Timesteps: 1794000, Elapsed Time: 00:45:37, Estimated Time Remaining: 06:37:23\n",
      "Mean Reward (last 1000 steps): 0.14522\n",
      "Timesteps: 207000/2000000, Remaining Timesteps: 1793000, Elapsed Time: 00:45:55, Estimated Time Remaining: 06:37:45\n",
      "Mean Reward (last 1000 steps): 0.27827\n",
      "Timesteps: 208000/2000000, Remaining Timesteps: 1792000, Elapsed Time: 00:46:06, Estimated Time Remaining: 06:37:18\n",
      "Mean Reward (last 1000 steps): 0.18064\n",
      "Timesteps: 209000/2000000, Remaining Timesteps: 1791000, Elapsed Time: 00:46:24, Estimated Time Remaining: 06:37:44\n",
      "Mean Reward (last 1000 steps): 0.22118\n",
      "Timesteps: 210000/2000000, Remaining Timesteps: 1790000, Elapsed Time: 00:46:36, Estimated Time Remaining: 06:37:18\n",
      "Mean Reward (last 1000 steps): 0.48945\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 211000/2000000, Remaining Timesteps: 1789000, Elapsed Time: 00:46:53, Estimated Time Remaining: 06:37:31\n",
      "Mean Reward (last 1000 steps): 0.30328\n",
      "Timesteps: 212000/2000000, Remaining Timesteps: 1788000, Elapsed Time: 00:47:04, Estimated Time Remaining: 06:37:02\n",
      "Mean Reward (last 1000 steps): 0.48445\n",
      "Timesteps: 213000/2000000, Remaining Timesteps: 1787000, Elapsed Time: 00:47:19, Estimated Time Remaining: 06:37:05\n",
      "Mean Reward (last 1000 steps): 0.34450\n",
      "Timesteps: 214000/2000000, Remaining Timesteps: 1786000, Elapsed Time: 00:47:30, Estimated Time Remaining: 06:36:30\n",
      "Mean Reward (last 1000 steps): 0.39621\n",
      "Timesteps: 215000/2000000, Remaining Timesteps: 1785000, Elapsed Time: 00:47:42, Estimated Time Remaining: 06:36:06\n",
      "Mean Reward (last 1000 steps): 0.32660\n",
      "Timesteps: 216000/2000000, Remaining Timesteps: 1784000, Elapsed Time: 00:48:11, Estimated Time Remaining: 06:38:01\n",
      "Mean Reward (last 1000 steps): 0.20872\n",
      "Timesteps: 217000/2000000, Remaining Timesteps: 1783000, Elapsed Time: 00:48:32, Estimated Time Remaining: 06:38:48\n",
      "Mean Reward (last 1000 steps): 0.63680\n",
      "Timesteps: 218000/2000000, Remaining Timesteps: 1782000, Elapsed Time: 00:48:47, Estimated Time Remaining: 06:38:49\n",
      "Mean Reward (last 1000 steps): 0.32824\n",
      "Timesteps: 219000/2000000, Remaining Timesteps: 1781000, Elapsed Time: 00:48:58, Estimated Time Remaining: 06:38:17\n",
      "Mean Reward (last 1000 steps): 0.20052\n",
      "Timesteps: 220000/2000000, Remaining Timesteps: 1780000, Elapsed Time: 00:49:13, Estimated Time Remaining: 06:38:20\n",
      "Mean Reward (last 1000 steps): 0.07278\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 221000/2000000, Remaining Timesteps: 1779000, Elapsed Time: 00:49:25, Estimated Time Remaining: 06:37:47\n",
      "Mean Reward (last 1000 steps): 0.34853\n",
      "Timesteps: 222000/2000000, Remaining Timesteps: 1778000, Elapsed Time: 00:49:39, Estimated Time Remaining: 06:37:40\n",
      "Mean Reward (last 1000 steps): 0.27899\n",
      "Timesteps: 223000/2000000, Remaining Timesteps: 1777000, Elapsed Time: 00:49:50, Estimated Time Remaining: 06:37:12\n",
      "Mean Reward (last 1000 steps): 0.53180\n",
      "Timesteps: 224000/2000000, Remaining Timesteps: 1776000, Elapsed Time: 00:50:05, Estimated Time Remaining: 06:37:07\n",
      "Mean Reward (last 1000 steps): 0.00958\n",
      "Timesteps: 225000/2000000, Remaining Timesteps: 1775000, Elapsed Time: 00:50:16, Estimated Time Remaining: 06:36:37\n",
      "Mean Reward (last 1000 steps): 0.43347\n",
      "Timesteps: 226000/2000000, Remaining Timesteps: 1774000, Elapsed Time: 00:50:31, Estimated Time Remaining: 06:36:34\n",
      "Mean Reward (last 1000 steps): 0.23835\n",
      "Timesteps: 227000/2000000, Remaining Timesteps: 1773000, Elapsed Time: 00:50:42, Estimated Time Remaining: 06:36:02\n",
      "Mean Reward (last 1000 steps): 0.22900\n",
      "Timesteps: 228000/2000000, Remaining Timesteps: 1772000, Elapsed Time: 00:50:57, Estimated Time Remaining: 06:35:58\n",
      "Mean Reward (last 1000 steps): 0.38776\n",
      "Timesteps: 229000/2000000, Remaining Timesteps: 1771000, Elapsed Time: 00:51:08, Estimated Time Remaining: 06:35:26\n",
      "Mean Reward (last 1000 steps): 0.30669\n",
      "Timesteps: 230000/2000000, Remaining Timesteps: 1770000, Elapsed Time: 00:51:22, Estimated Time Remaining: 06:35:20\n",
      "Mean Reward (last 1000 steps): 0.49022\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 231000/2000000, Remaining Timesteps: 1769000, Elapsed Time: 00:51:33, Estimated Time Remaining: 06:34:48\n",
      "Mean Reward (last 1000 steps): 0.25012\n",
      "Timesteps: 232000/2000000, Remaining Timesteps: 1768000, Elapsed Time: 00:51:47, Estimated Time Remaining: 06:34:41\n",
      "Mean Reward (last 1000 steps): -0.03919\n",
      "Timesteps: 233000/2000000, Remaining Timesteps: 1767000, Elapsed Time: 00:51:58, Estimated Time Remaining: 06:34:08\n",
      "Mean Reward (last 1000 steps): 0.12887\n",
      "Timesteps: 234000/2000000, Remaining Timesteps: 1766000, Elapsed Time: 00:52:12, Estimated Time Remaining: 06:34:04\n",
      "Mean Reward (last 1000 steps): 0.32806\n",
      "Timesteps: 235000/2000000, Remaining Timesteps: 1765000, Elapsed Time: 00:52:23, Estimated Time Remaining: 06:33:32\n",
      "Mean Reward (last 1000 steps): 0.36284\n",
      "Timesteps: 236000/2000000, Remaining Timesteps: 1764000, Elapsed Time: 00:52:38, Estimated Time Remaining: 06:33:31\n",
      "Mean Reward (last 1000 steps): 0.60675\n",
      "Timesteps: 237000/2000000, Remaining Timesteps: 1763000, Elapsed Time: 00:52:49, Estimated Time Remaining: 06:32:58\n",
      "Mean Reward (last 1000 steps): 0.56664\n",
      "Timesteps: 238000/2000000, Remaining Timesteps: 1762000, Elapsed Time: 00:53:03, Estimated Time Remaining: 06:32:51\n",
      "Mean Reward (last 1000 steps): 0.32375\n",
      "Timesteps: 239000/2000000, Remaining Timesteps: 1761000, Elapsed Time: 00:53:14, Estimated Time Remaining: 06:32:17\n",
      "Mean Reward (last 1000 steps): 0.70907\n",
      "Timesteps: 240000/2000000, Remaining Timesteps: 1760000, Elapsed Time: 00:53:29, Estimated Time Remaining: 06:32:14\n",
      "Mean Reward (last 1000 steps): 0.38568\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 241000/2000000, Remaining Timesteps: 1759000, Elapsed Time: 00:53:40, Estimated Time Remaining: 06:31:48\n",
      "Mean Reward (last 1000 steps): 0.70185\n",
      "Timesteps: 242000/2000000, Remaining Timesteps: 1758000, Elapsed Time: 00:53:55, Estimated Time Remaining: 06:31:45\n",
      "Mean Reward (last 1000 steps): 0.50422\n",
      "Timesteps: 243000/2000000, Remaining Timesteps: 1757000, Elapsed Time: 00:54:07, Estimated Time Remaining: 06:31:17\n",
      "Mean Reward (last 1000 steps): 0.53510\n",
      "Timesteps: 244000/2000000, Remaining Timesteps: 1756000, Elapsed Time: 00:54:21, Estimated Time Remaining: 06:31:11\n",
      "Mean Reward (last 1000 steps): 0.30707\n",
      "Timesteps: 245000/2000000, Remaining Timesteps: 1755000, Elapsed Time: 00:54:32, Estimated Time Remaining: 06:30:38\n",
      "Mean Reward (last 1000 steps): 0.31806\n",
      "Timesteps: 246000/2000000, Remaining Timesteps: 1754000, Elapsed Time: 00:54:46, Estimated Time Remaining: 06:30:35\n",
      "Mean Reward (last 1000 steps): 0.44353\n",
      "Timesteps: 247000/2000000, Remaining Timesteps: 1753000, Elapsed Time: 00:54:57, Estimated Time Remaining: 06:30:01\n",
      "Mean Reward (last 1000 steps): 0.50961\n",
      "Timesteps: 248000/2000000, Remaining Timesteps: 1752000, Elapsed Time: 00:55:11, Estimated Time Remaining: 06:29:56\n",
      "Mean Reward (last 1000 steps): 0.46817\n",
      "Timesteps: 249000/2000000, Remaining Timesteps: 1751000, Elapsed Time: 00:55:22, Estimated Time Remaining: 06:29:24\n",
      "Mean Reward (last 1000 steps): 0.23423\n",
      "Timesteps: 250000/2000000, Remaining Timesteps: 1750000, Elapsed Time: 00:55:37, Estimated Time Remaining: 06:29:20\n",
      "Mean Reward (last 1000 steps): 0.47752\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 251000/2000000, Remaining Timesteps: 1749000, Elapsed Time: 00:55:47, Estimated Time Remaining: 06:28:45\n",
      "Mean Reward (last 1000 steps): 0.67193\n",
      "Timesteps: 252000/2000000, Remaining Timesteps: 1748000, Elapsed Time: 00:56:02, Estimated Time Remaining: 06:28:42\n",
      "Mean Reward (last 1000 steps): 0.16183\n",
      "Timesteps: 253000/2000000, Remaining Timesteps: 1747000, Elapsed Time: 00:56:12, Estimated Time Remaining: 06:28:08\n",
      "Mean Reward (last 1000 steps): 0.66088\n",
      "Timesteps: 254000/2000000, Remaining Timesteps: 1746000, Elapsed Time: 00:56:27, Estimated Time Remaining: 06:28:03\n",
      "Mean Reward (last 1000 steps): 0.56204\n",
      "Timesteps: 255000/2000000, Remaining Timesteps: 1745000, Elapsed Time: 00:56:37, Estimated Time Remaining: 06:27:29\n",
      "Mean Reward (last 1000 steps): 0.32100\n",
      "Timesteps: 256000/2000000, Remaining Timesteps: 1744000, Elapsed Time: 00:56:48, Estimated Time Remaining: 06:26:59\n",
      "Mean Reward (last 1000 steps): 0.61399\n",
      "Timesteps: 257000/2000000, Remaining Timesteps: 1743000, Elapsed Time: 00:57:02, Estimated Time Remaining: 06:26:51\n",
      "Mean Reward (last 1000 steps): 0.27308\n",
      "Timesteps: 258000/2000000, Remaining Timesteps: 1742000, Elapsed Time: 00:57:13, Estimated Time Remaining: 06:26:22\n",
      "Mean Reward (last 1000 steps): 0.26629\n",
      "Timesteps: 259000/2000000, Remaining Timesteps: 1741000, Elapsed Time: 00:57:27, Estimated Time Remaining: 06:26:15\n",
      "Mean Reward (last 1000 steps): 0.17122\n",
      "Timesteps: 260000/2000000, Remaining Timesteps: 1740000, Elapsed Time: 00:57:38, Estimated Time Remaining: 06:25:45\n",
      "Mean Reward (last 1000 steps): 0.07946\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 261000/2000000, Remaining Timesteps: 1739000, Elapsed Time: 00:57:52, Estimated Time Remaining: 06:25:39\n",
      "Mean Reward (last 1000 steps): 0.19990\n",
      "Timesteps: 262000/2000000, Remaining Timesteps: 1738000, Elapsed Time: 00:58:03, Estimated Time Remaining: 06:25:11\n",
      "Mean Reward (last 1000 steps): 0.31889\n",
      "Timesteps: 263000/2000000, Remaining Timesteps: 1737000, Elapsed Time: 00:58:18, Estimated Time Remaining: 06:25:04\n",
      "Mean Reward (last 1000 steps): 0.18376\n",
      "Timesteps: 264000/2000000, Remaining Timesteps: 1736000, Elapsed Time: 00:58:29, Estimated Time Remaining: 06:24:40\n",
      "Mean Reward (last 1000 steps): 0.14820\n",
      "Timesteps: 265000/2000000, Remaining Timesteps: 1735000, Elapsed Time: 00:58:44, Estimated Time Remaining: 06:24:32\n",
      "Mean Reward (last 1000 steps): -0.01864\n",
      "Timesteps: 266000/2000000, Remaining Timesteps: 1734000, Elapsed Time: 00:58:54, Estimated Time Remaining: 06:24:02\n",
      "Mean Reward (last 1000 steps): -0.03650\n",
      "Timesteps: 267000/2000000, Remaining Timesteps: 1733000, Elapsed Time: 00:59:08, Estimated Time Remaining: 06:23:54\n",
      "Mean Reward (last 1000 steps): 0.10894\n",
      "Timesteps: 268000/2000000, Remaining Timesteps: 1732000, Elapsed Time: 00:59:19, Estimated Time Remaining: 06:23:25\n",
      "Mean Reward (last 1000 steps): -0.03597\n",
      "Timesteps: 269000/2000000, Remaining Timesteps: 1731000, Elapsed Time: 00:59:33, Estimated Time Remaining: 06:23:16\n",
      "Mean Reward (last 1000 steps): -0.00781\n",
      "Timesteps: 270000/2000000, Remaining Timesteps: 1730000, Elapsed Time: 00:59:44, Estimated Time Remaining: 06:22:46\n",
      "Mean Reward (last 1000 steps): -0.05000\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 271000/2000000, Remaining Timesteps: 1729000, Elapsed Time: 00:59:59, Estimated Time Remaining: 06:22:44\n",
      "Mean Reward (last 1000 steps): 0.33815\n",
      "Timesteps: 272000/2000000, Remaining Timesteps: 1728000, Elapsed Time: 01:00:10, Estimated Time Remaining: 06:22:14\n",
      "Mean Reward (last 1000 steps): -0.06167\n",
      "Timesteps: 273000/2000000, Remaining Timesteps: 1727000, Elapsed Time: 01:00:23, Estimated Time Remaining: 06:22:04\n",
      "Mean Reward (last 1000 steps): 0.09512\n",
      "Timesteps: 274000/2000000, Remaining Timesteps: 1726000, Elapsed Time: 01:00:34, Estimated Time Remaining: 06:21:37\n",
      "Mean Reward (last 1000 steps): -0.05203\n",
      "Timesteps: 275000/2000000, Remaining Timesteps: 1725000, Elapsed Time: 01:00:48, Estimated Time Remaining: 06:21:25\n",
      "Mean Reward (last 1000 steps): -0.05713\n",
      "Timesteps: 276000/2000000, Remaining Timesteps: 1724000, Elapsed Time: 01:00:58, Estimated Time Remaining: 06:20:54\n",
      "Mean Reward (last 1000 steps): 0.08858\n",
      "Timesteps: 277000/2000000, Remaining Timesteps: 1723000, Elapsed Time: 01:01:12, Estimated Time Remaining: 06:20:41\n",
      "Mean Reward (last 1000 steps): 0.19888\n",
      "Timesteps: 278000/2000000, Remaining Timesteps: 1722000, Elapsed Time: 01:01:22, Estimated Time Remaining: 06:20:12\n",
      "Mean Reward (last 1000 steps): 0.09751\n",
      "Timesteps: 279000/2000000, Remaining Timesteps: 1721000, Elapsed Time: 01:01:37, Estimated Time Remaining: 06:20:05\n",
      "Mean Reward (last 1000 steps): -0.02560\n",
      "Timesteps: 280000/2000000, Remaining Timesteps: 1720000, Elapsed Time: 01:01:48, Estimated Time Remaining: 06:19:39\n",
      "Mean Reward (last 1000 steps): 0.05987\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 281000/2000000, Remaining Timesteps: 1719000, Elapsed Time: 01:02:02, Estimated Time Remaining: 06:19:32\n",
      "Mean Reward (last 1000 steps): 0.01145\n",
      "Timesteps: 282000/2000000, Remaining Timesteps: 1718000, Elapsed Time: 01:02:13, Estimated Time Remaining: 06:19:02\n",
      "Mean Reward (last 1000 steps): -0.05638\n",
      "Timesteps: 283000/2000000, Remaining Timesteps: 1717000, Elapsed Time: 01:02:27, Estimated Time Remaining: 06:18:55\n",
      "Mean Reward (last 1000 steps): 0.08707\n",
      "Timesteps: 284000/2000000, Remaining Timesteps: 1716000, Elapsed Time: 01:02:37, Estimated Time Remaining: 06:18:25\n",
      "Mean Reward (last 1000 steps): 0.01481\n",
      "Timesteps: 285000/2000000, Remaining Timesteps: 1715000, Elapsed Time: 01:02:51, Estimated Time Remaining: 06:18:17\n",
      "Mean Reward (last 1000 steps): -0.05935\n",
      "Timesteps: 286000/2000000, Remaining Timesteps: 1714000, Elapsed Time: 01:03:01, Estimated Time Remaining: 06:17:44\n",
      "Mean Reward (last 1000 steps): 0.00760\n",
      "Timesteps: 287000/2000000, Remaining Timesteps: 1713000, Elapsed Time: 01:03:17, Estimated Time Remaining: 06:17:43\n",
      "Mean Reward (last 1000 steps): -0.05724\n",
      "Timesteps: 288000/2000000, Remaining Timesteps: 1712000, Elapsed Time: 01:03:27, Estimated Time Remaining: 06:17:12\n",
      "Mean Reward (last 1000 steps): 0.06472\n",
      "Timesteps: 289000/2000000, Remaining Timesteps: 1711000, Elapsed Time: 01:03:42, Estimated Time Remaining: 06:17:08\n",
      "Mean Reward (last 1000 steps): 0.07561\n",
      "Timesteps: 290000/2000000, Remaining Timesteps: 1710000, Elapsed Time: 01:03:52, Estimated Time Remaining: 06:16:37\n",
      "Mean Reward (last 1000 steps): 0.03871\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 291000/2000000, Remaining Timesteps: 1709000, Elapsed Time: 01:04:07, Estimated Time Remaining: 06:16:38\n",
      "Mean Reward (last 1000 steps): 0.00895\n",
      "Timesteps: 292000/2000000, Remaining Timesteps: 1708000, Elapsed Time: 01:04:17, Estimated Time Remaining: 06:16:06\n",
      "Mean Reward (last 1000 steps): 0.01177\n",
      "Timesteps: 293000/2000000, Remaining Timesteps: 1707000, Elapsed Time: 01:04:33, Estimated Time Remaining: 06:16:04\n",
      "Mean Reward (last 1000 steps): 0.15807\n",
      "Timesteps: 294000/2000000, Remaining Timesteps: 1706000, Elapsed Time: 01:04:43, Estimated Time Remaining: 06:15:37\n",
      "Mean Reward (last 1000 steps): 0.05477\n",
      "Timesteps: 295000/2000000, Remaining Timesteps: 1705000, Elapsed Time: 01:05:01, Estimated Time Remaining: 06:15:48\n",
      "Mean Reward (last 1000 steps): -0.02899\n",
      "Timesteps: 296000/2000000, Remaining Timesteps: 1704000, Elapsed Time: 01:05:14, Estimated Time Remaining: 06:15:33\n",
      "Mean Reward (last 1000 steps): 0.11014\n",
      "Timesteps: 297000/2000000, Remaining Timesteps: 1703000, Elapsed Time: 01:05:31, Estimated Time Remaining: 06:15:44\n",
      "Mean Reward (last 1000 steps): 0.02638\n",
      "Timesteps: 298000/2000000, Remaining Timesteps: 1702000, Elapsed Time: 01:05:44, Estimated Time Remaining: 06:15:30\n",
      "Mean Reward (last 1000 steps): 0.05758\n",
      "Timesteps: 299000/2000000, Remaining Timesteps: 1701000, Elapsed Time: 01:05:57, Estimated Time Remaining: 06:15:16\n",
      "Mean Reward (last 1000 steps): -0.01467\n",
      "Timesteps: 300000/2000000, Remaining Timesteps: 1700000, Elapsed Time: 01:06:14, Estimated Time Remaining: 06:15:24\n",
      "Mean Reward (last 1000 steps): 0.12139\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 301000/2000000, Remaining Timesteps: 1699000, Elapsed Time: 01:06:28, Estimated Time Remaining: 06:15:12\n",
      "Mean Reward (last 1000 steps): 0.13746\n",
      "Timesteps: 302000/2000000, Remaining Timesteps: 1698000, Elapsed Time: 01:06:45, Estimated Time Remaining: 06:15:23\n",
      "Mean Reward (last 1000 steps): -0.04594\n",
      "Timesteps: 303000/2000000, Remaining Timesteps: 1697000, Elapsed Time: 01:06:59, Estimated Time Remaining: 06:15:12\n",
      "Mean Reward (last 1000 steps): 0.17291\n",
      "Timesteps: 304000/2000000, Remaining Timesteps: 1696000, Elapsed Time: 01:07:16, Estimated Time Remaining: 06:15:19\n",
      "Mean Reward (last 1000 steps): 0.04510\n",
      "Timesteps: 305000/2000000, Remaining Timesteps: 1695000, Elapsed Time: 01:07:30, Estimated Time Remaining: 06:15:10\n",
      "Mean Reward (last 1000 steps): 0.12788\n",
      "Timesteps: 306000/2000000, Remaining Timesteps: 1694000, Elapsed Time: 01:07:48, Estimated Time Remaining: 06:15:22\n",
      "Mean Reward (last 1000 steps): 0.07249\n",
      "Timesteps: 307000/2000000, Remaining Timesteps: 1693000, Elapsed Time: 01:08:01, Estimated Time Remaining: 06:15:08\n",
      "Mean Reward (last 1000 steps): 0.05580\n",
      "Timesteps: 308000/2000000, Remaining Timesteps: 1692000, Elapsed Time: 01:08:18, Estimated Time Remaining: 06:15:15\n",
      "Mean Reward (last 1000 steps): 0.21854\n",
      "Timesteps: 309000/2000000, Remaining Timesteps: 1691000, Elapsed Time: 01:08:31, Estimated Time Remaining: 06:15:01\n",
      "Mean Reward (last 1000 steps): 0.18250\n",
      "Timesteps: 310000/2000000, Remaining Timesteps: 1690000, Elapsed Time: 01:08:48, Estimated Time Remaining: 06:15:08\n",
      "Mean Reward (last 1000 steps): 0.00902\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 311000/2000000, Remaining Timesteps: 1689000, Elapsed Time: 01:09:02, Estimated Time Remaining: 06:14:55\n",
      "Mean Reward (last 1000 steps): 0.09910\n",
      "Timesteps: 312000/2000000, Remaining Timesteps: 1688000, Elapsed Time: 01:09:19, Estimated Time Remaining: 06:15:05\n",
      "Mean Reward (last 1000 steps): 0.09667\n",
      "Timesteps: 313000/2000000, Remaining Timesteps: 1687000, Elapsed Time: 01:09:33, Estimated Time Remaining: 06:14:53\n",
      "Mean Reward (last 1000 steps): 0.20778\n",
      "Timesteps: 314000/2000000, Remaining Timesteps: 1686000, Elapsed Time: 01:09:50, Estimated Time Remaining: 06:14:59\n",
      "Mean Reward (last 1000 steps): 0.29506\n",
      "Timesteps: 315000/2000000, Remaining Timesteps: 1685000, Elapsed Time: 01:10:03, Estimated Time Remaining: 06:14:47\n",
      "Mean Reward (last 1000 steps): 0.15036\n",
      "Timesteps: 316000/2000000, Remaining Timesteps: 1684000, Elapsed Time: 01:10:20, Estimated Time Remaining: 06:14:53\n",
      "Mean Reward (last 1000 steps): -0.08039\n",
      "Timesteps: 317000/2000000, Remaining Timesteps: 1683000, Elapsed Time: 01:10:34, Estimated Time Remaining: 06:14:39\n",
      "Mean Reward (last 1000 steps): 0.02313\n",
      "Timesteps: 318000/2000000, Remaining Timesteps: 1682000, Elapsed Time: 01:10:50, Estimated Time Remaining: 06:14:44\n",
      "Mean Reward (last 1000 steps): -0.02977\n",
      "Timesteps: 319000/2000000, Remaining Timesteps: 1681000, Elapsed Time: 01:11:04, Estimated Time Remaining: 06:14:32\n",
      "Mean Reward (last 1000 steps): 0.25739\n",
      "Timesteps: 320000/2000000, Remaining Timesteps: 1680000, Elapsed Time: 01:11:21, Estimated Time Remaining: 06:14:38\n",
      "Mean Reward (last 1000 steps): 0.00547\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 321000/2000000, Remaining Timesteps: 1679000, Elapsed Time: 01:11:34, Estimated Time Remaining: 06:14:24\n",
      "Mean Reward (last 1000 steps): 0.32815\n",
      "Timesteps: 322000/2000000, Remaining Timesteps: 1678000, Elapsed Time: 01:11:51, Estimated Time Remaining: 06:14:30\n",
      "Mean Reward (last 1000 steps): 0.48043\n",
      "Timesteps: 323000/2000000, Remaining Timesteps: 1677000, Elapsed Time: 01:12:05, Estimated Time Remaining: 06:14:15\n",
      "Mean Reward (last 1000 steps): -0.00734\n",
      "Timesteps: 324000/2000000, Remaining Timesteps: 1676000, Elapsed Time: 01:12:22, Estimated Time Remaining: 06:14:21\n",
      "Mean Reward (last 1000 steps): 0.36492\n",
      "Timesteps: 325000/2000000, Remaining Timesteps: 1675000, Elapsed Time: 01:12:35, Estimated Time Remaining: 06:14:07\n",
      "Mean Reward (last 1000 steps): -0.01870\n",
      "Timesteps: 326000/2000000, Remaining Timesteps: 1674000, Elapsed Time: 01:12:52, Estimated Time Remaining: 06:14:11\n",
      "Mean Reward (last 1000 steps): 0.26232\n",
      "Timesteps: 327000/2000000, Remaining Timesteps: 1673000, Elapsed Time: 01:13:06, Estimated Time Remaining: 06:14:00\n",
      "Mean Reward (last 1000 steps): 0.11013\n",
      "Timesteps: 328000/2000000, Remaining Timesteps: 1672000, Elapsed Time: 01:13:23, Estimated Time Remaining: 06:14:05\n",
      "Mean Reward (last 1000 steps): 0.11583\n",
      "Timesteps: 329000/2000000, Remaining Timesteps: 1671000, Elapsed Time: 01:13:36, Estimated Time Remaining: 06:13:53\n",
      "Mean Reward (last 1000 steps): 0.51693\n",
      "Timesteps: 330000/2000000, Remaining Timesteps: 1670000, Elapsed Time: 01:13:54, Estimated Time Remaining: 06:14:02\n",
      "Mean Reward (last 1000 steps): 0.13333\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 331000/2000000, Remaining Timesteps: 1669000, Elapsed Time: 01:14:08, Estimated Time Remaining: 06:13:52\n",
      "Mean Reward (last 1000 steps): 0.22980\n",
      "Timesteps: 332000/2000000, Remaining Timesteps: 1668000, Elapsed Time: 01:14:26, Estimated Time Remaining: 06:14:00\n",
      "Mean Reward (last 1000 steps): 0.09178\n",
      "Timesteps: 333000/2000000, Remaining Timesteps: 1667000, Elapsed Time: 01:14:39, Estimated Time Remaining: 06:13:46\n",
      "Mean Reward (last 1000 steps): 0.43624\n",
      "Timesteps: 334000/2000000, Remaining Timesteps: 1666000, Elapsed Time: 01:14:57, Estimated Time Remaining: 06:13:51\n",
      "Mean Reward (last 1000 steps): 0.16528\n",
      "Timesteps: 335000/2000000, Remaining Timesteps: 1665000, Elapsed Time: 01:15:10, Estimated Time Remaining: 06:13:36\n",
      "Mean Reward (last 1000 steps): -0.02937\n",
      "Timesteps: 336000/2000000, Remaining Timesteps: 1664000, Elapsed Time: 01:15:27, Estimated Time Remaining: 06:13:43\n",
      "Mean Reward (last 1000 steps): 0.11955\n",
      "Timesteps: 337000/2000000, Remaining Timesteps: 1663000, Elapsed Time: 01:15:40, Estimated Time Remaining: 06:13:27\n",
      "Mean Reward (last 1000 steps): 0.25279\n",
      "Timesteps: 338000/2000000, Remaining Timesteps: 1662000, Elapsed Time: 01:15:58, Estimated Time Remaining: 06:13:34\n",
      "Mean Reward (last 1000 steps): -0.04030\n",
      "Timesteps: 339000/2000000, Remaining Timesteps: 1661000, Elapsed Time: 01:16:11, Estimated Time Remaining: 06:13:19\n",
      "Mean Reward (last 1000 steps): 0.19032\n",
      "Timesteps: 340000/2000000, Remaining Timesteps: 1660000, Elapsed Time: 01:16:29, Estimated Time Remaining: 06:13:25\n",
      "Mean Reward (last 1000 steps): 0.00368\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 341000/2000000, Remaining Timesteps: 1659000, Elapsed Time: 01:16:41, Estimated Time Remaining: 06:13:09\n",
      "Mean Reward (last 1000 steps): 0.36646\n",
      "Timesteps: 342000/2000000, Remaining Timesteps: 1658000, Elapsed Time: 01:16:55, Estimated Time Remaining: 06:12:53\n",
      "Mean Reward (last 1000 steps): 0.43356\n",
      "Timesteps: 343000/2000000, Remaining Timesteps: 1657000, Elapsed Time: 01:17:22, Estimated Time Remaining: 06:13:45\n",
      "Mean Reward (last 1000 steps): 0.23007\n",
      "Timesteps: 344000/2000000, Remaining Timesteps: 1656000, Elapsed Time: 01:17:41, Estimated Time Remaining: 06:14:01\n",
      "Mean Reward (last 1000 steps): 0.11959\n",
      "Timesteps: 345000/2000000, Remaining Timesteps: 1655000, Elapsed Time: 01:17:58, Estimated Time Remaining: 06:14:04\n",
      "Mean Reward (last 1000 steps): 0.15890\n",
      "Timesteps: 346000/2000000, Remaining Timesteps: 1654000, Elapsed Time: 01:18:12, Estimated Time Remaining: 06:13:49\n",
      "Mean Reward (last 1000 steps): 0.17450\n",
      "Timesteps: 347000/2000000, Remaining Timesteps: 1653000, Elapsed Time: 01:18:29, Estimated Time Remaining: 06:13:53\n",
      "Mean Reward (last 1000 steps): 0.06026\n",
      "Timesteps: 348000/2000000, Remaining Timesteps: 1652000, Elapsed Time: 01:18:43, Estimated Time Remaining: 06:13:40\n",
      "Mean Reward (last 1000 steps): 0.04041\n",
      "Timesteps: 349000/2000000, Remaining Timesteps: 1651000, Elapsed Time: 01:18:59, Estimated Time Remaining: 06:13:42\n",
      "Mean Reward (last 1000 steps): 0.27596\n",
      "Timesteps: 350000/2000000, Remaining Timesteps: 1650000, Elapsed Time: 01:19:13, Estimated Time Remaining: 06:13:27\n",
      "Mean Reward (last 1000 steps): 0.02541\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 351000/2000000, Remaining Timesteps: 1649000, Elapsed Time: 01:19:30, Estimated Time Remaining: 06:13:31\n",
      "Mean Reward (last 1000 steps): 0.07855\n",
      "Timesteps: 352000/2000000, Remaining Timesteps: 1648000, Elapsed Time: 01:19:44, Estimated Time Remaining: 06:13:19\n",
      "Mean Reward (last 1000 steps): 0.28264\n",
      "Timesteps: 353000/2000000, Remaining Timesteps: 1647000, Elapsed Time: 01:20:01, Estimated Time Remaining: 06:13:22\n",
      "Mean Reward (last 1000 steps): 0.02168\n",
      "Timesteps: 354000/2000000, Remaining Timesteps: 1646000, Elapsed Time: 01:20:14, Estimated Time Remaining: 06:13:05\n",
      "Mean Reward (last 1000 steps): 0.06842\n",
      "Timesteps: 355000/2000000, Remaining Timesteps: 1645000, Elapsed Time: 01:20:31, Estimated Time Remaining: 06:13:10\n",
      "Mean Reward (last 1000 steps): 0.15868\n",
      "Timesteps: 356000/2000000, Remaining Timesteps: 1644000, Elapsed Time: 01:20:45, Estimated Time Remaining: 06:12:54\n",
      "Mean Reward (last 1000 steps): 0.15744\n",
      "Timesteps: 357000/2000000, Remaining Timesteps: 1643000, Elapsed Time: 01:21:02, Estimated Time Remaining: 06:12:57\n",
      "Mean Reward (last 1000 steps): 0.06911\n",
      "Timesteps: 358000/2000000, Remaining Timesteps: 1642000, Elapsed Time: 01:21:15, Estimated Time Remaining: 06:12:43\n",
      "Mean Reward (last 1000 steps): 0.23692\n",
      "Timesteps: 359000/2000000, Remaining Timesteps: 1641000, Elapsed Time: 01:21:33, Estimated Time Remaining: 06:12:46\n",
      "Mean Reward (last 1000 steps): 0.03427\n",
      "Timesteps: 360000/2000000, Remaining Timesteps: 1640000, Elapsed Time: 01:21:46, Estimated Time Remaining: 06:12:31\n",
      "Mean Reward (last 1000 steps): 0.06615\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 361000/2000000, Remaining Timesteps: 1639000, Elapsed Time: 01:22:03, Estimated Time Remaining: 06:12:31\n",
      "Mean Reward (last 1000 steps): 0.07239\n",
      "Timesteps: 362000/2000000, Remaining Timesteps: 1638000, Elapsed Time: 01:22:16, Estimated Time Remaining: 06:12:18\n",
      "Mean Reward (last 1000 steps): 0.20958\n",
      "Timesteps: 363000/2000000, Remaining Timesteps: 1637000, Elapsed Time: 01:22:34, Estimated Time Remaining: 06:12:24\n",
      "Mean Reward (last 1000 steps): -0.00364\n",
      "Timesteps: 364000/2000000, Remaining Timesteps: 1636000, Elapsed Time: 01:22:48, Estimated Time Remaining: 06:12:11\n",
      "Mean Reward (last 1000 steps): 0.33078\n",
      "Timesteps: 365000/2000000, Remaining Timesteps: 1635000, Elapsed Time: 01:23:06, Estimated Time Remaining: 06:12:16\n",
      "Mean Reward (last 1000 steps): -0.01782\n",
      "Timesteps: 366000/2000000, Remaining Timesteps: 1634000, Elapsed Time: 01:23:19, Estimated Time Remaining: 06:12:01\n",
      "Mean Reward (last 1000 steps): 0.07220\n",
      "Timesteps: 367000/2000000, Remaining Timesteps: 1633000, Elapsed Time: 01:23:36, Estimated Time Remaining: 06:12:02\n",
      "Mean Reward (last 1000 steps): 0.13191\n",
      "Timesteps: 368000/2000000, Remaining Timesteps: 1632000, Elapsed Time: 01:23:49, Estimated Time Remaining: 06:11:46\n",
      "Mean Reward (last 1000 steps): 0.01540\n",
      "Timesteps: 369000/2000000, Remaining Timesteps: 1631000, Elapsed Time: 01:24:06, Estimated Time Remaining: 06:11:46\n",
      "Mean Reward (last 1000 steps): 0.07089\n",
      "Timesteps: 370000/2000000, Remaining Timesteps: 1630000, Elapsed Time: 01:24:19, Estimated Time Remaining: 06:11:30\n",
      "Mean Reward (last 1000 steps): 0.06039\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 371000/2000000, Remaining Timesteps: 1629000, Elapsed Time: 01:24:36, Estimated Time Remaining: 06:11:31\n",
      "Mean Reward (last 1000 steps): 0.26260\n",
      "Timesteps: 372000/2000000, Remaining Timesteps: 1628000, Elapsed Time: 01:24:50, Estimated Time Remaining: 06:11:16\n",
      "Mean Reward (last 1000 steps): 0.10093\n",
      "Timesteps: 373000/2000000, Remaining Timesteps: 1627000, Elapsed Time: 01:25:07, Estimated Time Remaining: 06:11:17\n",
      "Mean Reward (last 1000 steps): 0.31225\n",
      "Timesteps: 374000/2000000, Remaining Timesteps: 1626000, Elapsed Time: 01:25:20, Estimated Time Remaining: 06:11:03\n",
      "Mean Reward (last 1000 steps): 0.20744\n",
      "Timesteps: 375000/2000000, Remaining Timesteps: 1625000, Elapsed Time: 01:25:37, Estimated Time Remaining: 06:11:02\n",
      "Mean Reward (last 1000 steps): 0.06740\n",
      "Timesteps: 376000/2000000, Remaining Timesteps: 1624000, Elapsed Time: 01:25:50, Estimated Time Remaining: 06:10:46\n",
      "Mean Reward (last 1000 steps): 0.28165\n",
      "Timesteps: 377000/2000000, Remaining Timesteps: 1623000, Elapsed Time: 01:26:07, Estimated Time Remaining: 06:10:45\n",
      "Mean Reward (last 1000 steps): 0.16255\n",
      "Timesteps: 378000/2000000, Remaining Timesteps: 1622000, Elapsed Time: 01:26:20, Estimated Time Remaining: 06:10:27\n",
      "Mean Reward (last 1000 steps): 0.31347\n",
      "Timesteps: 379000/2000000, Remaining Timesteps: 1621000, Elapsed Time: 01:26:36, Estimated Time Remaining: 06:10:27\n",
      "Mean Reward (last 1000 steps): 0.33167\n",
      "Timesteps: 380000/2000000, Remaining Timesteps: 1620000, Elapsed Time: 01:26:50, Estimated Time Remaining: 06:10:12\n",
      "Mean Reward (last 1000 steps): 0.24921\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 381000/2000000, Remaining Timesteps: 1619000, Elapsed Time: 01:27:07, Estimated Time Remaining: 06:10:14\n",
      "Mean Reward (last 1000 steps): 0.17112\n",
      "Timesteps: 382000/2000000, Remaining Timesteps: 1618000, Elapsed Time: 01:27:20, Estimated Time Remaining: 06:09:58\n",
      "Mean Reward (last 1000 steps): 0.23400\n",
      "Timesteps: 383000/2000000, Remaining Timesteps: 1617000, Elapsed Time: 01:27:38, Estimated Time Remaining: 06:10:00\n",
      "Mean Reward (last 1000 steps): 0.36839\n",
      "Timesteps: 384000/2000000, Remaining Timesteps: 1616000, Elapsed Time: 01:27:51, Estimated Time Remaining: 06:09:45\n",
      "Mean Reward (last 1000 steps): 0.17652\n",
      "Timesteps: 385000/2000000, Remaining Timesteps: 1615000, Elapsed Time: 01:28:05, Estimated Time Remaining: 06:09:29\n",
      "Mean Reward (last 1000 steps): 0.16292\n",
      "Timesteps: 386000/2000000, Remaining Timesteps: 1614000, Elapsed Time: 01:28:22, Estimated Time Remaining: 06:09:30\n",
      "Mean Reward (last 1000 steps): 0.36096\n",
      "Timesteps: 387000/2000000, Remaining Timesteps: 1613000, Elapsed Time: 01:28:35, Estimated Time Remaining: 06:09:14\n",
      "Mean Reward (last 1000 steps): 0.09740\n",
      "Timesteps: 388000/2000000, Remaining Timesteps: 1612000, Elapsed Time: 01:28:52, Estimated Time Remaining: 06:09:13\n",
      "Mean Reward (last 1000 steps): 0.52914\n",
      "Timesteps: 389000/2000000, Remaining Timesteps: 1611000, Elapsed Time: 01:29:06, Estimated Time Remaining: 06:09:02\n",
      "Mean Reward (last 1000 steps): 0.30519\n",
      "Timesteps: 390000/2000000, Remaining Timesteps: 1610000, Elapsed Time: 01:29:24, Estimated Time Remaining: 06:09:05\n",
      "Mean Reward (last 1000 steps): 0.19650\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 391000/2000000, Remaining Timesteps: 1609000, Elapsed Time: 01:29:37, Estimated Time Remaining: 06:08:49\n",
      "Mean Reward (last 1000 steps): 0.15479\n",
      "Timesteps: 392000/2000000, Remaining Timesteps: 1608000, Elapsed Time: 01:29:54, Estimated Time Remaining: 06:08:50\n",
      "Mean Reward (last 1000 steps): 0.24918\n",
      "Timesteps: 393000/2000000, Remaining Timesteps: 1607000, Elapsed Time: 01:30:08, Estimated Time Remaining: 06:08:35\n",
      "Mean Reward (last 1000 steps): 0.16901\n",
      "Timesteps: 394000/2000000, Remaining Timesteps: 1606000, Elapsed Time: 01:30:26, Estimated Time Remaining: 06:08:37\n",
      "Mean Reward (last 1000 steps): 0.03701\n",
      "Timesteps: 395000/2000000, Remaining Timesteps: 1605000, Elapsed Time: 01:30:39, Estimated Time Remaining: 06:08:21\n",
      "Mean Reward (last 1000 steps): 0.23382\n",
      "Timesteps: 396000/2000000, Remaining Timesteps: 1604000, Elapsed Time: 01:30:56, Estimated Time Remaining: 06:08:20\n",
      "Mean Reward (last 1000 steps): 0.16431\n",
      "Timesteps: 397000/2000000, Remaining Timesteps: 1603000, Elapsed Time: 01:31:09, Estimated Time Remaining: 06:08:05\n",
      "Mean Reward (last 1000 steps): 0.16376\n",
      "Timesteps: 398000/2000000, Remaining Timesteps: 1602000, Elapsed Time: 01:31:27, Estimated Time Remaining: 06:08:06\n",
      "Mean Reward (last 1000 steps): 0.18196\n",
      "Timesteps: 399000/2000000, Remaining Timesteps: 1601000, Elapsed Time: 01:31:39, Estimated Time Remaining: 06:07:48\n",
      "Mean Reward (last 1000 steps): 0.23876\n",
      "Timesteps: 400000/2000000, Remaining Timesteps: 1600000, Elapsed Time: 01:31:56, Estimated Time Remaining: 06:07:45\n",
      "Mean Reward (last 1000 steps): 0.34865\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 401000/2000000, Remaining Timesteps: 1599000, Elapsed Time: 01:32:10, Estimated Time Remaining: 06:07:31\n",
      "Mean Reward (last 1000 steps): 0.11535\n",
      "Timesteps: 402000/2000000, Remaining Timesteps: 1598000, Elapsed Time: 01:32:26, Estimated Time Remaining: 06:07:29\n",
      "Mean Reward (last 1000 steps): 0.36602\n",
      "Timesteps: 403000/2000000, Remaining Timesteps: 1597000, Elapsed Time: 01:32:39, Estimated Time Remaining: 06:07:12\n",
      "Mean Reward (last 1000 steps): 0.12753\n",
      "Timesteps: 404000/2000000, Remaining Timesteps: 1596000, Elapsed Time: 01:32:56, Estimated Time Remaining: 06:07:11\n",
      "Mean Reward (last 1000 steps): 0.10673\n",
      "Timesteps: 405000/2000000, Remaining Timesteps: 1595000, Elapsed Time: 01:33:10, Estimated Time Remaining: 06:06:55\n",
      "Mean Reward (last 1000 steps): 0.23974\n",
      "Timesteps: 406000/2000000, Remaining Timesteps: 1594000, Elapsed Time: 01:33:27, Estimated Time Remaining: 06:06:56\n",
      "Mean Reward (last 1000 steps): 0.11554\n",
      "Timesteps: 407000/2000000, Remaining Timesteps: 1593000, Elapsed Time: 01:33:41, Estimated Time Remaining: 06:06:41\n",
      "Mean Reward (last 1000 steps): 0.16346\n",
      "Timesteps: 408000/2000000, Remaining Timesteps: 1592000, Elapsed Time: 01:33:58, Estimated Time Remaining: 06:06:41\n",
      "Mean Reward (last 1000 steps): 0.10390\n",
      "Timesteps: 409000/2000000, Remaining Timesteps: 1591000, Elapsed Time: 01:34:11, Estimated Time Remaining: 06:06:26\n",
      "Mean Reward (last 1000 steps): 0.09755\n",
      "Timesteps: 410000/2000000, Remaining Timesteps: 1590000, Elapsed Time: 01:34:29, Estimated Time Remaining: 06:06:25\n",
      "Mean Reward (last 1000 steps): 0.07693\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 411000/2000000, Remaining Timesteps: 1589000, Elapsed Time: 01:34:41, Estimated Time Remaining: 06:06:07\n",
      "Mean Reward (last 1000 steps): 0.10654\n",
      "Timesteps: 412000/2000000, Remaining Timesteps: 1588000, Elapsed Time: 01:34:58, Estimated Time Remaining: 06:06:04\n",
      "Mean Reward (last 1000 steps): 0.09048\n",
      "Timesteps: 413000/2000000, Remaining Timesteps: 1587000, Elapsed Time: 01:35:11, Estimated Time Remaining: 06:05:47\n",
      "Mean Reward (last 1000 steps): 0.24286\n",
      "Timesteps: 414000/2000000, Remaining Timesteps: 1586000, Elapsed Time: 01:35:29, Estimated Time Remaining: 06:05:47\n",
      "Mean Reward (last 1000 steps): 0.40244\n",
      "Timesteps: 415000/2000000, Remaining Timesteps: 1585000, Elapsed Time: 01:35:41, Estimated Time Remaining: 06:05:30\n",
      "Mean Reward (last 1000 steps): 0.10553\n",
      "Timesteps: 416000/2000000, Remaining Timesteps: 1584000, Elapsed Time: 01:35:58, Estimated Time Remaining: 06:05:25\n",
      "Mean Reward (last 1000 steps): 0.29027\n",
      "Timesteps: 417000/2000000, Remaining Timesteps: 1583000, Elapsed Time: 01:36:11, Estimated Time Remaining: 06:05:09\n",
      "Mean Reward (last 1000 steps): 0.36609\n",
      "Timesteps: 418000/2000000, Remaining Timesteps: 1582000, Elapsed Time: 01:36:28, Estimated Time Remaining: 06:05:07\n",
      "Mean Reward (last 1000 steps): 0.17940\n",
      "Timesteps: 419000/2000000, Remaining Timesteps: 1581000, Elapsed Time: 01:36:41, Estimated Time Remaining: 06:04:51\n",
      "Mean Reward (last 1000 steps): 0.16839\n",
      "Timesteps: 420000/2000000, Remaining Timesteps: 1580000, Elapsed Time: 01:36:58, Estimated Time Remaining: 06:04:49\n",
      "Mean Reward (last 1000 steps): 0.13549\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 421000/2000000, Remaining Timesteps: 1579000, Elapsed Time: 01:37:11, Estimated Time Remaining: 06:04:33\n",
      "Mean Reward (last 1000 steps): 0.45267\n",
      "Timesteps: 422000/2000000, Remaining Timesteps: 1578000, Elapsed Time: 01:37:29, Estimated Time Remaining: 06:04:32\n",
      "Mean Reward (last 1000 steps): 0.06074\n",
      "Timesteps: 423000/2000000, Remaining Timesteps: 1577000, Elapsed Time: 01:37:42, Estimated Time Remaining: 06:04:16\n",
      "Mean Reward (last 1000 steps): 0.32053\n",
      "Timesteps: 424000/2000000, Remaining Timesteps: 1576000, Elapsed Time: 01:38:00, Estimated Time Remaining: 06:04:16\n",
      "Mean Reward (last 1000 steps): 0.45050\n",
      "Timesteps: 425000/2000000, Remaining Timesteps: 1575000, Elapsed Time: 01:38:13, Estimated Time Remaining: 06:03:59\n",
      "Mean Reward (last 1000 steps): 0.06612\n",
      "Timesteps: 426000/2000000, Remaining Timesteps: 1574000, Elapsed Time: 01:38:29, Estimated Time Remaining: 06:03:56\n",
      "Mean Reward (last 1000 steps): 0.27624\n",
      "Timesteps: 427000/2000000, Remaining Timesteps: 1573000, Elapsed Time: 01:38:43, Estimated Time Remaining: 06:03:40\n",
      "Mean Reward (last 1000 steps): 0.44776\n",
      "Timesteps: 428000/2000000, Remaining Timesteps: 1572000, Elapsed Time: 01:38:56, Estimated Time Remaining: 06:03:24\n",
      "Mean Reward (last 1000 steps): 0.17393\n",
      "Timesteps: 429000/2000000, Remaining Timesteps: 1571000, Elapsed Time: 01:39:14, Estimated Time Remaining: 06:03:24\n",
      "Mean Reward (last 1000 steps): 0.29643\n",
      "Timesteps: 430000/2000000, Remaining Timesteps: 1570000, Elapsed Time: 01:39:27, Estimated Time Remaining: 06:03:06\n",
      "Mean Reward (last 1000 steps): 0.09025\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 431000/2000000, Remaining Timesteps: 1569000, Elapsed Time: 01:39:44, Estimated Time Remaining: 06:03:04\n",
      "Mean Reward (last 1000 steps): 0.04015\n",
      "Timesteps: 432000/2000000, Remaining Timesteps: 1568000, Elapsed Time: 01:39:57, Estimated Time Remaining: 06:02:47\n",
      "Mean Reward (last 1000 steps): 0.13650\n",
      "Timesteps: 433000/2000000, Remaining Timesteps: 1567000, Elapsed Time: 01:40:13, Estimated Time Remaining: 06:02:42\n",
      "Mean Reward (last 1000 steps): 0.13335\n",
      "Timesteps: 434000/2000000, Remaining Timesteps: 1566000, Elapsed Time: 01:40:26, Estimated Time Remaining: 06:02:25\n",
      "Mean Reward (last 1000 steps): 0.18943\n",
      "Timesteps: 435000/2000000, Remaining Timesteps: 1565000, Elapsed Time: 01:40:43, Estimated Time Remaining: 06:02:21\n",
      "Mean Reward (last 1000 steps): -0.01250\n",
      "Timesteps: 436000/2000000, Remaining Timesteps: 1564000, Elapsed Time: 01:40:56, Estimated Time Remaining: 06:02:04\n",
      "Mean Reward (last 1000 steps): 0.21225\n",
      "Timesteps: 437000/2000000, Remaining Timesteps: 1563000, Elapsed Time: 01:41:13, Estimated Time Remaining: 06:02:03\n",
      "Mean Reward (last 1000 steps): -0.03584\n",
      "Timesteps: 438000/2000000, Remaining Timesteps: 1562000, Elapsed Time: 01:41:26, Estimated Time Remaining: 06:01:47\n",
      "Mean Reward (last 1000 steps): 0.31462\n",
      "Timesteps: 439000/2000000, Remaining Timesteps: 1561000, Elapsed Time: 01:41:43, Estimated Time Remaining: 06:01:42\n",
      "Mean Reward (last 1000 steps): -0.04478\n",
      "Timesteps: 440000/2000000, Remaining Timesteps: 1560000, Elapsed Time: 01:41:56, Estimated Time Remaining: 06:01:25\n",
      "Mean Reward (last 1000 steps): 0.23919\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 441000/2000000, Remaining Timesteps: 1559000, Elapsed Time: 01:42:13, Estimated Time Remaining: 06:01:21\n",
      "Mean Reward (last 1000 steps): 0.23579\n",
      "Timesteps: 442000/2000000, Remaining Timesteps: 1558000, Elapsed Time: 01:42:25, Estimated Time Remaining: 06:01:03\n",
      "Mean Reward (last 1000 steps): -0.12980\n",
      "Timesteps: 443000/2000000, Remaining Timesteps: 1557000, Elapsed Time: 01:42:42, Estimated Time Remaining: 06:00:58\n",
      "Mean Reward (last 1000 steps): 0.13779\n",
      "Timesteps: 444000/2000000, Remaining Timesteps: 1556000, Elapsed Time: 01:42:55, Estimated Time Remaining: 06:00:41\n",
      "Mean Reward (last 1000 steps): -0.00410\n",
      "Timesteps: 445000/2000000, Remaining Timesteps: 1555000, Elapsed Time: 01:43:12, Estimated Time Remaining: 06:00:38\n",
      "Mean Reward (last 1000 steps): 0.04615\n",
      "Timesteps: 446000/2000000, Remaining Timesteps: 1554000, Elapsed Time: 01:43:25, Estimated Time Remaining: 06:00:21\n",
      "Mean Reward (last 1000 steps): -0.04403\n",
      "Timesteps: 447000/2000000, Remaining Timesteps: 1553000, Elapsed Time: 01:43:42, Estimated Time Remaining: 06:00:19\n",
      "Mean Reward (last 1000 steps): 0.10739\n",
      "Timesteps: 448000/2000000, Remaining Timesteps: 1552000, Elapsed Time: 01:43:56, Estimated Time Remaining: 06:00:03\n",
      "Mean Reward (last 1000 steps): -0.02260\n",
      "Timesteps: 449000/2000000, Remaining Timesteps: 1551000, Elapsed Time: 01:44:13, Estimated Time Remaining: 06:00:01\n",
      "Mean Reward (last 1000 steps): 0.24496\n",
      "Timesteps: 450000/2000000, Remaining Timesteps: 1550000, Elapsed Time: 01:44:26, Estimated Time Remaining: 05:59:44\n",
      "Mean Reward (last 1000 steps): 0.27058\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 451000/2000000, Remaining Timesteps: 1549000, Elapsed Time: 01:44:43, Estimated Time Remaining: 05:59:41\n",
      "Mean Reward (last 1000 steps): 0.02753\n",
      "Timesteps: 452000/2000000, Remaining Timesteps: 1548000, Elapsed Time: 01:44:56, Estimated Time Remaining: 05:59:25\n",
      "Mean Reward (last 1000 steps): -0.02811\n",
      "Timesteps: 453000/2000000, Remaining Timesteps: 1547000, Elapsed Time: 01:45:13, Estimated Time Remaining: 05:59:21\n",
      "Mean Reward (last 1000 steps): 0.16930\n",
      "Timesteps: 454000/2000000, Remaining Timesteps: 1546000, Elapsed Time: 01:45:27, Estimated Time Remaining: 05:59:06\n",
      "Mean Reward (last 1000 steps): -0.04828\n",
      "Timesteps: 455000/2000000, Remaining Timesteps: 1545000, Elapsed Time: 01:45:44, Estimated Time Remaining: 05:59:03\n",
      "Mean Reward (last 1000 steps): -0.01762\n",
      "Timesteps: 456000/2000000, Remaining Timesteps: 1544000, Elapsed Time: 01:45:57, Estimated Time Remaining: 05:58:46\n",
      "Mean Reward (last 1000 steps): -0.05457\n",
      "Timesteps: 457000/2000000, Remaining Timesteps: 1543000, Elapsed Time: 01:46:14, Estimated Time Remaining: 05:58:43\n",
      "Mean Reward (last 1000 steps): 0.10748\n",
      "Timesteps: 458000/2000000, Remaining Timesteps: 1542000, Elapsed Time: 01:46:28, Estimated Time Remaining: 05:58:28\n",
      "Mean Reward (last 1000 steps): 0.19731\n",
      "Timesteps: 459000/2000000, Remaining Timesteps: 1541000, Elapsed Time: 01:46:45, Estimated Time Remaining: 05:58:25\n",
      "Mean Reward (last 1000 steps): 0.14636\n",
      "Timesteps: 460000/2000000, Remaining Timesteps: 1540000, Elapsed Time: 01:46:59, Estimated Time Remaining: 05:58:10\n",
      "Mean Reward (last 1000 steps): 0.10058\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 461000/2000000, Remaining Timesteps: 1539000, Elapsed Time: 01:47:17, Estimated Time Remaining: 05:58:09\n",
      "Mean Reward (last 1000 steps): 0.12455\n",
      "Timesteps: 462000/2000000, Remaining Timesteps: 1538000, Elapsed Time: 01:47:30, Estimated Time Remaining: 05:57:53\n",
      "Mean Reward (last 1000 steps): 0.09851\n",
      "Timesteps: 463000/2000000, Remaining Timesteps: 1537000, Elapsed Time: 01:47:47, Estimated Time Remaining: 05:57:49\n",
      "Mean Reward (last 1000 steps): 0.23934\n",
      "Timesteps: 464000/2000000, Remaining Timesteps: 1536000, Elapsed Time: 01:48:00, Estimated Time Remaining: 05:57:33\n",
      "Mean Reward (last 1000 steps): 0.11648\n",
      "Timesteps: 465000/2000000, Remaining Timesteps: 1535000, Elapsed Time: 01:48:17, Estimated Time Remaining: 05:57:29\n",
      "Mean Reward (last 1000 steps): 0.05928\n",
      "Timesteps: 466000/2000000, Remaining Timesteps: 1534000, Elapsed Time: 01:48:30, Estimated Time Remaining: 05:57:13\n",
      "Mean Reward (last 1000 steps): 0.11284\n",
      "Timesteps: 467000/2000000, Remaining Timesteps: 1533000, Elapsed Time: 01:48:48, Estimated Time Remaining: 05:57:11\n",
      "Mean Reward (last 1000 steps): 0.06395\n",
      "Timesteps: 468000/2000000, Remaining Timesteps: 1532000, Elapsed Time: 01:49:01, Estimated Time Remaining: 05:56:53\n",
      "Mean Reward (last 1000 steps): -0.02500\n",
      "Timesteps: 469000/2000000, Remaining Timesteps: 1531000, Elapsed Time: 01:49:18, Estimated Time Remaining: 05:56:50\n",
      "Mean Reward (last 1000 steps): 0.39031\n",
      "Timesteps: 470000/2000000, Remaining Timesteps: 1530000, Elapsed Time: 01:49:31, Estimated Time Remaining: 05:56:33\n",
      "Mean Reward (last 1000 steps): 0.07169\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 471000/2000000, Remaining Timesteps: 1529000, Elapsed Time: 01:49:45, Estimated Time Remaining: 05:56:16\n",
      "Mean Reward (last 1000 steps): -0.03841\n",
      "Timesteps: 472000/2000000, Remaining Timesteps: 1528000, Elapsed Time: 01:50:02, Estimated Time Remaining: 05:56:12\n",
      "Mean Reward (last 1000 steps): 0.30448\n",
      "Timesteps: 473000/2000000, Remaining Timesteps: 1527000, Elapsed Time: 01:50:15, Estimated Time Remaining: 05:55:55\n",
      "Mean Reward (last 1000 steps): 0.27075\n",
      "Timesteps: 474000/2000000, Remaining Timesteps: 1526000, Elapsed Time: 01:50:32, Estimated Time Remaining: 05:55:51\n",
      "Mean Reward (last 1000 steps): -0.01608\n",
      "Timesteps: 475000/2000000, Remaining Timesteps: 1525000, Elapsed Time: 01:50:45, Estimated Time Remaining: 05:55:34\n",
      "Mean Reward (last 1000 steps): 0.32908\n",
      "Timesteps: 476000/2000000, Remaining Timesteps: 1524000, Elapsed Time: 01:51:02, Estimated Time Remaining: 05:55:30\n",
      "Mean Reward (last 1000 steps): 0.03925\n",
      "Timesteps: 477000/2000000, Remaining Timesteps: 1523000, Elapsed Time: 01:51:15, Estimated Time Remaining: 05:55:13\n",
      "Mean Reward (last 1000 steps): -0.01892\n",
      "Timesteps: 478000/2000000, Remaining Timesteps: 1522000, Elapsed Time: 01:51:32, Estimated Time Remaining: 05:55:10\n",
      "Mean Reward (last 1000 steps): -0.00016\n",
      "Timesteps: 479000/2000000, Remaining Timesteps: 1521000, Elapsed Time: 01:51:45, Estimated Time Remaining: 05:54:52\n",
      "Mean Reward (last 1000 steps): 0.11672\n",
      "Timesteps: 480000/2000000, Remaining Timesteps: 1520000, Elapsed Time: 01:52:02, Estimated Time Remaining: 05:54:47\n",
      "Mean Reward (last 1000 steps): -0.01263\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 481000/2000000, Remaining Timesteps: 1519000, Elapsed Time: 01:52:15, Estimated Time Remaining: 05:54:30\n",
      "Mean Reward (last 1000 steps): -0.02209\n",
      "Timesteps: 482000/2000000, Remaining Timesteps: 1518000, Elapsed Time: 01:52:32, Estimated Time Remaining: 05:54:26\n",
      "Mean Reward (last 1000 steps): 0.03259\n",
      "Timesteps: 483000/2000000, Remaining Timesteps: 1517000, Elapsed Time: 01:52:46, Estimated Time Remaining: 05:54:11\n",
      "Mean Reward (last 1000 steps): 0.15111\n",
      "Timesteps: 484000/2000000, Remaining Timesteps: 1516000, Elapsed Time: 01:53:04, Estimated Time Remaining: 05:54:09\n",
      "Mean Reward (last 1000 steps): 0.10602\n",
      "Timesteps: 485000/2000000, Remaining Timesteps: 1515000, Elapsed Time: 01:53:17, Estimated Time Remaining: 05:53:53\n",
      "Mean Reward (last 1000 steps): -0.04134\n",
      "Timesteps: 486000/2000000, Remaining Timesteps: 1514000, Elapsed Time: 01:53:34, Estimated Time Remaining: 05:53:47\n",
      "Mean Reward (last 1000 steps): 0.31727\n",
      "Timesteps: 487000/2000000, Remaining Timesteps: 1513000, Elapsed Time: 01:53:47, Estimated Time Remaining: 05:53:30\n",
      "Mean Reward (last 1000 steps): 0.28156\n",
      "Timesteps: 488000/2000000, Remaining Timesteps: 1512000, Elapsed Time: 01:54:04, Estimated Time Remaining: 05:53:25\n",
      "Mean Reward (last 1000 steps): 0.23624\n",
      "Timesteps: 489000/2000000, Remaining Timesteps: 1511000, Elapsed Time: 01:54:17, Estimated Time Remaining: 05:53:09\n",
      "Mean Reward (last 1000 steps): 0.04293\n",
      "Timesteps: 490000/2000000, Remaining Timesteps: 1510000, Elapsed Time: 01:54:34, Estimated Time Remaining: 05:53:04\n",
      "Mean Reward (last 1000 steps): 0.23605\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 491000/2000000, Remaining Timesteps: 1509000, Elapsed Time: 01:54:48, Estimated Time Remaining: 05:52:50\n",
      "Mean Reward (last 1000 steps): 0.06286\n",
      "Timesteps: 492000/2000000, Remaining Timesteps: 1508000, Elapsed Time: 01:55:05, Estimated Time Remaining: 05:52:46\n",
      "Mean Reward (last 1000 steps): -0.00354\n",
      "Timesteps: 493000/2000000, Remaining Timesteps: 1507000, Elapsed Time: 01:55:19, Estimated Time Remaining: 05:52:31\n",
      "Mean Reward (last 1000 steps): 0.39805\n",
      "Timesteps: 494000/2000000, Remaining Timesteps: 1506000, Elapsed Time: 01:55:36, Estimated Time Remaining: 05:52:25\n",
      "Mean Reward (last 1000 steps): 0.19770\n",
      "Timesteps: 495000/2000000, Remaining Timesteps: 1505000, Elapsed Time: 01:55:49, Estimated Time Remaining: 05:52:09\n",
      "Mean Reward (last 1000 steps): -0.04565\n",
      "Timesteps: 496000/2000000, Remaining Timesteps: 1504000, Elapsed Time: 01:56:06, Estimated Time Remaining: 05:52:04\n",
      "Mean Reward (last 1000 steps): -0.04649\n",
      "Timesteps: 497000/2000000, Remaining Timesteps: 1503000, Elapsed Time: 01:56:20, Estimated Time Remaining: 05:51:49\n",
      "Mean Reward (last 1000 steps): 0.30203\n",
      "Timesteps: 498000/2000000, Remaining Timesteps: 1502000, Elapsed Time: 01:56:37, Estimated Time Remaining: 05:51:44\n",
      "Mean Reward (last 1000 steps): 0.06433\n",
      "Timesteps: 499000/2000000, Remaining Timesteps: 1501000, Elapsed Time: 01:56:50, Estimated Time Remaining: 05:51:28\n",
      "Mean Reward (last 1000 steps): -0.04148\n",
      "Timesteps: 500000/2000000, Remaining Timesteps: 1500000, Elapsed Time: 01:57:08, Estimated Time Remaining: 05:51:24\n",
      "Mean Reward (last 1000 steps): 0.08156\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 501000/2000000, Remaining Timesteps: 1499000, Elapsed Time: 01:57:22, Estimated Time Remaining: 05:51:11\n",
      "Mean Reward (last 1000 steps): 0.17302\n",
      "Timesteps: 502000/2000000, Remaining Timesteps: 1498000, Elapsed Time: 01:57:39, Estimated Time Remaining: 05:51:07\n",
      "Mean Reward (last 1000 steps): 0.35859\n",
      "Timesteps: 503000/2000000, Remaining Timesteps: 1497000, Elapsed Time: 01:57:53, Estimated Time Remaining: 05:50:51\n",
      "Mean Reward (last 1000 steps): 0.02772\n",
      "Timesteps: 504000/2000000, Remaining Timesteps: 1496000, Elapsed Time: 01:58:10, Estimated Time Remaining: 05:50:47\n",
      "Mean Reward (last 1000 steps): 0.10388\n",
      "Timesteps: 505000/2000000, Remaining Timesteps: 1495000, Elapsed Time: 01:58:24, Estimated Time Remaining: 05:50:32\n",
      "Mean Reward (last 1000 steps): 0.36031\n",
      "Timesteps: 506000/2000000, Remaining Timesteps: 1494000, Elapsed Time: 01:58:42, Estimated Time Remaining: 05:50:29\n",
      "Mean Reward (last 1000 steps): 0.26496\n",
      "Timesteps: 507000/2000000, Remaining Timesteps: 1493000, Elapsed Time: 01:58:55, Estimated Time Remaining: 05:50:11\n",
      "Mean Reward (last 1000 steps): 0.20451\n",
      "Timesteps: 508000/2000000, Remaining Timesteps: 1492000, Elapsed Time: 01:59:13, Estimated Time Remaining: 05:50:08\n",
      "Mean Reward (last 1000 steps): 0.24914\n",
      "Timesteps: 509000/2000000, Remaining Timesteps: 1491000, Elapsed Time: 01:59:26, Estimated Time Remaining: 05:49:52\n",
      "Mean Reward (last 1000 steps): 0.01196\n",
      "Timesteps: 510000/2000000, Remaining Timesteps: 1490000, Elapsed Time: 01:59:43, Estimated Time Remaining: 05:49:48\n",
      "Mean Reward (last 1000 steps): 0.29150\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 511000/2000000, Remaining Timesteps: 1489000, Elapsed Time: 01:59:57, Estimated Time Remaining: 05:49:32\n",
      "Mean Reward (last 1000 steps): -0.02410\n",
      "Timesteps: 512000/2000000, Remaining Timesteps: 1488000, Elapsed Time: 02:00:22, Estimated Time Remaining: 05:49:48\n",
      "Mean Reward (last 1000 steps): -0.04585\n",
      "Timesteps: 513000/2000000, Remaining Timesteps: 1487000, Elapsed Time: 02:00:42, Estimated Time Remaining: 05:49:52\n",
      "Mean Reward (last 1000 steps): -0.07445\n",
      "Timesteps: 514000/2000000, Remaining Timesteps: 1486000, Elapsed Time: 02:00:55, Estimated Time Remaining: 05:49:35\n",
      "Mean Reward (last 1000 steps): -0.01729\n",
      "Timesteps: 515000/2000000, Remaining Timesteps: 1485000, Elapsed Time: 02:01:12, Estimated Time Remaining: 05:49:28\n",
      "Mean Reward (last 1000 steps): 0.18889\n",
      "Timesteps: 516000/2000000, Remaining Timesteps: 1484000, Elapsed Time: 02:01:24, Estimated Time Remaining: 05:49:11\n",
      "Mean Reward (last 1000 steps): 0.06667\n",
      "Timesteps: 517000/2000000, Remaining Timesteps: 1483000, Elapsed Time: 02:01:42, Estimated Time Remaining: 05:49:06\n",
      "Mean Reward (last 1000 steps): -0.07039\n",
      "Timesteps: 518000/2000000, Remaining Timesteps: 1482000, Elapsed Time: 02:01:55, Estimated Time Remaining: 05:48:50\n",
      "Mean Reward (last 1000 steps): -0.04631\n",
      "Timesteps: 519000/2000000, Remaining Timesteps: 1481000, Elapsed Time: 02:02:14, Estimated Time Remaining: 05:48:48\n",
      "Mean Reward (last 1000 steps): 0.10882\n",
      "Timesteps: 520000/2000000, Remaining Timesteps: 1480000, Elapsed Time: 02:02:27, Estimated Time Remaining: 05:48:32\n",
      "Mean Reward (last 1000 steps): 0.20921\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 521000/2000000, Remaining Timesteps: 1479000, Elapsed Time: 02:02:44, Estimated Time Remaining: 05:48:27\n",
      "Mean Reward (last 1000 steps): 0.30982\n",
      "Timesteps: 522000/2000000, Remaining Timesteps: 1478000, Elapsed Time: 02:02:58, Estimated Time Remaining: 05:48:10\n",
      "Mean Reward (last 1000 steps): -0.03208\n",
      "Timesteps: 523000/2000000, Remaining Timesteps: 1477000, Elapsed Time: 02:03:15, Estimated Time Remaining: 05:48:06\n",
      "Mean Reward (last 1000 steps): 0.11726\n",
      "Timesteps: 524000/2000000, Remaining Timesteps: 1476000, Elapsed Time: 02:03:28, Estimated Time Remaining: 05:47:49\n",
      "Mean Reward (last 1000 steps): -0.05829\n",
      "Timesteps: 525000/2000000, Remaining Timesteps: 1475000, Elapsed Time: 02:03:45, Estimated Time Remaining: 05:47:43\n",
      "Mean Reward (last 1000 steps): 0.00032\n",
      "Timesteps: 526000/2000000, Remaining Timesteps: 1474000, Elapsed Time: 02:03:59, Estimated Time Remaining: 05:47:26\n",
      "Mean Reward (last 1000 steps): -0.03502\n",
      "Timesteps: 527000/2000000, Remaining Timesteps: 1473000, Elapsed Time: 02:04:16, Estimated Time Remaining: 05:47:20\n",
      "Mean Reward (last 1000 steps): 0.00792\n",
      "Timesteps: 528000/2000000, Remaining Timesteps: 1472000, Elapsed Time: 02:04:29, Estimated Time Remaining: 05:47:05\n",
      "Mean Reward (last 1000 steps): 0.13003\n",
      "Timesteps: 529000/2000000, Remaining Timesteps: 1471000, Elapsed Time: 02:04:47, Estimated Time Remaining: 05:46:59\n",
      "Mean Reward (last 1000 steps): -0.03515\n",
      "Timesteps: 530000/2000000, Remaining Timesteps: 1470000, Elapsed Time: 02:05:01, Estimated Time Remaining: 05:46:45\n",
      "Mean Reward (last 1000 steps): 0.11958\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 531000/2000000, Remaining Timesteps: 1469000, Elapsed Time: 02:05:18, Estimated Time Remaining: 05:46:40\n",
      "Mean Reward (last 1000 steps): 0.11753\n",
      "Timesteps: 532000/2000000, Remaining Timesteps: 1468000, Elapsed Time: 02:05:31, Estimated Time Remaining: 05:46:21\n",
      "Mean Reward (last 1000 steps): -0.00451\n",
      "Timesteps: 533000/2000000, Remaining Timesteps: 1467000, Elapsed Time: 02:05:48, Estimated Time Remaining: 05:46:14\n",
      "Mean Reward (last 1000 steps): 0.28633\n",
      "Timesteps: 534000/2000000, Remaining Timesteps: 1466000, Elapsed Time: 02:06:01, Estimated Time Remaining: 05:45:58\n",
      "Mean Reward (last 1000 steps): 0.01087\n",
      "Timesteps: 535000/2000000, Remaining Timesteps: 1465000, Elapsed Time: 02:06:18, Estimated Time Remaining: 05:45:51\n",
      "Mean Reward (last 1000 steps): 0.05181\n",
      "Timesteps: 536000/2000000, Remaining Timesteps: 1464000, Elapsed Time: 02:06:31, Estimated Time Remaining: 05:45:35\n",
      "Mean Reward (last 1000 steps): 0.17759\n",
      "Timesteps: 537000/2000000, Remaining Timesteps: 1463000, Elapsed Time: 02:06:49, Estimated Time Remaining: 05:45:30\n",
      "Mean Reward (last 1000 steps): 0.01407\n",
      "Timesteps: 538000/2000000, Remaining Timesteps: 1462000, Elapsed Time: 02:07:02, Estimated Time Remaining: 05:45:14\n",
      "Mean Reward (last 1000 steps): -0.05890\n",
      "Timesteps: 539000/2000000, Remaining Timesteps: 1461000, Elapsed Time: 02:07:18, Estimated Time Remaining: 05:45:06\n",
      "Mean Reward (last 1000 steps): -0.05705\n",
      "Timesteps: 540000/2000000, Remaining Timesteps: 1460000, Elapsed Time: 02:07:32, Estimated Time Remaining: 05:44:49\n",
      "Mean Reward (last 1000 steps): 0.28083\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 541000/2000000, Remaining Timesteps: 1459000, Elapsed Time: 02:07:48, Estimated Time Remaining: 05:44:41\n",
      "Mean Reward (last 1000 steps): 0.23920\n",
      "Timesteps: 542000/2000000, Remaining Timesteps: 1458000, Elapsed Time: 02:08:01, Estimated Time Remaining: 05:44:23\n",
      "Mean Reward (last 1000 steps): 0.18151\n",
      "Timesteps: 543000/2000000, Remaining Timesteps: 1457000, Elapsed Time: 02:08:19, Estimated Time Remaining: 05:44:18\n",
      "Mean Reward (last 1000 steps): -0.01159\n",
      "Timesteps: 544000/2000000, Remaining Timesteps: 1456000, Elapsed Time: 02:08:32, Estimated Time Remaining: 05:44:01\n",
      "Mean Reward (last 1000 steps): 0.02996\n",
      "Timesteps: 545000/2000000, Remaining Timesteps: 1455000, Elapsed Time: 02:08:49, Estimated Time Remaining: 05:43:55\n",
      "Mean Reward (last 1000 steps): 0.07857\n",
      "Timesteps: 546000/2000000, Remaining Timesteps: 1454000, Elapsed Time: 02:09:02, Estimated Time Remaining: 05:43:37\n",
      "Mean Reward (last 1000 steps): 0.32577\n",
      "Timesteps: 547000/2000000, Remaining Timesteps: 1453000, Elapsed Time: 02:09:19, Estimated Time Remaining: 05:43:30\n",
      "Mean Reward (last 1000 steps): 0.54913\n",
      "Timesteps: 548000/2000000, Remaining Timesteps: 1452000, Elapsed Time: 02:09:31, Estimated Time Remaining: 05:43:10\n",
      "Mean Reward (last 1000 steps): 0.58472\n",
      "Timesteps: 549000/2000000, Remaining Timesteps: 1451000, Elapsed Time: 02:09:47, Estimated Time Remaining: 05:43:02\n",
      "Mean Reward (last 1000 steps): 0.15178\n",
      "Timesteps: 550000/2000000, Remaining Timesteps: 1450000, Elapsed Time: 02:10:00, Estimated Time Remaining: 05:42:45\n",
      "Mean Reward (last 1000 steps): 0.45404\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 551000/2000000, Remaining Timesteps: 1449000, Elapsed Time: 02:10:18, Estimated Time Remaining: 05:42:40\n",
      "Mean Reward (last 1000 steps): 0.27736\n",
      "Timesteps: 552000/2000000, Remaining Timesteps: 1448000, Elapsed Time: 02:10:32, Estimated Time Remaining: 05:42:25\n",
      "Mean Reward (last 1000 steps): 0.07875\n",
      "Timesteps: 553000/2000000, Remaining Timesteps: 1447000, Elapsed Time: 02:10:50, Estimated Time Remaining: 05:42:21\n",
      "Mean Reward (last 1000 steps): -0.04526\n",
      "Timesteps: 554000/2000000, Remaining Timesteps: 1446000, Elapsed Time: 02:11:03, Estimated Time Remaining: 05:42:05\n",
      "Mean Reward (last 1000 steps): 0.18490\n",
      "Timesteps: 555000/2000000, Remaining Timesteps: 1445000, Elapsed Time: 02:11:18, Estimated Time Remaining: 05:41:52\n",
      "Mean Reward (last 1000 steps): 0.08649\n",
      "Timesteps: 556000/2000000, Remaining Timesteps: 1444000, Elapsed Time: 02:11:36, Estimated Time Remaining: 05:41:49\n",
      "Mean Reward (last 1000 steps): 0.36172\n",
      "Timesteps: 557000/2000000, Remaining Timesteps: 1443000, Elapsed Time: 02:11:49, Estimated Time Remaining: 05:41:31\n",
      "Mean Reward (last 1000 steps): 0.05078\n",
      "Timesteps: 558000/2000000, Remaining Timesteps: 1442000, Elapsed Time: 02:12:06, Estimated Time Remaining: 05:41:24\n",
      "Mean Reward (last 1000 steps): -0.00034\n",
      "Timesteps: 559000/2000000, Remaining Timesteps: 1441000, Elapsed Time: 02:12:20, Estimated Time Remaining: 05:41:08\n",
      "Mean Reward (last 1000 steps): 0.06411\n",
      "Timesteps: 560000/2000000, Remaining Timesteps: 1440000, Elapsed Time: 02:12:37, Estimated Time Remaining: 05:41:02\n",
      "Mean Reward (last 1000 steps): 0.04866\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 561000/2000000, Remaining Timesteps: 1439000, Elapsed Time: 02:12:50, Estimated Time Remaining: 05:40:44\n",
      "Mean Reward (last 1000 steps): -0.01321\n",
      "Timesteps: 562000/2000000, Remaining Timesteps: 1438000, Elapsed Time: 02:13:07, Estimated Time Remaining: 05:40:38\n",
      "Mean Reward (last 1000 steps): 0.07742\n",
      "Timesteps: 563000/2000000, Remaining Timesteps: 1437000, Elapsed Time: 02:13:20, Estimated Time Remaining: 05:40:21\n",
      "Mean Reward (last 1000 steps): 0.25272\n",
      "Timesteps: 564000/2000000, Remaining Timesteps: 1436000, Elapsed Time: 02:13:38, Estimated Time Remaining: 05:40:15\n",
      "Mean Reward (last 1000 steps): 0.33923\n",
      "Timesteps: 565000/2000000, Remaining Timesteps: 1435000, Elapsed Time: 02:13:50, Estimated Time Remaining: 05:39:56\n",
      "Mean Reward (last 1000 steps): 0.00821\n",
      "Timesteps: 566000/2000000, Remaining Timesteps: 1434000, Elapsed Time: 02:14:08, Estimated Time Remaining: 05:39:51\n",
      "Mean Reward (last 1000 steps): 0.09997\n",
      "Timesteps: 567000/2000000, Remaining Timesteps: 1433000, Elapsed Time: 02:14:21, Estimated Time Remaining: 05:39:33\n",
      "Mean Reward (last 1000 steps): 0.03480\n",
      "Timesteps: 568000/2000000, Remaining Timesteps: 1432000, Elapsed Time: 02:14:38, Estimated Time Remaining: 05:39:27\n",
      "Mean Reward (last 1000 steps): 0.07212\n",
      "Timesteps: 569000/2000000, Remaining Timesteps: 1431000, Elapsed Time: 02:14:51, Estimated Time Remaining: 05:39:09\n",
      "Mean Reward (last 1000 steps): 0.24842\n",
      "Timesteps: 570000/2000000, Remaining Timesteps: 1430000, Elapsed Time: 02:15:09, Estimated Time Remaining: 05:39:03\n",
      "Mean Reward (last 1000 steps): -0.01569\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 571000/2000000, Remaining Timesteps: 1429000, Elapsed Time: 02:15:22, Estimated Time Remaining: 05:38:46\n",
      "Mean Reward (last 1000 steps): -0.01194\n",
      "Timesteps: 572000/2000000, Remaining Timesteps: 1428000, Elapsed Time: 02:15:40, Estimated Time Remaining: 05:38:41\n",
      "Mean Reward (last 1000 steps): 0.24130\n",
      "Timesteps: 573000/2000000, Remaining Timesteps: 1427000, Elapsed Time: 02:15:52, Estimated Time Remaining: 05:38:24\n",
      "Mean Reward (last 1000 steps): 0.14438\n",
      "Timesteps: 574000/2000000, Remaining Timesteps: 1426000, Elapsed Time: 02:16:09, Estimated Time Remaining: 05:38:15\n",
      "Mean Reward (last 1000 steps): 0.14192\n",
      "Timesteps: 575000/2000000, Remaining Timesteps: 1425000, Elapsed Time: 02:16:21, Estimated Time Remaining: 05:37:56\n",
      "Mean Reward (last 1000 steps): 0.22234\n",
      "Timesteps: 576000/2000000, Remaining Timesteps: 1424000, Elapsed Time: 02:16:38, Estimated Time Remaining: 05:37:47\n",
      "Mean Reward (last 1000 steps): 0.41067\n",
      "Timesteps: 577000/2000000, Remaining Timesteps: 1423000, Elapsed Time: 02:16:50, Estimated Time Remaining: 05:37:29\n",
      "Mean Reward (last 1000 steps): 0.19882\n",
      "Timesteps: 578000/2000000, Remaining Timesteps: 1422000, Elapsed Time: 02:17:07, Estimated Time Remaining: 05:37:20\n",
      "Mean Reward (last 1000 steps): -0.07049\n",
      "Timesteps: 579000/2000000, Remaining Timesteps: 1421000, Elapsed Time: 02:17:20, Estimated Time Remaining: 05:37:03\n",
      "Mean Reward (last 1000 steps): 0.08681\n",
      "Timesteps: 580000/2000000, Remaining Timesteps: 1420000, Elapsed Time: 02:17:36, Estimated Time Remaining: 05:36:54\n",
      "Mean Reward (last 1000 steps): -0.01826\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 581000/2000000, Remaining Timesteps: 1419000, Elapsed Time: 02:17:49, Estimated Time Remaining: 05:36:37\n",
      "Mean Reward (last 1000 steps): 0.07041\n",
      "Timesteps: 582000/2000000, Remaining Timesteps: 1418000, Elapsed Time: 02:18:06, Estimated Time Remaining: 05:36:29\n",
      "Mean Reward (last 1000 steps): 0.13151\n",
      "Timesteps: 583000/2000000, Remaining Timesteps: 1417000, Elapsed Time: 02:18:19, Estimated Time Remaining: 05:36:12\n",
      "Mean Reward (last 1000 steps): 0.01719\n",
      "Timesteps: 584000/2000000, Remaining Timesteps: 1416000, Elapsed Time: 02:18:35, Estimated Time Remaining: 05:36:02\n",
      "Mean Reward (last 1000 steps): 0.21481\n",
      "Timesteps: 585000/2000000, Remaining Timesteps: 1415000, Elapsed Time: 02:18:48, Estimated Time Remaining: 05:35:44\n",
      "Mean Reward (last 1000 steps): 0.07545\n",
      "Timesteps: 586000/2000000, Remaining Timesteps: 1414000, Elapsed Time: 02:19:05, Estimated Time Remaining: 05:35:36\n",
      "Mean Reward (last 1000 steps): -0.06739\n",
      "Timesteps: 587000/2000000, Remaining Timesteps: 1413000, Elapsed Time: 02:19:18, Estimated Time Remaining: 05:35:19\n",
      "Mean Reward (last 1000 steps): -0.04585\n",
      "Timesteps: 588000/2000000, Remaining Timesteps: 1412000, Elapsed Time: 02:19:34, Estimated Time Remaining: 05:35:10\n",
      "Mean Reward (last 1000 steps): -0.05935\n",
      "Timesteps: 589000/2000000, Remaining Timesteps: 1411000, Elapsed Time: 02:19:47, Estimated Time Remaining: 05:34:52\n",
      "Mean Reward (last 1000 steps): -0.04464\n",
      "Timesteps: 590000/2000000, Remaining Timesteps: 1410000, Elapsed Time: 02:20:04, Estimated Time Remaining: 05:34:46\n",
      "Mean Reward (last 1000 steps): 0.09928\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 591000/2000000, Remaining Timesteps: 1409000, Elapsed Time: 02:20:18, Estimated Time Remaining: 05:34:30\n",
      "Mean Reward (last 1000 steps): -0.01093\n",
      "Timesteps: 592000/2000000, Remaining Timesteps: 1408000, Elapsed Time: 02:20:36, Estimated Time Remaining: 05:34:24\n",
      "Mean Reward (last 1000 steps): 0.01348\n",
      "Timesteps: 593000/2000000, Remaining Timesteps: 1407000, Elapsed Time: 02:20:48, Estimated Time Remaining: 05:34:06\n",
      "Mean Reward (last 1000 steps): -0.01441\n",
      "Timesteps: 594000/2000000, Remaining Timesteps: 1406000, Elapsed Time: 02:21:05, Estimated Time Remaining: 05:33:58\n",
      "Mean Reward (last 1000 steps): 0.16937\n",
      "Timesteps: 595000/2000000, Remaining Timesteps: 1405000, Elapsed Time: 02:21:18, Estimated Time Remaining: 05:33:41\n",
      "Mean Reward (last 1000 steps): 0.14305\n",
      "Timesteps: 596000/2000000, Remaining Timesteps: 1404000, Elapsed Time: 02:21:36, Estimated Time Remaining: 05:33:34\n",
      "Mean Reward (last 1000 steps): -0.00988\n",
      "Timesteps: 597000/2000000, Remaining Timesteps: 1403000, Elapsed Time: 02:21:49, Estimated Time Remaining: 05:33:18\n",
      "Mean Reward (last 1000 steps): -0.00753\n",
      "Timesteps: 598000/2000000, Remaining Timesteps: 1402000, Elapsed Time: 02:22:02, Estimated Time Remaining: 05:33:01\n",
      "Mean Reward (last 1000 steps): 0.18755\n",
      "Timesteps: 599000/2000000, Remaining Timesteps: 1401000, Elapsed Time: 02:22:21, Estimated Time Remaining: 05:32:56\n",
      "Mean Reward (last 1000 steps): 0.00214\n",
      "Timesteps: 600000/2000000, Remaining Timesteps: 1400000, Elapsed Time: 02:22:35, Estimated Time Remaining: 05:32:41\n",
      "Mean Reward (last 1000 steps): 0.03443\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 601000/2000000, Remaining Timesteps: 1399000, Elapsed Time: 02:22:52, Estimated Time Remaining: 05:32:35\n",
      "Mean Reward (last 1000 steps): -0.03524\n",
      "Timesteps: 602000/2000000, Remaining Timesteps: 1398000, Elapsed Time: 02:23:06, Estimated Time Remaining: 05:32:19\n",
      "Mean Reward (last 1000 steps): -0.07020\n",
      "Timesteps: 603000/2000000, Remaining Timesteps: 1397000, Elapsed Time: 02:23:24, Estimated Time Remaining: 05:32:13\n",
      "Mean Reward (last 1000 steps): -0.05819\n",
      "Timesteps: 604000/2000000, Remaining Timesteps: 1396000, Elapsed Time: 02:23:37, Estimated Time Remaining: 05:31:58\n",
      "Mean Reward (last 1000 steps): -0.05820\n",
      "Timesteps: 605000/2000000, Remaining Timesteps: 1395000, Elapsed Time: 02:23:55, Estimated Time Remaining: 05:31:52\n",
      "Mean Reward (last 1000 steps): 0.00175\n",
      "Timesteps: 606000/2000000, Remaining Timesteps: 1394000, Elapsed Time: 02:24:08, Estimated Time Remaining: 05:31:34\n",
      "Mean Reward (last 1000 steps): -0.05267\n",
      "Timesteps: 607000/2000000, Remaining Timesteps: 1393000, Elapsed Time: 02:24:26, Estimated Time Remaining: 05:31:28\n",
      "Mean Reward (last 1000 steps): -0.05886\n",
      "Timesteps: 608000/2000000, Remaining Timesteps: 1392000, Elapsed Time: 02:24:39, Estimated Time Remaining: 05:31:11\n",
      "Mean Reward (last 1000 steps): -0.06282\n",
      "Timesteps: 609000/2000000, Remaining Timesteps: 1391000, Elapsed Time: 02:24:57, Estimated Time Remaining: 05:31:05\n",
      "Mean Reward (last 1000 steps): -0.00034\n",
      "Timesteps: 610000/2000000, Remaining Timesteps: 1390000, Elapsed Time: 02:25:10, Estimated Time Remaining: 05:30:49\n",
      "Mean Reward (last 1000 steps): -0.04982\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 611000/2000000, Remaining Timesteps: 1389000, Elapsed Time: 02:25:28, Estimated Time Remaining: 05:30:43\n",
      "Mean Reward (last 1000 steps): -0.06181\n",
      "Timesteps: 612000/2000000, Remaining Timesteps: 1388000, Elapsed Time: 02:25:42, Estimated Time Remaining: 05:30:27\n",
      "Mean Reward (last 1000 steps): 0.05421\n",
      "Timesteps: 613000/2000000, Remaining Timesteps: 1387000, Elapsed Time: 02:26:00, Estimated Time Remaining: 05:30:21\n",
      "Mean Reward (last 1000 steps): -0.06220\n",
      "Timesteps: 614000/2000000, Remaining Timesteps: 1386000, Elapsed Time: 02:26:13, Estimated Time Remaining: 05:30:05\n",
      "Mean Reward (last 1000 steps): -0.01362\n",
      "Timesteps: 615000/2000000, Remaining Timesteps: 1385000, Elapsed Time: 02:26:31, Estimated Time Remaining: 05:29:58\n",
      "Mean Reward (last 1000 steps): 0.08937\n",
      "Timesteps: 616000/2000000, Remaining Timesteps: 1384000, Elapsed Time: 02:26:44, Estimated Time Remaining: 05:29:40\n",
      "Mean Reward (last 1000 steps): -0.03380\n",
      "Timesteps: 617000/2000000, Remaining Timesteps: 1383000, Elapsed Time: 02:27:01, Estimated Time Remaining: 05:29:34\n",
      "Mean Reward (last 1000 steps): 0.02270\n",
      "Timesteps: 618000/2000000, Remaining Timesteps: 1382000, Elapsed Time: 02:27:14, Estimated Time Remaining: 05:29:16\n",
      "Mean Reward (last 1000 steps): -0.05053\n",
      "Timesteps: 619000/2000000, Remaining Timesteps: 1381000, Elapsed Time: 02:27:32, Estimated Time Remaining: 05:29:08\n",
      "Mean Reward (last 1000 steps): -0.05221\n",
      "Timesteps: 620000/2000000, Remaining Timesteps: 1380000, Elapsed Time: 02:27:44, Estimated Time Remaining: 05:28:50\n",
      "Mean Reward (last 1000 steps): -0.06503\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 621000/2000000, Remaining Timesteps: 1379000, Elapsed Time: 02:28:02, Estimated Time Remaining: 05:28:43\n",
      "Mean Reward (last 1000 steps): 0.06765\n",
      "Timesteps: 622000/2000000, Remaining Timesteps: 1378000, Elapsed Time: 02:28:15, Estimated Time Remaining: 05:28:27\n",
      "Mean Reward (last 1000 steps): -0.01929\n",
      "Timesteps: 623000/2000000, Remaining Timesteps: 1377000, Elapsed Time: 02:28:32, Estimated Time Remaining: 05:28:18\n",
      "Mean Reward (last 1000 steps): 0.02313\n",
      "Timesteps: 624000/2000000, Remaining Timesteps: 1376000, Elapsed Time: 02:28:45, Estimated Time Remaining: 05:28:01\n",
      "Mean Reward (last 1000 steps): -0.03930\n",
      "Timesteps: 625000/2000000, Remaining Timesteps: 1375000, Elapsed Time: 02:29:02, Estimated Time Remaining: 05:27:54\n",
      "Mean Reward (last 1000 steps): 0.02829\n",
      "Timesteps: 626000/2000000, Remaining Timesteps: 1374000, Elapsed Time: 02:29:15, Estimated Time Remaining: 05:27:37\n",
      "Mean Reward (last 1000 steps): 0.02773\n",
      "Timesteps: 627000/2000000, Remaining Timesteps: 1373000, Elapsed Time: 02:29:32, Estimated Time Remaining: 05:27:27\n",
      "Mean Reward (last 1000 steps): 0.03710\n",
      "Timesteps: 628000/2000000, Remaining Timesteps: 1372000, Elapsed Time: 02:29:45, Estimated Time Remaining: 05:27:10\n",
      "Mean Reward (last 1000 steps): 0.00821\n",
      "Timesteps: 629000/2000000, Remaining Timesteps: 1371000, Elapsed Time: 02:30:02, Estimated Time Remaining: 05:27:01\n",
      "Mean Reward (last 1000 steps): -0.01439\n",
      "Timesteps: 630000/2000000, Remaining Timesteps: 1370000, Elapsed Time: 02:30:14, Estimated Time Remaining: 05:26:43\n",
      "Mean Reward (last 1000 steps): 0.09812\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 631000/2000000, Remaining Timesteps: 1369000, Elapsed Time: 02:30:32, Estimated Time Remaining: 05:26:36\n",
      "Mean Reward (last 1000 steps): 0.02601\n",
      "Timesteps: 632000/2000000, Remaining Timesteps: 1368000, Elapsed Time: 02:30:45, Estimated Time Remaining: 05:26:19\n",
      "Mean Reward (last 1000 steps): -0.02284\n",
      "Timesteps: 633000/2000000, Remaining Timesteps: 1367000, Elapsed Time: 02:31:02, Estimated Time Remaining: 05:26:10\n",
      "Mean Reward (last 1000 steps): 0.05175\n",
      "Timesteps: 634000/2000000, Remaining Timesteps: 1366000, Elapsed Time: 02:31:16, Estimated Time Remaining: 05:25:55\n",
      "Mean Reward (last 1000 steps): -0.05427\n",
      "Timesteps: 635000/2000000, Remaining Timesteps: 1365000, Elapsed Time: 02:31:33, Estimated Time Remaining: 05:25:46\n",
      "Mean Reward (last 1000 steps): -0.04718\n",
      "Timesteps: 636000/2000000, Remaining Timesteps: 1364000, Elapsed Time: 02:31:45, Estimated Time Remaining: 05:25:28\n",
      "Mean Reward (last 1000 steps): -0.04245\n",
      "Timesteps: 637000/2000000, Remaining Timesteps: 1363000, Elapsed Time: 02:32:02, Estimated Time Remaining: 05:25:19\n",
      "Mean Reward (last 1000 steps): -0.04403\n",
      "Timesteps: 638000/2000000, Remaining Timesteps: 1362000, Elapsed Time: 02:32:14, Estimated Time Remaining: 05:25:01\n",
      "Mean Reward (last 1000 steps): -0.08450\n",
      "Timesteps: 639000/2000000, Remaining Timesteps: 1361000, Elapsed Time: 02:32:31, Estimated Time Remaining: 05:24:50\n",
      "Mean Reward (last 1000 steps): 0.06218\n",
      "Timesteps: 640000/2000000, Remaining Timesteps: 1360000, Elapsed Time: 02:32:44, Estimated Time Remaining: 05:24:34\n",
      "Mean Reward (last 1000 steps): 0.10257\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 641000/2000000, Remaining Timesteps: 1359000, Elapsed Time: 02:32:57, Estimated Time Remaining: 05:24:17\n",
      "Mean Reward (last 1000 steps): -0.01658\n",
      "Timesteps: 642000/2000000, Remaining Timesteps: 1358000, Elapsed Time: 02:33:13, Estimated Time Remaining: 05:24:07\n",
      "Mean Reward (last 1000 steps): 0.00227\n",
      "Timesteps: 643000/2000000, Remaining Timesteps: 1357000, Elapsed Time: 02:33:25, Estimated Time Remaining: 05:23:48\n",
      "Mean Reward (last 1000 steps): -0.03254\n",
      "Timesteps: 644000/2000000, Remaining Timesteps: 1356000, Elapsed Time: 02:33:42, Estimated Time Remaining: 05:23:39\n",
      "Mean Reward (last 1000 steps): -0.02676\n",
      "Timesteps: 645000/2000000, Remaining Timesteps: 1355000, Elapsed Time: 02:33:54, Estimated Time Remaining: 05:23:20\n",
      "Mean Reward (last 1000 steps): 0.01567\n",
      "Timesteps: 646000/2000000, Remaining Timesteps: 1354000, Elapsed Time: 02:34:11, Estimated Time Remaining: 05:23:10\n",
      "Mean Reward (last 1000 steps): 0.11455\n",
      "Timesteps: 647000/2000000, Remaining Timesteps: 1353000, Elapsed Time: 02:34:24, Estimated Time Remaining: 05:22:53\n",
      "Mean Reward (last 1000 steps): -0.03493\n",
      "Timesteps: 648000/2000000, Remaining Timesteps: 1352000, Elapsed Time: 02:34:40, Estimated Time Remaining: 05:22:43\n",
      "Mean Reward (last 1000 steps): -0.04632\n",
      "Timesteps: 649000/2000000, Remaining Timesteps: 1351000, Elapsed Time: 02:34:53, Estimated Time Remaining: 05:22:26\n",
      "Mean Reward (last 1000 steps): 0.06236\n",
      "Timesteps: 650000/2000000, Remaining Timesteps: 1350000, Elapsed Time: 02:35:10, Estimated Time Remaining: 05:22:16\n",
      "Mean Reward (last 1000 steps): 0.10351\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 651000/2000000, Remaining Timesteps: 1349000, Elapsed Time: 02:35:23, Estimated Time Remaining: 05:21:59\n",
      "Mean Reward (last 1000 steps): 0.06961\n",
      "Timesteps: 652000/2000000, Remaining Timesteps: 1348000, Elapsed Time: 02:35:40, Estimated Time Remaining: 05:21:51\n",
      "Mean Reward (last 1000 steps): 0.06667\n",
      "Timesteps: 653000/2000000, Remaining Timesteps: 1347000, Elapsed Time: 02:35:53, Estimated Time Remaining: 05:21:33\n",
      "Mean Reward (last 1000 steps): -0.02537\n",
      "Timesteps: 654000/2000000, Remaining Timesteps: 1346000, Elapsed Time: 02:36:09, Estimated Time Remaining: 05:21:24\n",
      "Mean Reward (last 1000 steps): -0.05890\n",
      "Timesteps: 655000/2000000, Remaining Timesteps: 1345000, Elapsed Time: 02:36:23, Estimated Time Remaining: 05:21:08\n",
      "Mean Reward (last 1000 steps): -0.03651\n",
      "Timesteps: 656000/2000000, Remaining Timesteps: 1344000, Elapsed Time: 02:36:40, Estimated Time Remaining: 05:20:59\n",
      "Mean Reward (last 1000 steps): -0.06358\n",
      "Timesteps: 657000/2000000, Remaining Timesteps: 1343000, Elapsed Time: 02:36:52, Estimated Time Remaining: 05:20:40\n",
      "Mean Reward (last 1000 steps): -0.02391\n",
      "Timesteps: 658000/2000000, Remaining Timesteps: 1342000, Elapsed Time: 02:37:08, Estimated Time Remaining: 05:20:30\n",
      "Mean Reward (last 1000 steps): -0.06271\n",
      "Timesteps: 659000/2000000, Remaining Timesteps: 1341000, Elapsed Time: 02:37:22, Estimated Time Remaining: 05:20:14\n",
      "Mean Reward (last 1000 steps): 0.02647\n",
      "Timesteps: 660000/2000000, Remaining Timesteps: 1340000, Elapsed Time: 02:37:40, Estimated Time Remaining: 05:20:06\n",
      "Mean Reward (last 1000 steps): -0.03769\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 661000/2000000, Remaining Timesteps: 1339000, Elapsed Time: 02:37:52, Estimated Time Remaining: 05:19:49\n",
      "Mean Reward (last 1000 steps): -0.04161\n",
      "Timesteps: 662000/2000000, Remaining Timesteps: 1338000, Elapsed Time: 02:38:09, Estimated Time Remaining: 05:19:40\n",
      "Mean Reward (last 1000 steps): -0.06271\n",
      "Timesteps: 663000/2000000, Remaining Timesteps: 1337000, Elapsed Time: 02:38:22, Estimated Time Remaining: 05:19:21\n",
      "Mean Reward (last 1000 steps): 0.05859\n",
      "Timesteps: 664000/2000000, Remaining Timesteps: 1336000, Elapsed Time: 02:38:38, Estimated Time Remaining: 05:19:12\n",
      "Mean Reward (last 1000 steps): -0.02419\n",
      "Timesteps: 665000/2000000, Remaining Timesteps: 1335000, Elapsed Time: 02:38:51, Estimated Time Remaining: 05:18:54\n",
      "Mean Reward (last 1000 steps): -0.06346\n",
      "Timesteps: 666000/2000000, Remaining Timesteps: 1334000, Elapsed Time: 02:39:08, Estimated Time Remaining: 05:18:45\n",
      "Mean Reward (last 1000 steps): -0.06519\n",
      "Timesteps: 667000/2000000, Remaining Timesteps: 1333000, Elapsed Time: 02:39:21, Estimated Time Remaining: 05:18:28\n",
      "Mean Reward (last 1000 steps): -0.01418\n",
      "Timesteps: 668000/2000000, Remaining Timesteps: 1332000, Elapsed Time: 02:39:37, Estimated Time Remaining: 05:18:18\n",
      "Mean Reward (last 1000 steps): 0.22258\n",
      "Timesteps: 669000/2000000, Remaining Timesteps: 1331000, Elapsed Time: 02:39:50, Estimated Time Remaining: 05:18:01\n",
      "Mean Reward (last 1000 steps): 0.04000\n",
      "Timesteps: 670000/2000000, Remaining Timesteps: 1330000, Elapsed Time: 02:40:07, Estimated Time Remaining: 05:17:52\n",
      "Mean Reward (last 1000 steps): -0.06552\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 671000/2000000, Remaining Timesteps: 1329000, Elapsed Time: 02:40:20, Estimated Time Remaining: 05:17:34\n",
      "Mean Reward (last 1000 steps): -0.02281\n",
      "Timesteps: 672000/2000000, Remaining Timesteps: 1328000, Elapsed Time: 02:40:36, Estimated Time Remaining: 05:17:23\n",
      "Mean Reward (last 1000 steps): -0.05985\n",
      "Timesteps: 673000/2000000, Remaining Timesteps: 1327000, Elapsed Time: 02:40:49, Estimated Time Remaining: 05:17:06\n",
      "Mean Reward (last 1000 steps): 0.24084\n",
      "Timesteps: 674000/2000000, Remaining Timesteps: 1326000, Elapsed Time: 02:41:05, Estimated Time Remaining: 05:16:55\n",
      "Mean Reward (last 1000 steps): -0.05707\n",
      "Timesteps: 675000/2000000, Remaining Timesteps: 1325000, Elapsed Time: 02:41:18, Estimated Time Remaining: 05:16:38\n",
      "Mean Reward (last 1000 steps): -0.02881\n",
      "Timesteps: 676000/2000000, Remaining Timesteps: 1324000, Elapsed Time: 02:41:35, Estimated Time Remaining: 05:16:29\n",
      "Mean Reward (last 1000 steps): -0.05802\n",
      "Timesteps: 677000/2000000, Remaining Timesteps: 1323000, Elapsed Time: 02:41:48, Estimated Time Remaining: 05:16:12\n",
      "Mean Reward (last 1000 steps): -0.06078\n",
      "Timesteps: 678000/2000000, Remaining Timesteps: 1322000, Elapsed Time: 02:42:04, Estimated Time Remaining: 05:16:01\n",
      "Mean Reward (last 1000 steps): -0.02308\n",
      "Timesteps: 679000/2000000, Remaining Timesteps: 1321000, Elapsed Time: 02:42:17, Estimated Time Remaining: 05:15:44\n",
      "Mean Reward (last 1000 steps): -0.05635\n",
      "Timesteps: 680000/2000000, Remaining Timesteps: 1320000, Elapsed Time: 02:42:34, Estimated Time Remaining: 05:15:34\n",
      "Mean Reward (last 1000 steps): -0.06053\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 681000/2000000, Remaining Timesteps: 1319000, Elapsed Time: 02:42:47, Estimated Time Remaining: 05:15:17\n",
      "Mean Reward (last 1000 steps): -0.05502\n",
      "Timesteps: 682000/2000000, Remaining Timesteps: 1318000, Elapsed Time: 02:43:03, Estimated Time Remaining: 05:15:06\n",
      "Mean Reward (last 1000 steps): -0.02279\n",
      "Timesteps: 683000/2000000, Remaining Timesteps: 1317000, Elapsed Time: 02:43:16, Estimated Time Remaining: 05:14:49\n",
      "Mean Reward (last 1000 steps): -0.00429\n",
      "Timesteps: 684000/2000000, Remaining Timesteps: 1316000, Elapsed Time: 02:43:28, Estimated Time Remaining: 05:14:31\n",
      "Mean Reward (last 1000 steps): -0.01727\n",
      "Timesteps: 685000/2000000, Remaining Timesteps: 1315000, Elapsed Time: 02:43:45, Estimated Time Remaining: 05:14:22\n",
      "Mean Reward (last 1000 steps): -0.06129\n",
      "Timesteps: 686000/2000000, Remaining Timesteps: 1314000, Elapsed Time: 02:43:58, Estimated Time Remaining: 05:14:05\n",
      "Mean Reward (last 1000 steps): -0.03590\n",
      "Timesteps: 687000/2000000, Remaining Timesteps: 1313000, Elapsed Time: 02:44:15, Estimated Time Remaining: 05:13:56\n",
      "Mean Reward (last 1000 steps): -0.05091\n",
      "Timesteps: 688000/2000000, Remaining Timesteps: 1312000, Elapsed Time: 02:44:28, Estimated Time Remaining: 05:13:38\n",
      "Mean Reward (last 1000 steps): -0.05745\n",
      "Timesteps: 689000/2000000, Remaining Timesteps: 1311000, Elapsed Time: 02:44:45, Estimated Time Remaining: 05:13:30\n",
      "Mean Reward (last 1000 steps): -0.05385\n",
      "Timesteps: 690000/2000000, Remaining Timesteps: 1310000, Elapsed Time: 02:44:58, Estimated Time Remaining: 05:13:12\n",
      "Mean Reward (last 1000 steps): -0.04007\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 691000/2000000, Remaining Timesteps: 1309000, Elapsed Time: 02:45:14, Estimated Time Remaining: 05:13:02\n",
      "Mean Reward (last 1000 steps): -0.05031\n",
      "Timesteps: 692000/2000000, Remaining Timesteps: 1308000, Elapsed Time: 02:45:28, Estimated Time Remaining: 05:12:46\n",
      "Mean Reward (last 1000 steps): 0.08846\n",
      "Timesteps: 693000/2000000, Remaining Timesteps: 1307000, Elapsed Time: 02:45:44, Estimated Time Remaining: 05:12:35\n",
      "Mean Reward (last 1000 steps): -0.05985\n",
      "Timesteps: 694000/2000000, Remaining Timesteps: 1306000, Elapsed Time: 02:45:57, Estimated Time Remaining: 05:12:18\n",
      "Mean Reward (last 1000 steps): -0.07143\n",
      "Timesteps: 695000/2000000, Remaining Timesteps: 1305000, Elapsed Time: 02:46:14, Estimated Time Remaining: 05:12:09\n",
      "Mean Reward (last 1000 steps): -0.01539\n",
      "Timesteps: 696000/2000000, Remaining Timesteps: 1304000, Elapsed Time: 02:46:27, Estimated Time Remaining: 05:11:52\n",
      "Mean Reward (last 1000 steps): -0.06400\n",
      "Timesteps: 697000/2000000, Remaining Timesteps: 1303000, Elapsed Time: 02:46:43, Estimated Time Remaining: 05:11:41\n",
      "Mean Reward (last 1000 steps): -0.00977\n",
      "Timesteps: 698000/2000000, Remaining Timesteps: 1302000, Elapsed Time: 02:46:56, Estimated Time Remaining: 05:11:24\n",
      "Mean Reward (last 1000 steps): -0.06066\n",
      "Timesteps: 699000/2000000, Remaining Timesteps: 1301000, Elapsed Time: 02:47:13, Estimated Time Remaining: 05:11:14\n",
      "Mean Reward (last 1000 steps): -0.03220\n",
      "Timesteps: 700000/2000000, Remaining Timesteps: 1300000, Elapsed Time: 02:47:27, Estimated Time Remaining: 05:10:58\n",
      "Mean Reward (last 1000 steps): -0.05971\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 701000/2000000, Remaining Timesteps: 1299000, Elapsed Time: 02:47:44, Estimated Time Remaining: 05:10:49\n",
      "Mean Reward (last 1000 steps): -0.06246\n",
      "Timesteps: 702000/2000000, Remaining Timesteps: 1298000, Elapsed Time: 02:47:57, Estimated Time Remaining: 05:10:33\n",
      "Mean Reward (last 1000 steps): -0.08675\n",
      "Timesteps: 703000/2000000, Remaining Timesteps: 1297000, Elapsed Time: 02:48:14, Estimated Time Remaining: 05:10:23\n",
      "Mean Reward (last 1000 steps): -0.06990\n",
      "Timesteps: 704000/2000000, Remaining Timesteps: 1296000, Elapsed Time: 02:48:27, Estimated Time Remaining: 05:10:06\n",
      "Mean Reward (last 1000 steps): 0.01108\n",
      "Timesteps: 705000/2000000, Remaining Timesteps: 1295000, Elapsed Time: 02:48:44, Estimated Time Remaining: 05:09:57\n",
      "Mean Reward (last 1000 steps): -0.06194\n",
      "Timesteps: 706000/2000000, Remaining Timesteps: 1294000, Elapsed Time: 02:48:57, Estimated Time Remaining: 05:09:41\n",
      "Mean Reward (last 1000 steps): -0.07690\n",
      "Timesteps: 707000/2000000, Remaining Timesteps: 1293000, Elapsed Time: 02:49:14, Estimated Time Remaining: 05:09:31\n",
      "Mean Reward (last 1000 steps): -0.05993\n",
      "Timesteps: 708000/2000000, Remaining Timesteps: 1292000, Elapsed Time: 02:49:27, Estimated Time Remaining: 05:09:14\n",
      "Mean Reward (last 1000 steps): -0.01338\n",
      "Timesteps: 709000/2000000, Remaining Timesteps: 1291000, Elapsed Time: 02:49:45, Estimated Time Remaining: 05:09:06\n",
      "Mean Reward (last 1000 steps): -0.04892\n",
      "Timesteps: 710000/2000000, Remaining Timesteps: 1290000, Elapsed Time: 02:49:58, Estimated Time Remaining: 05:08:50\n",
      "Mean Reward (last 1000 steps): 0.05380\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 711000/2000000, Remaining Timesteps: 1289000, Elapsed Time: 02:50:15, Estimated Time Remaining: 05:08:39\n",
      "Mean Reward (last 1000 steps): -0.05862\n",
      "Timesteps: 712000/2000000, Remaining Timesteps: 1288000, Elapsed Time: 02:50:27, Estimated Time Remaining: 05:08:22\n",
      "Mean Reward (last 1000 steps): -0.06085\n",
      "Timesteps: 713000/2000000, Remaining Timesteps: 1287000, Elapsed Time: 02:50:45, Estimated Time Remaining: 05:08:12\n",
      "Mean Reward (last 1000 steps): -0.06452\n",
      "Timesteps: 714000/2000000, Remaining Timesteps: 1286000, Elapsed Time: 02:50:57, Estimated Time Remaining: 05:07:55\n",
      "Mean Reward (last 1000 steps): -0.05825\n",
      "Timesteps: 715000/2000000, Remaining Timesteps: 1285000, Elapsed Time: 02:51:15, Estimated Time Remaining: 05:07:46\n",
      "Mean Reward (last 1000 steps): -0.04888\n",
      "Timesteps: 716000/2000000, Remaining Timesteps: 1284000, Elapsed Time: 02:51:28, Estimated Time Remaining: 05:07:30\n",
      "Mean Reward (last 1000 steps): -0.04278\n",
      "Timesteps: 717000/2000000, Remaining Timesteps: 1283000, Elapsed Time: 02:51:45, Estimated Time Remaining: 05:07:21\n",
      "Mean Reward (last 1000 steps): -0.06615\n",
      "Timesteps: 718000/2000000, Remaining Timesteps: 1282000, Elapsed Time: 02:51:59, Estimated Time Remaining: 05:07:05\n",
      "Mean Reward (last 1000 steps): -0.02123\n",
      "Timesteps: 719000/2000000, Remaining Timesteps: 1281000, Elapsed Time: 02:52:16, Estimated Time Remaining: 05:06:55\n",
      "Mean Reward (last 1000 steps): -0.03351\n",
      "Timesteps: 720000/2000000, Remaining Timesteps: 1280000, Elapsed Time: 02:52:30, Estimated Time Remaining: 05:06:40\n",
      "Mean Reward (last 1000 steps): 0.00717\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 721000/2000000, Remaining Timesteps: 1279000, Elapsed Time: 02:52:47, Estimated Time Remaining: 05:06:31\n",
      "Mean Reward (last 1000 steps): -0.01771\n",
      "Timesteps: 722000/2000000, Remaining Timesteps: 1278000, Elapsed Time: 02:53:01, Estimated Time Remaining: 05:06:15\n",
      "Mean Reward (last 1000 steps): -0.01478\n",
      "Timesteps: 723000/2000000, Remaining Timesteps: 1277000, Elapsed Time: 02:53:18, Estimated Time Remaining: 05:06:06\n",
      "Mean Reward (last 1000 steps): -0.04691\n",
      "Timesteps: 724000/2000000, Remaining Timesteps: 1276000, Elapsed Time: 02:53:31, Estimated Time Remaining: 05:05:49\n",
      "Mean Reward (last 1000 steps): -0.02049\n",
      "Timesteps: 725000/2000000, Remaining Timesteps: 1275000, Elapsed Time: 02:53:48, Estimated Time Remaining: 05:05:40\n",
      "Mean Reward (last 1000 steps): -0.04257\n",
      "Timesteps: 726000/2000000, Remaining Timesteps: 1274000, Elapsed Time: 02:54:01, Estimated Time Remaining: 05:05:23\n",
      "Mean Reward (last 1000 steps): -0.04119\n",
      "Timesteps: 727000/2000000, Remaining Timesteps: 1273000, Elapsed Time: 02:54:14, Estimated Time Remaining: 05:05:07\n",
      "Mean Reward (last 1000 steps): 0.01066\n",
      "Timesteps: 728000/2000000, Remaining Timesteps: 1272000, Elapsed Time: 02:54:36, Estimated Time Remaining: 05:05:04\n",
      "Mean Reward (last 1000 steps): -0.07527\n",
      "Timesteps: 729000/2000000, Remaining Timesteps: 1271000, Elapsed Time: 02:54:58, Estimated Time Remaining: 05:05:04\n",
      "Mean Reward (last 1000 steps): -0.01494\n",
      "Timesteps: 730000/2000000, Remaining Timesteps: 1270000, Elapsed Time: 02:55:15, Estimated Time Remaining: 05:04:54\n",
      "Mean Reward (last 1000 steps): -0.01462\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 731000/2000000, Remaining Timesteps: 1269000, Elapsed Time: 02:55:28, Estimated Time Remaining: 05:04:37\n",
      "Mean Reward (last 1000 steps): -0.05439\n",
      "Timesteps: 732000/2000000, Remaining Timesteps: 1268000, Elapsed Time: 02:55:45, Estimated Time Remaining: 05:04:27\n",
      "Mean Reward (last 1000 steps): 0.00220\n",
      "Timesteps: 733000/2000000, Remaining Timesteps: 1267000, Elapsed Time: 02:55:58, Estimated Time Remaining: 05:04:10\n",
      "Mean Reward (last 1000 steps): -0.03275\n",
      "Timesteps: 734000/2000000, Remaining Timesteps: 1266000, Elapsed Time: 02:56:15, Estimated Time Remaining: 05:03:59\n",
      "Mean Reward (last 1000 steps): 0.02377\n",
      "Timesteps: 735000/2000000, Remaining Timesteps: 1265000, Elapsed Time: 02:56:28, Estimated Time Remaining: 05:03:43\n",
      "Mean Reward (last 1000 steps): -0.04036\n",
      "Timesteps: 736000/2000000, Remaining Timesteps: 1264000, Elapsed Time: 02:56:45, Estimated Time Remaining: 05:03:33\n",
      "Mean Reward (last 1000 steps): 0.02000\n",
      "Timesteps: 737000/2000000, Remaining Timesteps: 1263000, Elapsed Time: 02:56:58, Estimated Time Remaining: 05:03:16\n",
      "Mean Reward (last 1000 steps): -0.00556\n",
      "Timesteps: 738000/2000000, Remaining Timesteps: 1262000, Elapsed Time: 02:57:15, Estimated Time Remaining: 05:03:06\n",
      "Mean Reward (last 1000 steps): -0.06241\n",
      "Timesteps: 739000/2000000, Remaining Timesteps: 1261000, Elapsed Time: 02:57:27, Estimated Time Remaining: 05:02:48\n",
      "Mean Reward (last 1000 steps): 0.13395\n",
      "Timesteps: 740000/2000000, Remaining Timesteps: 1260000, Elapsed Time: 02:57:45, Estimated Time Remaining: 05:02:39\n",
      "Mean Reward (last 1000 steps): 0.03524\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 741000/2000000, Remaining Timesteps: 1259000, Elapsed Time: 02:57:58, Estimated Time Remaining: 05:02:23\n",
      "Mean Reward (last 1000 steps): -0.01968\n",
      "Timesteps: 742000/2000000, Remaining Timesteps: 1258000, Elapsed Time: 02:58:14, Estimated Time Remaining: 05:02:12\n",
      "Mean Reward (last 1000 steps): 0.00147\n",
      "Timesteps: 743000/2000000, Remaining Timesteps: 1257000, Elapsed Time: 02:58:27, Estimated Time Remaining: 05:01:54\n",
      "Mean Reward (last 1000 steps): -0.00459\n",
      "Timesteps: 744000/2000000, Remaining Timesteps: 1256000, Elapsed Time: 02:58:45, Estimated Time Remaining: 05:01:46\n",
      "Mean Reward (last 1000 steps): -0.02700\n",
      "Timesteps: 745000/2000000, Remaining Timesteps: 1255000, Elapsed Time: 02:58:58, Estimated Time Remaining: 05:01:29\n",
      "Mean Reward (last 1000 steps): -0.02326\n",
      "Timesteps: 746000/2000000, Remaining Timesteps: 1254000, Elapsed Time: 02:59:15, Estimated Time Remaining: 05:01:19\n",
      "Mean Reward (last 1000 steps): -0.03287\n",
      "Timesteps: 747000/2000000, Remaining Timesteps: 1253000, Elapsed Time: 02:59:28, Estimated Time Remaining: 05:01:02\n",
      "Mean Reward (last 1000 steps): -0.03985\n",
      "Timesteps: 748000/2000000, Remaining Timesteps: 1252000, Elapsed Time: 02:59:44, Estimated Time Remaining: 05:00:51\n",
      "Mean Reward (last 1000 steps): 0.01127\n",
      "Timesteps: 749000/2000000, Remaining Timesteps: 1251000, Elapsed Time: 02:59:57, Estimated Time Remaining: 05:00:34\n",
      "Mean Reward (last 1000 steps): -0.04921\n",
      "Timesteps: 750000/2000000, Remaining Timesteps: 1250000, Elapsed Time: 03:00:15, Estimated Time Remaining: 05:00:25\n",
      "Mean Reward (last 1000 steps): -0.00998\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 751000/2000000, Remaining Timesteps: 1249000, Elapsed Time: 03:00:28, Estimated Time Remaining: 05:00:08\n",
      "Mean Reward (last 1000 steps): -0.05486\n",
      "Timesteps: 752000/2000000, Remaining Timesteps: 1248000, Elapsed Time: 03:00:44, Estimated Time Remaining: 04:59:57\n",
      "Mean Reward (last 1000 steps): 0.02747\n",
      "Timesteps: 753000/2000000, Remaining Timesteps: 1247000, Elapsed Time: 03:00:57, Estimated Time Remaining: 04:59:40\n",
      "Mean Reward (last 1000 steps): -0.03709\n",
      "Timesteps: 754000/2000000, Remaining Timesteps: 1246000, Elapsed Time: 03:01:14, Estimated Time Remaining: 04:59:30\n",
      "Mean Reward (last 1000 steps): -0.00684\n",
      "Timesteps: 755000/2000000, Remaining Timesteps: 1245000, Elapsed Time: 03:01:27, Estimated Time Remaining: 04:59:14\n",
      "Mean Reward (last 1000 steps): -0.03818\n",
      "Timesteps: 756000/2000000, Remaining Timesteps: 1244000, Elapsed Time: 03:01:44, Estimated Time Remaining: 04:59:03\n",
      "Mean Reward (last 1000 steps): 0.00102\n",
      "Timesteps: 757000/2000000, Remaining Timesteps: 1243000, Elapsed Time: 03:01:57, Estimated Time Remaining: 04:58:46\n",
      "Mean Reward (last 1000 steps): 0.03904\n",
      "Timesteps: 758000/2000000, Remaining Timesteps: 1242000, Elapsed Time: 03:02:14, Estimated Time Remaining: 04:58:35\n",
      "Mean Reward (last 1000 steps): -0.02565\n",
      "Timesteps: 759000/2000000, Remaining Timesteps: 1241000, Elapsed Time: 03:02:26, Estimated Time Remaining: 04:58:18\n",
      "Mean Reward (last 1000 steps): -0.06066\n",
      "Timesteps: 760000/2000000, Remaining Timesteps: 1240000, Elapsed Time: 03:02:43, Estimated Time Remaining: 04:58:08\n",
      "Mean Reward (last 1000 steps): -0.03718\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 761000/2000000, Remaining Timesteps: 1239000, Elapsed Time: 03:02:56, Estimated Time Remaining: 04:57:51\n",
      "Mean Reward (last 1000 steps): 0.03784\n",
      "Timesteps: 762000/2000000, Remaining Timesteps: 1238000, Elapsed Time: 03:03:12, Estimated Time Remaining: 04:57:39\n",
      "Mean Reward (last 1000 steps): 0.05738\n",
      "Timesteps: 763000/2000000, Remaining Timesteps: 1237000, Elapsed Time: 03:03:25, Estimated Time Remaining: 04:57:22\n",
      "Mean Reward (last 1000 steps): -0.05165\n",
      "Timesteps: 764000/2000000, Remaining Timesteps: 1236000, Elapsed Time: 03:03:43, Estimated Time Remaining: 04:57:13\n",
      "Mean Reward (last 1000 steps): -0.06241\n",
      "Timesteps: 765000/2000000, Remaining Timesteps: 1235000, Elapsed Time: 03:03:55, Estimated Time Remaining: 04:56:55\n",
      "Mean Reward (last 1000 steps): -0.02071\n",
      "Timesteps: 766000/2000000, Remaining Timesteps: 1234000, Elapsed Time: 03:04:12, Estimated Time Remaining: 04:56:45\n",
      "Mean Reward (last 1000 steps): 0.00580\n",
      "Timesteps: 767000/2000000, Remaining Timesteps: 1233000, Elapsed Time: 03:04:24, Estimated Time Remaining: 04:56:27\n",
      "Mean Reward (last 1000 steps): -0.01684\n",
      "Timesteps: 768000/2000000, Remaining Timesteps: 1232000, Elapsed Time: 03:04:38, Estimated Time Remaining: 04:56:11\n",
      "Mean Reward (last 1000 steps): -0.01996\n",
      "Timesteps: 769000/2000000, Remaining Timesteps: 1231000, Elapsed Time: 03:04:54, Estimated Time Remaining: 04:56:00\n",
      "Mean Reward (last 1000 steps): -0.01028\n",
      "Timesteps: 770000/2000000, Remaining Timesteps: 1230000, Elapsed Time: 03:05:07, Estimated Time Remaining: 04:55:43\n",
      "Mean Reward (last 1000 steps): 0.01762\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 771000/2000000, Remaining Timesteps: 1229000, Elapsed Time: 03:05:24, Estimated Time Remaining: 04:55:32\n",
      "Mean Reward (last 1000 steps): -0.03421\n",
      "Timesteps: 772000/2000000, Remaining Timesteps: 1228000, Elapsed Time: 03:05:37, Estimated Time Remaining: 04:55:16\n",
      "Mean Reward (last 1000 steps): -0.03740\n",
      "Timesteps: 773000/2000000, Remaining Timesteps: 1227000, Elapsed Time: 03:05:54, Estimated Time Remaining: 04:55:05\n",
      "Mean Reward (last 1000 steps): -0.01659\n",
      "Timesteps: 774000/2000000, Remaining Timesteps: 1226000, Elapsed Time: 03:06:07, Estimated Time Remaining: 04:54:49\n",
      "Mean Reward (last 1000 steps): -0.05605\n",
      "Timesteps: 775000/2000000, Remaining Timesteps: 1225000, Elapsed Time: 03:06:24, Estimated Time Remaining: 04:54:39\n",
      "Mean Reward (last 1000 steps): -0.03220\n",
      "Timesteps: 776000/2000000, Remaining Timesteps: 1224000, Elapsed Time: 03:06:38, Estimated Time Remaining: 04:54:24\n",
      "Mean Reward (last 1000 steps): -0.01640\n",
      "Timesteps: 777000/2000000, Remaining Timesteps: 1223000, Elapsed Time: 03:06:56, Estimated Time Remaining: 04:54:14\n",
      "Mean Reward (last 1000 steps): 0.03202\n",
      "Timesteps: 778000/2000000, Remaining Timesteps: 1222000, Elapsed Time: 03:07:08, Estimated Time Remaining: 04:53:56\n",
      "Mean Reward (last 1000 steps): 0.00276\n",
      "Timesteps: 779000/2000000, Remaining Timesteps: 1221000, Elapsed Time: 03:07:25, Estimated Time Remaining: 04:53:46\n",
      "Mean Reward (last 1000 steps): -0.03709\n",
      "Timesteps: 780000/2000000, Remaining Timesteps: 1220000, Elapsed Time: 03:07:39, Estimated Time Remaining: 04:53:30\n",
      "Mean Reward (last 1000 steps): -0.09381\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 781000/2000000, Remaining Timesteps: 1219000, Elapsed Time: 03:07:56, Estimated Time Remaining: 04:53:20\n",
      "Mean Reward (last 1000 steps): -0.03878\n",
      "Timesteps: 782000/2000000, Remaining Timesteps: 1218000, Elapsed Time: 03:08:09, Estimated Time Remaining: 04:53:03\n",
      "Mean Reward (last 1000 steps): -0.09357\n",
      "Timesteps: 783000/2000000, Remaining Timesteps: 1217000, Elapsed Time: 03:08:26, Estimated Time Remaining: 04:52:53\n",
      "Mean Reward (last 1000 steps): -0.09308\n",
      "Timesteps: 784000/2000000, Remaining Timesteps: 1216000, Elapsed Time: 03:08:39, Estimated Time Remaining: 04:52:36\n",
      "Mean Reward (last 1000 steps): -0.05686\n",
      "Timesteps: 785000/2000000, Remaining Timesteps: 1215000, Elapsed Time: 03:08:55, Estimated Time Remaining: 04:52:25\n",
      "Mean Reward (last 1000 steps): -0.08148\n",
      "Timesteps: 786000/2000000, Remaining Timesteps: 1214000, Elapsed Time: 03:09:08, Estimated Time Remaining: 04:52:07\n",
      "Mean Reward (last 1000 steps): -0.08288\n",
      "Timesteps: 787000/2000000, Remaining Timesteps: 1213000, Elapsed Time: 03:09:25, Estimated Time Remaining: 04:51:58\n",
      "Mean Reward (last 1000 steps): 0.00416\n",
      "Timesteps: 788000/2000000, Remaining Timesteps: 1212000, Elapsed Time: 03:09:39, Estimated Time Remaining: 04:51:41\n",
      "Mean Reward (last 1000 steps): -0.03033\n",
      "Timesteps: 789000/2000000, Remaining Timesteps: 1211000, Elapsed Time: 03:09:55, Estimated Time Remaining: 04:51:31\n",
      "Mean Reward (last 1000 steps): -0.04404\n",
      "Timesteps: 790000/2000000, Remaining Timesteps: 1210000, Elapsed Time: 03:10:09, Estimated Time Remaining: 04:51:14\n",
      "Mean Reward (last 1000 steps): -0.03625\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 791000/2000000, Remaining Timesteps: 1209000, Elapsed Time: 03:10:26, Estimated Time Remaining: 04:51:04\n",
      "Mean Reward (last 1000 steps): -0.05374\n",
      "Timesteps: 792000/2000000, Remaining Timesteps: 1208000, Elapsed Time: 03:10:38, Estimated Time Remaining: 04:50:47\n",
      "Mean Reward (last 1000 steps): -0.04662\n",
      "Timesteps: 793000/2000000, Remaining Timesteps: 1207000, Elapsed Time: 03:10:55, Estimated Time Remaining: 04:50:36\n",
      "Mean Reward (last 1000 steps): 0.01488\n",
      "Timesteps: 794000/2000000, Remaining Timesteps: 1206000, Elapsed Time: 03:11:08, Estimated Time Remaining: 04:50:19\n",
      "Mean Reward (last 1000 steps): -0.06403\n",
      "Timesteps: 795000/2000000, Remaining Timesteps: 1205000, Elapsed Time: 03:11:24, Estimated Time Remaining: 04:50:07\n",
      "Mean Reward (last 1000 steps): -0.01569\n",
      "Timesteps: 796000/2000000, Remaining Timesteps: 1204000, Elapsed Time: 03:11:37, Estimated Time Remaining: 04:49:50\n",
      "Mean Reward (last 1000 steps): -0.07578\n",
      "Timesteps: 797000/2000000, Remaining Timesteps: 1203000, Elapsed Time: 03:11:54, Estimated Time Remaining: 04:49:39\n",
      "Mean Reward (last 1000 steps): 0.00873\n",
      "Timesteps: 798000/2000000, Remaining Timesteps: 1202000, Elapsed Time: 03:12:07, Estimated Time Remaining: 04:49:22\n",
      "Mean Reward (last 1000 steps): -0.04585\n",
      "Timesteps: 799000/2000000, Remaining Timesteps: 1201000, Elapsed Time: 03:12:24, Estimated Time Remaining: 04:49:12\n",
      "Mean Reward (last 1000 steps): 0.03027\n",
      "Timesteps: 800000/2000000, Remaining Timesteps: 1200000, Elapsed Time: 03:12:36, Estimated Time Remaining: 04:48:54\n",
      "Mean Reward (last 1000 steps): -0.08944\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 801000/2000000, Remaining Timesteps: 1199000, Elapsed Time: 03:12:53, Estimated Time Remaining: 04:48:44\n",
      "Mean Reward (last 1000 steps): -0.02948\n",
      "Timesteps: 802000/2000000, Remaining Timesteps: 1198000, Elapsed Time: 03:13:06, Estimated Time Remaining: 04:48:27\n",
      "Mean Reward (last 1000 steps): -0.02941\n",
      "Timesteps: 803000/2000000, Remaining Timesteps: 1197000, Elapsed Time: 03:13:23, Estimated Time Remaining: 04:48:16\n",
      "Mean Reward (last 1000 steps): -0.08655\n",
      "Timesteps: 804000/2000000, Remaining Timesteps: 1196000, Elapsed Time: 03:13:35, Estimated Time Remaining: 04:47:59\n",
      "Mean Reward (last 1000 steps): -0.09310\n",
      "Timesteps: 805000/2000000, Remaining Timesteps: 1195000, Elapsed Time: 03:13:52, Estimated Time Remaining: 04:47:48\n",
      "Mean Reward (last 1000 steps): -0.09336\n",
      "Timesteps: 806000/2000000, Remaining Timesteps: 1194000, Elapsed Time: 03:14:05, Estimated Time Remaining: 04:47:31\n",
      "Mean Reward (last 1000 steps): -0.09327\n",
      "Timesteps: 807000/2000000, Remaining Timesteps: 1193000, Elapsed Time: 03:14:22, Estimated Time Remaining: 04:47:20\n",
      "Mean Reward (last 1000 steps): -0.08649\n",
      "Timesteps: 808000/2000000, Remaining Timesteps: 1192000, Elapsed Time: 03:14:35, Estimated Time Remaining: 04:47:03\n",
      "Mean Reward (last 1000 steps): -0.03898\n",
      "Timesteps: 809000/2000000, Remaining Timesteps: 1191000, Elapsed Time: 03:14:52, Estimated Time Remaining: 04:46:53\n",
      "Mean Reward (last 1000 steps): -0.09363\n",
      "Timesteps: 810000/2000000, Remaining Timesteps: 1190000, Elapsed Time: 03:15:05, Estimated Time Remaining: 04:46:36\n",
      "Mean Reward (last 1000 steps): -0.09286\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 811000/2000000, Remaining Timesteps: 1189000, Elapsed Time: 03:15:17, Estimated Time Remaining: 04:46:18\n",
      "Mean Reward (last 1000 steps): -0.09231\n",
      "Timesteps: 812000/2000000, Remaining Timesteps: 1188000, Elapsed Time: 03:15:34, Estimated Time Remaining: 04:46:07\n",
      "Mean Reward (last 1000 steps): -0.07924\n",
      "Timesteps: 813000/2000000, Remaining Timesteps: 1187000, Elapsed Time: 03:15:46, Estimated Time Remaining: 04:45:50\n",
      "Mean Reward (last 1000 steps): -0.04394\n",
      "Timesteps: 814000/2000000, Remaining Timesteps: 1186000, Elapsed Time: 03:16:03, Estimated Time Remaining: 04:45:39\n",
      "Mean Reward (last 1000 steps): -0.08587\n",
      "Timesteps: 815000/2000000, Remaining Timesteps: 1185000, Elapsed Time: 03:16:16, Estimated Time Remaining: 04:45:22\n",
      "Mean Reward (last 1000 steps): -0.03568\n",
      "Timesteps: 816000/2000000, Remaining Timesteps: 1184000, Elapsed Time: 03:16:32, Estimated Time Remaining: 04:45:11\n",
      "Mean Reward (last 1000 steps): -0.00172\n",
      "Timesteps: 817000/2000000, Remaining Timesteps: 1183000, Elapsed Time: 03:16:45, Estimated Time Remaining: 04:44:54\n",
      "Mean Reward (last 1000 steps): -0.05546\n",
      "Timesteps: 818000/2000000, Remaining Timesteps: 1182000, Elapsed Time: 03:17:02, Estimated Time Remaining: 04:44:43\n",
      "Mean Reward (last 1000 steps): -0.07812\n",
      "Timesteps: 819000/2000000, Remaining Timesteps: 1181000, Elapsed Time: 03:17:15, Estimated Time Remaining: 04:44:26\n",
      "Mean Reward (last 1000 steps): -0.04466\n",
      "Timesteps: 820000/2000000, Remaining Timesteps: 1180000, Elapsed Time: 03:17:31, Estimated Time Remaining: 04:44:15\n",
      "Mean Reward (last 1000 steps): -0.07027\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 821000/2000000, Remaining Timesteps: 1179000, Elapsed Time: 03:17:44, Estimated Time Remaining: 04:43:57\n",
      "Mean Reward (last 1000 steps): -0.02872\n",
      "Timesteps: 822000/2000000, Remaining Timesteps: 1178000, Elapsed Time: 03:18:01, Estimated Time Remaining: 04:43:47\n",
      "Mean Reward (last 1000 steps): -0.02324\n",
      "Timesteps: 823000/2000000, Remaining Timesteps: 1177000, Elapsed Time: 03:18:14, Estimated Time Remaining: 04:43:30\n",
      "Mean Reward (last 1000 steps): -0.05283\n",
      "Timesteps: 824000/2000000, Remaining Timesteps: 1176000, Elapsed Time: 03:18:33, Estimated Time Remaining: 04:43:23\n",
      "Mean Reward (last 1000 steps): -0.08851\n",
      "Timesteps: 825000/2000000, Remaining Timesteps: 1175000, Elapsed Time: 03:18:46, Estimated Time Remaining: 04:43:06\n",
      "Mean Reward (last 1000 steps): -0.09298\n",
      "Timesteps: 826000/2000000, Remaining Timesteps: 1174000, Elapsed Time: 03:19:03, Estimated Time Remaining: 04:42:55\n",
      "Mean Reward (last 1000 steps): -0.09338\n",
      "Timesteps: 827000/2000000, Remaining Timesteps: 1173000, Elapsed Time: 03:19:16, Estimated Time Remaining: 04:42:39\n",
      "Mean Reward (last 1000 steps): -0.03024\n",
      "Timesteps: 828000/2000000, Remaining Timesteps: 1172000, Elapsed Time: 03:19:34, Estimated Time Remaining: 04:42:29\n",
      "Mean Reward (last 1000 steps): -0.05614\n",
      "Timesteps: 829000/2000000, Remaining Timesteps: 1171000, Elapsed Time: 03:19:47, Estimated Time Remaining: 04:42:12\n",
      "Mean Reward (last 1000 steps): -0.06109\n",
      "Timesteps: 830000/2000000, Remaining Timesteps: 1170000, Elapsed Time: 03:20:04, Estimated Time Remaining: 04:42:02\n",
      "Mean Reward (last 1000 steps): -0.08210\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 831000/2000000, Remaining Timesteps: 1169000, Elapsed Time: 03:20:18, Estimated Time Remaining: 04:41:46\n",
      "Mean Reward (last 1000 steps): -0.05890\n",
      "Timesteps: 832000/2000000, Remaining Timesteps: 1168000, Elapsed Time: 03:20:36, Estimated Time Remaining: 04:41:36\n",
      "Mean Reward (last 1000 steps): -0.03368\n",
      "Timesteps: 833000/2000000, Remaining Timesteps: 1167000, Elapsed Time: 03:20:49, Estimated Time Remaining: 04:41:21\n",
      "Mean Reward (last 1000 steps): -0.06575\n",
      "Timesteps: 834000/2000000, Remaining Timesteps: 1166000, Elapsed Time: 03:21:07, Estimated Time Remaining: 04:41:11\n",
      "Mean Reward (last 1000 steps): -0.09327\n",
      "Timesteps: 835000/2000000, Remaining Timesteps: 1165000, Elapsed Time: 03:21:20, Estimated Time Remaining: 04:40:55\n",
      "Mean Reward (last 1000 steps): -0.09296\n",
      "Timesteps: 836000/2000000, Remaining Timesteps: 1164000, Elapsed Time: 03:21:37, Estimated Time Remaining: 04:40:44\n",
      "Mean Reward (last 1000 steps): -0.05747\n",
      "Timesteps: 837000/2000000, Remaining Timesteps: 1163000, Elapsed Time: 03:21:51, Estimated Time Remaining: 04:40:28\n",
      "Mean Reward (last 1000 steps): -0.03819\n",
      "Timesteps: 838000/2000000, Remaining Timesteps: 1162000, Elapsed Time: 03:22:08, Estimated Time Remaining: 04:40:18\n",
      "Mean Reward (last 1000 steps): -0.03161\n",
      "Timesteps: 839000/2000000, Remaining Timesteps: 1161000, Elapsed Time: 03:22:22, Estimated Time Remaining: 04:40:02\n",
      "Mean Reward (last 1000 steps): -0.05013\n",
      "Timesteps: 840000/2000000, Remaining Timesteps: 1160000, Elapsed Time: 03:22:39, Estimated Time Remaining: 04:39:51\n",
      "Mean Reward (last 1000 steps): -0.07500\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 841000/2000000, Remaining Timesteps: 1159000, Elapsed Time: 03:22:52, Estimated Time Remaining: 04:39:34\n",
      "Mean Reward (last 1000 steps): -0.03350\n",
      "Timesteps: 842000/2000000, Remaining Timesteps: 1158000, Elapsed Time: 03:23:09, Estimated Time Remaining: 04:39:23\n",
      "Mean Reward (last 1000 steps): -0.03639\n",
      "Timesteps: 843000/2000000, Remaining Timesteps: 1157000, Elapsed Time: 03:23:22, Estimated Time Remaining: 04:39:08\n",
      "Mean Reward (last 1000 steps): -0.03487\n",
      "Timesteps: 844000/2000000, Remaining Timesteps: 1156000, Elapsed Time: 03:23:40, Estimated Time Remaining: 04:38:57\n",
      "Mean Reward (last 1000 steps): -0.04624\n",
      "Timesteps: 845000/2000000, Remaining Timesteps: 1155000, Elapsed Time: 03:23:53, Estimated Time Remaining: 04:38:41\n",
      "Mean Reward (last 1000 steps): -0.01673\n",
      "Timesteps: 846000/2000000, Remaining Timesteps: 1154000, Elapsed Time: 03:24:10, Estimated Time Remaining: 04:38:31\n",
      "Mean Reward (last 1000 steps): -0.04613\n",
      "Timesteps: 847000/2000000, Remaining Timesteps: 1153000, Elapsed Time: 03:24:24, Estimated Time Remaining: 04:38:15\n",
      "Mean Reward (last 1000 steps): -0.06679\n",
      "Timesteps: 848000/2000000, Remaining Timesteps: 1152000, Elapsed Time: 03:24:41, Estimated Time Remaining: 04:38:04\n",
      "Mean Reward (last 1000 steps): -0.02320\n",
      "Timesteps: 849000/2000000, Remaining Timesteps: 1151000, Elapsed Time: 03:24:55, Estimated Time Remaining: 04:37:48\n",
      "Mean Reward (last 1000 steps): -0.08660\n",
      "Timesteps: 850000/2000000, Remaining Timesteps: 1150000, Elapsed Time: 03:25:12, Estimated Time Remaining: 04:37:37\n",
      "Mean Reward (last 1000 steps): -0.03112\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 851000/2000000, Remaining Timesteps: 1149000, Elapsed Time: 03:25:25, Estimated Time Remaining: 04:37:21\n",
      "Mean Reward (last 1000 steps): -0.03470\n",
      "Timesteps: 852000/2000000, Remaining Timesteps: 1148000, Elapsed Time: 03:25:42, Estimated Time Remaining: 04:37:10\n",
      "Mean Reward (last 1000 steps): -0.05000\n",
      "Timesteps: 853000/2000000, Remaining Timesteps: 1147000, Elapsed Time: 03:25:55, Estimated Time Remaining: 04:36:54\n",
      "Mean Reward (last 1000 steps): -0.05045\n",
      "Timesteps: 854000/2000000, Remaining Timesteps: 1146000, Elapsed Time: 03:26:09, Estimated Time Remaining: 04:36:38\n",
      "Mean Reward (last 1000 steps): -0.02881\n",
      "Timesteps: 855000/2000000, Remaining Timesteps: 1145000, Elapsed Time: 03:26:26, Estimated Time Remaining: 04:36:27\n",
      "Mean Reward (last 1000 steps): -0.02866\n",
      "Timesteps: 856000/2000000, Remaining Timesteps: 1144000, Elapsed Time: 03:26:39, Estimated Time Remaining: 04:36:10\n",
      "Mean Reward (last 1000 steps): -0.01862\n",
      "Timesteps: 857000/2000000, Remaining Timesteps: 1143000, Elapsed Time: 03:26:56, Estimated Time Remaining: 04:35:59\n",
      "Mean Reward (last 1000 steps): -0.03296\n",
      "Timesteps: 858000/2000000, Remaining Timesteps: 1142000, Elapsed Time: 03:27:08, Estimated Time Remaining: 04:35:42\n",
      "Mean Reward (last 1000 steps): -0.02281\n",
      "Timesteps: 859000/2000000, Remaining Timesteps: 1141000, Elapsed Time: 03:27:26, Estimated Time Remaining: 04:35:32\n",
      "Mean Reward (last 1000 steps): 0.00500\n",
      "Timesteps: 860000/2000000, Remaining Timesteps: 1140000, Elapsed Time: 03:27:39, Estimated Time Remaining: 04:35:16\n",
      "Mean Reward (last 1000 steps): 0.00505\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 861000/2000000, Remaining Timesteps: 1139000, Elapsed Time: 03:27:57, Estimated Time Remaining: 04:35:06\n",
      "Mean Reward (last 1000 steps): -0.06002\n",
      "Timesteps: 862000/2000000, Remaining Timesteps: 1138000, Elapsed Time: 03:28:11, Estimated Time Remaining: 04:34:50\n",
      "Mean Reward (last 1000 steps): -0.02388\n",
      "Timesteps: 863000/2000000, Remaining Timesteps: 1137000, Elapsed Time: 03:28:28, Estimated Time Remaining: 04:34:39\n",
      "Mean Reward (last 1000 steps): -0.03411\n",
      "Timesteps: 864000/2000000, Remaining Timesteps: 1136000, Elapsed Time: 03:28:41, Estimated Time Remaining: 04:34:23\n",
      "Mean Reward (last 1000 steps): -0.04073\n",
      "Timesteps: 865000/2000000, Remaining Timesteps: 1135000, Elapsed Time: 03:28:58, Estimated Time Remaining: 04:34:12\n",
      "Mean Reward (last 1000 steps): -0.05720\n",
      "Timesteps: 866000/2000000, Remaining Timesteps: 1134000, Elapsed Time: 03:29:12, Estimated Time Remaining: 04:33:56\n",
      "Mean Reward (last 1000 steps): -0.00280\n",
      "Timesteps: 867000/2000000, Remaining Timesteps: 1133000, Elapsed Time: 03:29:29, Estimated Time Remaining: 04:33:46\n",
      "Mean Reward (last 1000 steps): -0.02430\n",
      "Timesteps: 868000/2000000, Remaining Timesteps: 1132000, Elapsed Time: 03:29:43, Estimated Time Remaining: 04:33:30\n",
      "Mean Reward (last 1000 steps): -0.04552\n",
      "Timesteps: 869000/2000000, Remaining Timesteps: 1131000, Elapsed Time: 03:30:01, Estimated Time Remaining: 04:33:20\n",
      "Mean Reward (last 1000 steps): -0.00476\n",
      "Timesteps: 870000/2000000, Remaining Timesteps: 1130000, Elapsed Time: 03:30:15, Estimated Time Remaining: 04:33:05\n",
      "Mean Reward (last 1000 steps): -0.05423\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 871000/2000000, Remaining Timesteps: 1129000, Elapsed Time: 03:30:32, Estimated Time Remaining: 04:32:54\n",
      "Mean Reward (last 1000 steps): -0.05074\n",
      "Timesteps: 872000/2000000, Remaining Timesteps: 1128000, Elapsed Time: 03:30:46, Estimated Time Remaining: 04:32:38\n",
      "Mean Reward (last 1000 steps): -0.02565\n",
      "Timesteps: 873000/2000000, Remaining Timesteps: 1127000, Elapsed Time: 03:31:03, Estimated Time Remaining: 04:32:27\n",
      "Mean Reward (last 1000 steps): -0.01853\n",
      "Timesteps: 874000/2000000, Remaining Timesteps: 1126000, Elapsed Time: 03:31:16, Estimated Time Remaining: 04:32:11\n",
      "Mean Reward (last 1000 steps): -0.04995\n",
      "Timesteps: 875000/2000000, Remaining Timesteps: 1125000, Elapsed Time: 03:31:33, Estimated Time Remaining: 04:32:00\n",
      "Mean Reward (last 1000 steps): -0.04491\n",
      "Timesteps: 876000/2000000, Remaining Timesteps: 1124000, Elapsed Time: 03:31:46, Estimated Time Remaining: 04:31:44\n",
      "Mean Reward (last 1000 steps): 0.01485\n",
      "Timesteps: 877000/2000000, Remaining Timesteps: 1123000, Elapsed Time: 03:32:04, Estimated Time Remaining: 04:31:33\n",
      "Mean Reward (last 1000 steps): -0.04364\n",
      "Timesteps: 878000/2000000, Remaining Timesteps: 1122000, Elapsed Time: 03:32:17, Estimated Time Remaining: 04:31:17\n",
      "Mean Reward (last 1000 steps): -0.07509\n",
      "Timesteps: 879000/2000000, Remaining Timesteps: 1121000, Elapsed Time: 03:32:34, Estimated Time Remaining: 04:31:06\n",
      "Mean Reward (last 1000 steps): -0.01450\n",
      "Timesteps: 880000/2000000, Remaining Timesteps: 1120000, Elapsed Time: 03:32:47, Estimated Time Remaining: 04:30:50\n",
      "Mean Reward (last 1000 steps): -0.04460\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 881000/2000000, Remaining Timesteps: 1119000, Elapsed Time: 03:33:05, Estimated Time Remaining: 04:30:39\n",
      "Mean Reward (last 1000 steps): -0.05289\n",
      "Timesteps: 882000/2000000, Remaining Timesteps: 1118000, Elapsed Time: 03:33:18, Estimated Time Remaining: 04:30:23\n",
      "Mean Reward (last 1000 steps): -0.08842\n",
      "Timesteps: 883000/2000000, Remaining Timesteps: 1117000, Elapsed Time: 03:33:35, Estimated Time Remaining: 04:30:11\n",
      "Mean Reward (last 1000 steps): -0.01846\n",
      "Timesteps: 884000/2000000, Remaining Timesteps: 1116000, Elapsed Time: 03:33:48, Estimated Time Remaining: 04:29:55\n",
      "Mean Reward (last 1000 steps): -0.03682\n",
      "Timesteps: 885000/2000000, Remaining Timesteps: 1115000, Elapsed Time: 03:34:05, Estimated Time Remaining: 04:29:44\n",
      "Mean Reward (last 1000 steps): -0.04866\n",
      "Timesteps: 886000/2000000, Remaining Timesteps: 1114000, Elapsed Time: 03:34:19, Estimated Time Remaining: 04:29:28\n",
      "Mean Reward (last 1000 steps): -0.04035\n",
      "Timesteps: 887000/2000000, Remaining Timesteps: 1113000, Elapsed Time: 03:34:36, Estimated Time Remaining: 04:29:17\n",
      "Mean Reward (last 1000 steps): -0.07880\n",
      "Timesteps: 888000/2000000, Remaining Timesteps: 1112000, Elapsed Time: 03:34:49, Estimated Time Remaining: 04:29:00\n",
      "Mean Reward (last 1000 steps): -0.02451\n",
      "Timesteps: 889000/2000000, Remaining Timesteps: 1111000, Elapsed Time: 03:35:06, Estimated Time Remaining: 04:28:49\n",
      "Mean Reward (last 1000 steps): -0.03259\n",
      "Timesteps: 890000/2000000, Remaining Timesteps: 1110000, Elapsed Time: 03:35:20, Estimated Time Remaining: 04:28:34\n",
      "Mean Reward (last 1000 steps): -0.04911\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 891000/2000000, Remaining Timesteps: 1109000, Elapsed Time: 03:35:38, Estimated Time Remaining: 04:28:23\n",
      "Mean Reward (last 1000 steps): -0.03995\n",
      "Timesteps: 892000/2000000, Remaining Timesteps: 1108000, Elapsed Time: 03:35:51, Estimated Time Remaining: 04:28:07\n",
      "Mean Reward (last 1000 steps): -0.01112\n",
      "Timesteps: 893000/2000000, Remaining Timesteps: 1107000, Elapsed Time: 03:36:09, Estimated Time Remaining: 04:27:57\n",
      "Mean Reward (last 1000 steps): -0.05412\n",
      "Timesteps: 894000/2000000, Remaining Timesteps: 1106000, Elapsed Time: 03:36:22, Estimated Time Remaining: 04:27:41\n",
      "Mean Reward (last 1000 steps): -0.07826\n",
      "Timesteps: 895000/2000000, Remaining Timesteps: 1105000, Elapsed Time: 03:36:40, Estimated Time Remaining: 04:27:30\n",
      "Mean Reward (last 1000 steps): -0.03403\n",
      "Timesteps: 896000/2000000, Remaining Timesteps: 1104000, Elapsed Time: 03:36:53, Estimated Time Remaining: 04:27:15\n",
      "Mean Reward (last 1000 steps): -0.05267\n",
      "Timesteps: 897000/2000000, Remaining Timesteps: 1103000, Elapsed Time: 03:37:07, Estimated Time Remaining: 04:26:58\n",
      "Mean Reward (last 1000 steps): -0.08703\n",
      "Timesteps: 898000/2000000, Remaining Timesteps: 1102000, Elapsed Time: 03:37:24, Estimated Time Remaining: 04:26:48\n",
      "Mean Reward (last 1000 steps): -0.04748\n",
      "Timesteps: 899000/2000000, Remaining Timesteps: 1101000, Elapsed Time: 03:37:38, Estimated Time Remaining: 04:26:32\n",
      "Mean Reward (last 1000 steps): -0.00827\n",
      "Timesteps: 900000/2000000, Remaining Timesteps: 1100000, Elapsed Time: 03:37:56, Estimated Time Remaining: 04:26:21\n",
      "Mean Reward (last 1000 steps): -0.02130\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 901000/2000000, Remaining Timesteps: 1099000, Elapsed Time: 03:38:09, Estimated Time Remaining: 04:26:06\n",
      "Mean Reward (last 1000 steps): -0.04771\n",
      "Timesteps: 902000/2000000, Remaining Timesteps: 1098000, Elapsed Time: 03:38:27, Estimated Time Remaining: 04:25:55\n",
      "Mean Reward (last 1000 steps): -0.01697\n",
      "Timesteps: 903000/2000000, Remaining Timesteps: 1097000, Elapsed Time: 03:38:40, Estimated Time Remaining: 04:25:39\n",
      "Mean Reward (last 1000 steps): -0.08568\n",
      "Timesteps: 904000/2000000, Remaining Timesteps: 1096000, Elapsed Time: 03:38:57, Estimated Time Remaining: 04:25:28\n",
      "Mean Reward (last 1000 steps): -0.01845\n",
      "Timesteps: 905000/2000000, Remaining Timesteps: 1095000, Elapsed Time: 03:39:11, Estimated Time Remaining: 04:25:12\n",
      "Mean Reward (last 1000 steps): -0.03580\n",
      "Timesteps: 906000/2000000, Remaining Timesteps: 1094000, Elapsed Time: 03:39:28, Estimated Time Remaining: 04:25:01\n",
      "Mean Reward (last 1000 steps): -0.03061\n",
      "Timesteps: 907000/2000000, Remaining Timesteps: 1093000, Elapsed Time: 03:39:42, Estimated Time Remaining: 04:24:45\n",
      "Mean Reward (last 1000 steps): -0.04365\n",
      "Timesteps: 908000/2000000, Remaining Timesteps: 1092000, Elapsed Time: 03:39:59, Estimated Time Remaining: 04:24:34\n",
      "Mean Reward (last 1000 steps): -0.01000\n",
      "Timesteps: 909000/2000000, Remaining Timesteps: 1091000, Elapsed Time: 03:40:13, Estimated Time Remaining: 04:24:19\n",
      "Mean Reward (last 1000 steps): -0.08042\n",
      "Timesteps: 910000/2000000, Remaining Timesteps: 1090000, Elapsed Time: 03:40:30, Estimated Time Remaining: 04:24:08\n",
      "Mean Reward (last 1000 steps): -0.09283\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 911000/2000000, Remaining Timesteps: 1089000, Elapsed Time: 03:40:44, Estimated Time Remaining: 04:23:52\n",
      "Mean Reward (last 1000 steps): -0.02022\n",
      "Timesteps: 912000/2000000, Remaining Timesteps: 1088000, Elapsed Time: 03:41:01, Estimated Time Remaining: 04:23:41\n",
      "Mean Reward (last 1000 steps): -0.04054\n",
      "Timesteps: 913000/2000000, Remaining Timesteps: 1087000, Elapsed Time: 03:41:15, Estimated Time Remaining: 04:23:25\n",
      "Mean Reward (last 1000 steps): -0.08062\n",
      "Timesteps: 914000/2000000, Remaining Timesteps: 1086000, Elapsed Time: 03:41:33, Estimated Time Remaining: 04:23:14\n",
      "Mean Reward (last 1000 steps): -0.03901\n",
      "Timesteps: 915000/2000000, Remaining Timesteps: 1085000, Elapsed Time: 03:41:46, Estimated Time Remaining: 04:22:58\n",
      "Mean Reward (last 1000 steps): -0.05269\n",
      "Timesteps: 916000/2000000, Remaining Timesteps: 1084000, Elapsed Time: 03:42:03, Estimated Time Remaining: 04:22:47\n",
      "Mean Reward (last 1000 steps): -0.04513\n",
      "Timesteps: 917000/2000000, Remaining Timesteps: 1083000, Elapsed Time: 03:42:17, Estimated Time Remaining: 04:22:31\n",
      "Mean Reward (last 1000 steps): -0.05608\n",
      "Timesteps: 918000/2000000, Remaining Timesteps: 1082000, Elapsed Time: 03:42:35, Estimated Time Remaining: 04:22:21\n",
      "Mean Reward (last 1000 steps): -0.05057\n",
      "Timesteps: 919000/2000000, Remaining Timesteps: 1081000, Elapsed Time: 03:42:48, Estimated Time Remaining: 04:22:05\n",
      "Mean Reward (last 1000 steps): -0.03314\n",
      "Timesteps: 920000/2000000, Remaining Timesteps: 1080000, Elapsed Time: 03:43:06, Estimated Time Remaining: 04:21:54\n",
      "Mean Reward (last 1000 steps): -0.05084\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 921000/2000000, Remaining Timesteps: 1079000, Elapsed Time: 03:43:19, Estimated Time Remaining: 04:21:38\n",
      "Mean Reward (last 1000 steps): -0.02707\n",
      "Timesteps: 922000/2000000, Remaining Timesteps: 1078000, Elapsed Time: 03:43:37, Estimated Time Remaining: 04:21:27\n",
      "Mean Reward (last 1000 steps): -0.05979\n",
      "Timesteps: 923000/2000000, Remaining Timesteps: 1077000, Elapsed Time: 03:43:50, Estimated Time Remaining: 04:21:11\n",
      "Mean Reward (last 1000 steps): -0.06706\n",
      "Timesteps: 924000/2000000, Remaining Timesteps: 1076000, Elapsed Time: 03:44:07, Estimated Time Remaining: 04:20:59\n",
      "Mean Reward (last 1000 steps): -0.06180\n",
      "Timesteps: 925000/2000000, Remaining Timesteps: 1075000, Elapsed Time: 03:44:20, Estimated Time Remaining: 04:20:43\n",
      "Mean Reward (last 1000 steps): -0.02384\n",
      "Timesteps: 926000/2000000, Remaining Timesteps: 1074000, Elapsed Time: 03:44:38, Estimated Time Remaining: 04:20:32\n",
      "Mean Reward (last 1000 steps): -0.02781\n",
      "Timesteps: 927000/2000000, Remaining Timesteps: 1073000, Elapsed Time: 03:44:52, Estimated Time Remaining: 04:20:17\n",
      "Mean Reward (last 1000 steps): 0.00750\n",
      "Timesteps: 928000/2000000, Remaining Timesteps: 1072000, Elapsed Time: 03:45:09, Estimated Time Remaining: 04:20:05\n",
      "Mean Reward (last 1000 steps): -0.05567\n",
      "Timesteps: 929000/2000000, Remaining Timesteps: 1071000, Elapsed Time: 03:45:22, Estimated Time Remaining: 04:19:49\n",
      "Mean Reward (last 1000 steps): -0.05899\n",
      "Timesteps: 930000/2000000, Remaining Timesteps: 1070000, Elapsed Time: 03:45:40, Estimated Time Remaining: 04:19:38\n",
      "Mean Reward (last 1000 steps): -0.09213\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 931000/2000000, Remaining Timesteps: 1069000, Elapsed Time: 03:45:53, Estimated Time Remaining: 04:19:22\n",
      "Mean Reward (last 1000 steps): -0.03974\n",
      "Timesteps: 932000/2000000, Remaining Timesteps: 1068000, Elapsed Time: 03:46:10, Estimated Time Remaining: 04:19:11\n",
      "Mean Reward (last 1000 steps): -0.04210\n",
      "Timesteps: 933000/2000000, Remaining Timesteps: 1067000, Elapsed Time: 03:46:24, Estimated Time Remaining: 04:18:55\n",
      "Mean Reward (last 1000 steps): -0.05032\n",
      "Timesteps: 934000/2000000, Remaining Timesteps: 1066000, Elapsed Time: 03:46:41, Estimated Time Remaining: 04:18:43\n",
      "Mean Reward (last 1000 steps): -0.05109\n",
      "Timesteps: 935000/2000000, Remaining Timesteps: 1065000, Elapsed Time: 03:46:55, Estimated Time Remaining: 04:18:27\n",
      "Mean Reward (last 1000 steps): -0.07116\n",
      "Timesteps: 936000/2000000, Remaining Timesteps: 1064000, Elapsed Time: 03:47:12, Estimated Time Remaining: 04:18:16\n",
      "Mean Reward (last 1000 steps): -0.04551\n",
      "Timesteps: 937000/2000000, Remaining Timesteps: 1063000, Elapsed Time: 03:47:26, Estimated Time Remaining: 04:18:01\n",
      "Mean Reward (last 1000 steps): -0.07792\n",
      "Timesteps: 938000/2000000, Remaining Timesteps: 1062000, Elapsed Time: 03:47:44, Estimated Time Remaining: 04:17:50\n",
      "Mean Reward (last 1000 steps): -0.08116\n",
      "Timesteps: 939000/2000000, Remaining Timesteps: 1061000, Elapsed Time: 03:47:58, Estimated Time Remaining: 04:17:35\n",
      "Mean Reward (last 1000 steps): -0.03403\n",
      "Timesteps: 940000/2000000, Remaining Timesteps: 1060000, Elapsed Time: 03:48:11, Estimated Time Remaining: 04:17:19\n",
      "Mean Reward (last 1000 steps): -0.03016\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 941000/2000000, Remaining Timesteps: 1059000, Elapsed Time: 03:48:29, Estimated Time Remaining: 04:17:08\n",
      "Mean Reward (last 1000 steps): -0.07826\n",
      "Timesteps: 942000/2000000, Remaining Timesteps: 1058000, Elapsed Time: 03:48:43, Estimated Time Remaining: 04:16:52\n",
      "Mean Reward (last 1000 steps): -0.01504\n",
      "Timesteps: 943000/2000000, Remaining Timesteps: 1057000, Elapsed Time: 03:49:01, Estimated Time Remaining: 04:16:42\n",
      "Mean Reward (last 1000 steps): -0.03299\n",
      "Timesteps: 944000/2000000, Remaining Timesteps: 1056000, Elapsed Time: 03:49:14, Estimated Time Remaining: 04:16:26\n",
      "Mean Reward (last 1000 steps): -0.07681\n",
      "Timesteps: 945000/2000000, Remaining Timesteps: 1055000, Elapsed Time: 03:49:32, Estimated Time Remaining: 04:16:16\n",
      "Mean Reward (last 1000 steps): -0.07546\n",
      "Timesteps: 946000/2000000, Remaining Timesteps: 1054000, Elapsed Time: 03:49:46, Estimated Time Remaining: 04:16:00\n",
      "Mean Reward (last 1000 steps): -0.03930\n",
      "Timesteps: 947000/2000000, Remaining Timesteps: 1053000, Elapsed Time: 03:50:04, Estimated Time Remaining: 04:15:49\n",
      "Mean Reward (last 1000 steps): -0.07248\n",
      "Timesteps: 948000/2000000, Remaining Timesteps: 1052000, Elapsed Time: 03:50:17, Estimated Time Remaining: 04:15:33\n",
      "Mean Reward (last 1000 steps): -0.08941\n",
      "Timesteps: 949000/2000000, Remaining Timesteps: 1051000, Elapsed Time: 03:50:34, Estimated Time Remaining: 04:15:21\n",
      "Mean Reward (last 1000 steps): -0.01864\n",
      "Timesteps: 950000/2000000, Remaining Timesteps: 1050000, Elapsed Time: 03:50:47, Estimated Time Remaining: 04:15:05\n",
      "Mean Reward (last 1000 steps): -0.04579\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 951000/2000000, Remaining Timesteps: 1049000, Elapsed Time: 03:51:05, Estimated Time Remaining: 04:14:54\n",
      "Mean Reward (last 1000 steps): -0.06019\n",
      "Timesteps: 952000/2000000, Remaining Timesteps: 1048000, Elapsed Time: 03:51:18, Estimated Time Remaining: 04:14:37\n",
      "Mean Reward (last 1000 steps): -0.01323\n",
      "Timesteps: 953000/2000000, Remaining Timesteps: 1047000, Elapsed Time: 03:51:35, Estimated Time Remaining: 04:14:25\n",
      "Mean Reward (last 1000 steps): -0.04842\n",
      "Timesteps: 954000/2000000, Remaining Timesteps: 1046000, Elapsed Time: 03:51:48, Estimated Time Remaining: 04:14:09\n",
      "Mean Reward (last 1000 steps): -0.08513\n",
      "Timesteps: 955000/2000000, Remaining Timesteps: 1045000, Elapsed Time: 03:52:05, Estimated Time Remaining: 04:13:57\n",
      "Mean Reward (last 1000 steps): -0.04494\n",
      "Timesteps: 956000/2000000, Remaining Timesteps: 1044000, Elapsed Time: 03:52:18, Estimated Time Remaining: 04:13:41\n",
      "Mean Reward (last 1000 steps): -0.05365\n",
      "Timesteps: 957000/2000000, Remaining Timesteps: 1043000, Elapsed Time: 03:52:36, Estimated Time Remaining: 04:13:30\n",
      "Mean Reward (last 1000 steps): -0.03822\n",
      "Timesteps: 958000/2000000, Remaining Timesteps: 1042000, Elapsed Time: 03:52:49, Estimated Time Remaining: 04:13:14\n",
      "Mean Reward (last 1000 steps): -0.06746\n",
      "Timesteps: 959000/2000000, Remaining Timesteps: 1041000, Elapsed Time: 03:53:07, Estimated Time Remaining: 04:13:03\n",
      "Mean Reward (last 1000 steps): -0.07482\n",
      "Timesteps: 960000/2000000, Remaining Timesteps: 1040000, Elapsed Time: 03:53:20, Estimated Time Remaining: 04:12:47\n",
      "Mean Reward (last 1000 steps): -0.03654\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 961000/2000000, Remaining Timesteps: 1039000, Elapsed Time: 03:53:38, Estimated Time Remaining: 04:12:36\n",
      "Mean Reward (last 1000 steps): -0.05707\n",
      "Timesteps: 962000/2000000, Remaining Timesteps: 1038000, Elapsed Time: 03:53:51, Estimated Time Remaining: 04:12:19\n",
      "Mean Reward (last 1000 steps): -0.04037\n",
      "Timesteps: 963000/2000000, Remaining Timesteps: 1037000, Elapsed Time: 03:54:08, Estimated Time Remaining: 04:12:08\n",
      "Mean Reward (last 1000 steps): -0.04822\n",
      "Timesteps: 964000/2000000, Remaining Timesteps: 1036000, Elapsed Time: 03:54:22, Estimated Time Remaining: 04:11:52\n",
      "Mean Reward (last 1000 steps): -0.04891\n",
      "Timesteps: 965000/2000000, Remaining Timesteps: 1035000, Elapsed Time: 03:54:39, Estimated Time Remaining: 04:11:41\n",
      "Mean Reward (last 1000 steps): -0.02808\n",
      "Timesteps: 966000/2000000, Remaining Timesteps: 1034000, Elapsed Time: 03:54:53, Estimated Time Remaining: 04:11:25\n",
      "Mean Reward (last 1000 steps): -0.07509\n",
      "Timesteps: 967000/2000000, Remaining Timesteps: 1033000, Elapsed Time: 03:55:10, Estimated Time Remaining: 04:11:13\n",
      "Mean Reward (last 1000 steps): -0.04743\n",
      "Timesteps: 968000/2000000, Remaining Timesteps: 1032000, Elapsed Time: 03:55:24, Estimated Time Remaining: 04:10:57\n",
      "Mean Reward (last 1000 steps): -0.08617\n",
      "Timesteps: 969000/2000000, Remaining Timesteps: 1031000, Elapsed Time: 03:55:41, Estimated Time Remaining: 04:10:46\n",
      "Mean Reward (last 1000 steps): -0.06069\n",
      "Timesteps: 970000/2000000, Remaining Timesteps: 1030000, Elapsed Time: 03:55:55, Estimated Time Remaining: 04:10:30\n",
      "Mean Reward (last 1000 steps): -0.07132\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 971000/2000000, Remaining Timesteps: 1029000, Elapsed Time: 03:56:12, Estimated Time Remaining: 04:10:18\n",
      "Mean Reward (last 1000 steps): -0.09257\n",
      "Timesteps: 972000/2000000, Remaining Timesteps: 1028000, Elapsed Time: 03:56:25, Estimated Time Remaining: 04:10:02\n",
      "Mean Reward (last 1000 steps): -0.04218\n",
      "Timesteps: 973000/2000000, Remaining Timesteps: 1027000, Elapsed Time: 03:56:42, Estimated Time Remaining: 04:09:51\n",
      "Mean Reward (last 1000 steps): -0.06154\n",
      "Timesteps: 974000/2000000, Remaining Timesteps: 1026000, Elapsed Time: 03:56:55, Estimated Time Remaining: 04:09:34\n",
      "Mean Reward (last 1000 steps): -0.09355\n",
      "Timesteps: 975000/2000000, Remaining Timesteps: 1025000, Elapsed Time: 03:57:13, Estimated Time Remaining: 04:09:23\n",
      "Mean Reward (last 1000 steps): -0.09342\n",
      "Timesteps: 976000/2000000, Remaining Timesteps: 1024000, Elapsed Time: 03:57:27, Estimated Time Remaining: 04:09:08\n",
      "Mean Reward (last 1000 steps): -0.07491\n",
      "Timesteps: 977000/2000000, Remaining Timesteps: 1023000, Elapsed Time: 03:57:44, Estimated Time Remaining: 04:08:56\n",
      "Mean Reward (last 1000 steps): -0.06418\n",
      "Timesteps: 978000/2000000, Remaining Timesteps: 1022000, Elapsed Time: 03:57:58, Estimated Time Remaining: 04:08:40\n",
      "Mean Reward (last 1000 steps): -0.09288\n",
      "Timesteps: 979000/2000000, Remaining Timesteps: 1021000, Elapsed Time: 03:58:15, Estimated Time Remaining: 04:08:28\n",
      "Mean Reward (last 1000 steps): -0.08131\n",
      "Timesteps: 980000/2000000, Remaining Timesteps: 1020000, Elapsed Time: 03:58:29, Estimated Time Remaining: 04:08:13\n",
      "Mean Reward (last 1000 steps): -0.05060\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 981000/2000000, Remaining Timesteps: 1019000, Elapsed Time: 03:58:46, Estimated Time Remaining: 04:08:01\n",
      "Mean Reward (last 1000 steps): -0.04663\n",
      "Timesteps: 982000/2000000, Remaining Timesteps: 1018000, Elapsed Time: 03:58:59, Estimated Time Remaining: 04:07:45\n",
      "Mean Reward (last 1000 steps): -0.05155\n",
      "Timesteps: 983000/2000000, Remaining Timesteps: 1017000, Elapsed Time: 03:59:12, Estimated Time Remaining: 04:07:29\n",
      "Mean Reward (last 1000 steps): -0.04757\n",
      "Timesteps: 984000/2000000, Remaining Timesteps: 1016000, Elapsed Time: 03:59:30, Estimated Time Remaining: 04:07:17\n",
      "Mean Reward (last 1000 steps): -0.05690\n",
      "Timesteps: 985000/2000000, Remaining Timesteps: 1015000, Elapsed Time: 03:59:44, Estimated Time Remaining: 04:07:02\n",
      "Mean Reward (last 1000 steps): -0.07586\n",
      "Timesteps: 986000/2000000, Remaining Timesteps: 1014000, Elapsed Time: 04:00:01, Estimated Time Remaining: 04:06:50\n",
      "Mean Reward (last 1000 steps): -0.03933\n",
      "Timesteps: 987000/2000000, Remaining Timesteps: 1013000, Elapsed Time: 04:00:14, Estimated Time Remaining: 04:06:34\n",
      "Mean Reward (last 1000 steps): -0.04461\n",
      "Timesteps: 988000/2000000, Remaining Timesteps: 1012000, Elapsed Time: 04:00:32, Estimated Time Remaining: 04:06:22\n",
      "Mean Reward (last 1000 steps): -0.07451\n",
      "Timesteps: 989000/2000000, Remaining Timesteps: 1011000, Elapsed Time: 04:00:45, Estimated Time Remaining: 04:06:06\n",
      "Mean Reward (last 1000 steps): -0.07999\n",
      "Timesteps: 990000/2000000, Remaining Timesteps: 1010000, Elapsed Time: 04:01:02, Estimated Time Remaining: 04:05:55\n",
      "Mean Reward (last 1000 steps): -0.05692\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 991000/2000000, Remaining Timesteps: 1009000, Elapsed Time: 04:01:16, Estimated Time Remaining: 04:05:39\n",
      "Mean Reward (last 1000 steps): -0.05294\n",
      "Timesteps: 992000/2000000, Remaining Timesteps: 1008000, Elapsed Time: 04:01:33, Estimated Time Remaining: 04:05:27\n",
      "Mean Reward (last 1000 steps): -0.04564\n",
      "Timesteps: 993000/2000000, Remaining Timesteps: 1007000, Elapsed Time: 04:01:46, Estimated Time Remaining: 04:05:10\n",
      "Mean Reward (last 1000 steps): -0.06559\n",
      "Timesteps: 994000/2000000, Remaining Timesteps: 1006000, Elapsed Time: 04:02:03, Estimated Time Remaining: 04:04:59\n",
      "Mean Reward (last 1000 steps): -0.07590\n",
      "Timesteps: 995000/2000000, Remaining Timesteps: 1005000, Elapsed Time: 04:02:17, Estimated Time Remaining: 04:04:43\n",
      "Mean Reward (last 1000 steps): -0.04258\n",
      "Timesteps: 996000/2000000, Remaining Timesteps: 1004000, Elapsed Time: 04:02:35, Estimated Time Remaining: 04:04:32\n",
      "Mean Reward (last 1000 steps): -0.06035\n",
      "Timesteps: 997000/2000000, Remaining Timesteps: 1003000, Elapsed Time: 04:02:48, Estimated Time Remaining: 04:04:15\n",
      "Mean Reward (last 1000 steps): -0.02729\n",
      "Timesteps: 998000/2000000, Remaining Timesteps: 1002000, Elapsed Time: 04:03:06, Estimated Time Remaining: 04:04:04\n",
      "Mean Reward (last 1000 steps): -0.05588\n",
      "Timesteps: 999000/2000000, Remaining Timesteps: 1001000, Elapsed Time: 04:03:23, Estimated Time Remaining: 04:03:53\n",
      "Mean Reward (last 1000 steps): -0.06717\n",
      "Timesteps: 1000000/2000000, Remaining Timesteps: 1000000, Elapsed Time: 04:03:49, Estimated Time Remaining: 04:03:49\n",
      "Mean Reward (last 1000 steps): -0.07720\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 1001000/2000000, Remaining Timesteps: 999000, Elapsed Time: 04:04:03, Estimated Time Remaining: 04:03:34\n",
      "Mean Reward (last 1000 steps): -0.05135\n",
      "Timesteps: 1002000/2000000, Remaining Timesteps: 998000, Elapsed Time: 04:04:21, Estimated Time Remaining: 04:03:22\n",
      "Mean Reward (last 1000 steps): -0.07857\n",
      "Timesteps: 1003000/2000000, Remaining Timesteps: 997000, Elapsed Time: 04:04:33, Estimated Time Remaining: 04:03:06\n",
      "Mean Reward (last 1000 steps): -0.05614\n",
      "Timesteps: 1004000/2000000, Remaining Timesteps: 996000, Elapsed Time: 04:04:51, Estimated Time Remaining: 04:02:53\n",
      "Mean Reward (last 1000 steps): -0.03281\n",
      "Timesteps: 1005000/2000000, Remaining Timesteps: 995000, Elapsed Time: 04:05:03, Estimated Time Remaining: 04:02:37\n",
      "Mean Reward (last 1000 steps): -0.03219\n",
      "Timesteps: 1006000/2000000, Remaining Timesteps: 994000, Elapsed Time: 04:05:20, Estimated Time Remaining: 04:02:24\n",
      "Mean Reward (last 1000 steps): -0.05440\n",
      "Timesteps: 1007000/2000000, Remaining Timesteps: 993000, Elapsed Time: 04:05:33, Estimated Time Remaining: 04:02:08\n",
      "Mean Reward (last 1000 steps): -0.03424\n",
      "Timesteps: 1008000/2000000, Remaining Timesteps: 992000, Elapsed Time: 04:05:48, Estimated Time Remaining: 04:01:54\n",
      "Mean Reward (last 1000 steps): -0.04552\n",
      "Timesteps: 1009000/2000000, Remaining Timesteps: 991000, Elapsed Time: 04:06:01, Estimated Time Remaining: 04:01:38\n",
      "Mean Reward (last 1000 steps): -0.04330\n",
      "Timesteps: 1010000/2000000, Remaining Timesteps: 990000, Elapsed Time: 04:06:18, Estimated Time Remaining: 04:01:25\n",
      "Mean Reward (last 1000 steps): -0.06528\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 1011000/2000000, Remaining Timesteps: 989000, Elapsed Time: 04:06:30, Estimated Time Remaining: 04:01:08\n",
      "Mean Reward (last 1000 steps): -0.07550\n",
      "Timesteps: 1012000/2000000, Remaining Timesteps: 988000, Elapsed Time: 04:06:47, Estimated Time Remaining: 04:00:56\n",
      "Mean Reward (last 1000 steps): -0.09288\n",
      "Timesteps: 1013000/2000000, Remaining Timesteps: 987000, Elapsed Time: 04:06:59, Estimated Time Remaining: 04:00:39\n",
      "Mean Reward (last 1000 steps): -0.08377\n",
      "Timesteps: 1014000/2000000, Remaining Timesteps: 986000, Elapsed Time: 04:07:15, Estimated Time Remaining: 04:00:25\n",
      "Mean Reward (last 1000 steps): -0.04935\n",
      "Timesteps: 1015000/2000000, Remaining Timesteps: 985000, Elapsed Time: 04:07:27, Estimated Time Remaining: 04:00:08\n",
      "Mean Reward (last 1000 steps): -0.05985\n",
      "Timesteps: 1016000/2000000, Remaining Timesteps: 984000, Elapsed Time: 04:07:44, Estimated Time Remaining: 03:59:55\n",
      "Mean Reward (last 1000 steps): -0.06699\n",
      "Timesteps: 1017000/2000000, Remaining Timesteps: 983000, Elapsed Time: 04:07:57, Estimated Time Remaining: 03:59:39\n",
      "Mean Reward (last 1000 steps): -0.06607\n",
      "Timesteps: 1018000/2000000, Remaining Timesteps: 982000, Elapsed Time: 04:08:12, Estimated Time Remaining: 03:59:25\n",
      "Mean Reward (last 1000 steps): -0.09242\n",
      "Timesteps: 1019000/2000000, Remaining Timesteps: 981000, Elapsed Time: 04:08:24, Estimated Time Remaining: 03:59:08\n",
      "Mean Reward (last 1000 steps): -0.09317\n",
      "Timesteps: 1020000/2000000, Remaining Timesteps: 980000, Elapsed Time: 04:08:42, Estimated Time Remaining: 03:58:56\n",
      "Mean Reward (last 1000 steps): -0.09344\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 1021000/2000000, Remaining Timesteps: 979000, Elapsed Time: 04:08:54, Estimated Time Remaining: 03:58:39\n",
      "Mean Reward (last 1000 steps): -0.06713\n",
      "Timesteps: 1022000/2000000, Remaining Timesteps: 978000, Elapsed Time: 04:09:11, Estimated Time Remaining: 03:58:27\n",
      "Mean Reward (last 1000 steps): -0.06814\n",
      "Timesteps: 1023000/2000000, Remaining Timesteps: 977000, Elapsed Time: 04:09:22, Estimated Time Remaining: 03:58:10\n",
      "Mean Reward (last 1000 steps): -0.07368\n",
      "Timesteps: 1024000/2000000, Remaining Timesteps: 976000, Elapsed Time: 04:09:34, Estimated Time Remaining: 03:57:52\n",
      "Mean Reward (last 1000 steps): -0.05207\n",
      "Timesteps: 1025000/2000000, Remaining Timesteps: 975000, Elapsed Time: 04:09:50, Estimated Time Remaining: 03:57:39\n",
      "Mean Reward (last 1000 steps): -0.05810\n",
      "Timesteps: 1026000/2000000, Remaining Timesteps: 974000, Elapsed Time: 04:10:01, Estimated Time Remaining: 03:57:21\n",
      "Mean Reward (last 1000 steps): -0.03643\n",
      "Timesteps: 1027000/2000000, Remaining Timesteps: 973000, Elapsed Time: 04:10:18, Estimated Time Remaining: 03:57:08\n",
      "Mean Reward (last 1000 steps): -0.05720\n",
      "Timesteps: 1028000/2000000, Remaining Timesteps: 972000, Elapsed Time: 04:10:29, Estimated Time Remaining: 03:56:50\n",
      "Mean Reward (last 1000 steps): -0.01928\n",
      "Timesteps: 1029000/2000000, Remaining Timesteps: 971000, Elapsed Time: 04:10:45, Estimated Time Remaining: 03:56:37\n",
      "Mean Reward (last 1000 steps): -0.07951\n",
      "Timesteps: 1030000/2000000, Remaining Timesteps: 970000, Elapsed Time: 04:10:57, Estimated Time Remaining: 03:56:20\n",
      "Mean Reward (last 1000 steps): -0.09262\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 1031000/2000000, Remaining Timesteps: 969000, Elapsed Time: 04:11:12, Estimated Time Remaining: 03:56:06\n",
      "Mean Reward (last 1000 steps): -0.05162\n",
      "Timesteps: 1032000/2000000, Remaining Timesteps: 968000, Elapsed Time: 04:11:24, Estimated Time Remaining: 03:55:48\n",
      "Mean Reward (last 1000 steps): -0.09396\n",
      "Timesteps: 1033000/2000000, Remaining Timesteps: 967000, Elapsed Time: 04:11:40, Estimated Time Remaining: 03:55:36\n",
      "Mean Reward (last 1000 steps): -0.06400\n",
      "Timesteps: 1034000/2000000, Remaining Timesteps: 966000, Elapsed Time: 04:11:52, Estimated Time Remaining: 03:55:18\n",
      "Mean Reward (last 1000 steps): -0.08093\n",
      "Timesteps: 1035000/2000000, Remaining Timesteps: 965000, Elapsed Time: 04:12:07, Estimated Time Remaining: 03:55:04\n",
      "Mean Reward (last 1000 steps): -0.09401\n",
      "Timesteps: 1036000/2000000, Remaining Timesteps: 964000, Elapsed Time: 04:12:19, Estimated Time Remaining: 03:54:47\n",
      "Mean Reward (last 1000 steps): -0.07324\n",
      "Timesteps: 1037000/2000000, Remaining Timesteps: 963000, Elapsed Time: 04:12:35, Estimated Time Remaining: 03:54:34\n",
      "Mean Reward (last 1000 steps): -0.05123\n",
      "Timesteps: 1038000/2000000, Remaining Timesteps: 962000, Elapsed Time: 04:12:47, Estimated Time Remaining: 03:54:16\n",
      "Mean Reward (last 1000 steps): -0.04025\n",
      "Timesteps: 1039000/2000000, Remaining Timesteps: 961000, Elapsed Time: 04:13:03, Estimated Time Remaining: 03:54:04\n",
      "Mean Reward (last 1000 steps): -0.07161\n",
      "Timesteps: 1040000/2000000, Remaining Timesteps: 960000, Elapsed Time: 04:13:16, Estimated Time Remaining: 03:53:47\n",
      "Mean Reward (last 1000 steps): -0.09308\n",
      "Model saved to TRAIN_PPO_RL_2M (overwritten)\n",
      "Timesteps: 1041000/2000000, Remaining Timesteps: 959000, Elapsed Time: 04:13:33, Estimated Time Remaining: 03:53:35\n",
      "Mean Reward (last 1000 steps): -0.09308\n",
      "Timesteps: 1042000/2000000, Remaining Timesteps: 958000, Elapsed Time: 04:13:46, Estimated Time Remaining: 03:53:18\n",
      "Mean Reward (last 1000 steps): -0.06552\n",
      "Timesteps: 1043000/2000000, Remaining Timesteps: 957000, Elapsed Time: 04:14:02, Estimated Time Remaining: 03:53:05\n",
      "Mean Reward (last 1000 steps): -0.05383\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13984\\2266790594.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[0mprogress_callback\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mProgressCallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtotal_timesteps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mNUM_OF_STEPS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"TRAIN_PPO_RL_\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mVERSION\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m \u001B[0mPPOmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlearn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtotal_timesteps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mNUM_OF_STEPS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlog_interval\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mLOG_INTERVAL\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprogress_callback\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m \u001B[0mPPOmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mMODEL_SAVE_NAME\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py\u001B[0m in \u001B[0;36mlearn\u001B[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001B[0m\n\u001B[0;32m    306\u001B[0m             \u001B[0mtb_log_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtb_log_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    307\u001B[0m             \u001B[0meval_log_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0meval_log_path\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 308\u001B[1;33m             \u001B[0mreset_num_timesteps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mreset_num_timesteps\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    309\u001B[0m         )\n",
      "\u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001B[0m in \u001B[0;36mlearn\u001B[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001B[0m\n\u001B[0;32m    248\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_timesteps\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mtotal_timesteps\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 250\u001B[1;33m             \u001B[0mcontinue_training\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcollect_rollouts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrollout_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_rollout_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_steps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    251\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    252\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mcontinue_training\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001B[0m in \u001B[0;36mcollect_rollouts\u001B[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001B[0m\n\u001B[0;32m    205\u001B[0m                     \u001B[0mrewards\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgamma\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mterminal_value\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 207\u001B[1;33m             \u001B[0mrollout_buffer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_last_obs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrewards\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_last_episode_starts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlog_probs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    208\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_last_obs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnew_obs\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    209\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_last_episode_starts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdones\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\buffers.py\u001B[0m in \u001B[0;36madd\u001B[1;34m(self, obs, action, reward, episode_start, value, log_prob)\u001B[0m\n\u001B[0;32m    430\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrewards\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpos\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreward\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    431\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mepisode_starts\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpos\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepisode_start\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 432\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpos\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    433\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlog_probs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpos\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlog_prob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    434\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpos\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:07:23.333029Z",
     "start_time": "2024-11-18T22:07:23.320815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_version(model, env, version_name, video_path):\n",
    "    MODEL_SAVE_NAME = version_name\n",
    "\n",
    "    try:\n",
    "        loaded_model = model.load(MODEL_SAVE_NAME)\n",
    "        print(f\"Model {MODEL_SAVE_NAME} loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    env = MonitorCustom(env)\n",
    "    obs = env.reset()\n",
    "    print(\"Observation shape: \", obs.shape)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        obs = np.copy(obs)\n",
    "\n",
    "        action, _states = loaded_model.predict(obs, deterministic=True)\n",
    "\n",
    "        obs, reward, done, info = env.step(action)\n",
    "\n",
    "    env.close()"
   ],
   "id": "4a946fe337050581",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:09:23.916513Z",
     "start_time": "2024-11-18T22:09:02.797268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import DQN, PPO\n",
    "from merger import CarRacingDiscrete, MultiCarRacing\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.atari_wrappers import WarpFrame\n",
    "\n",
    "# env = CarRacingDiscrete()\n",
    "# evaluate_version(DQN, env, \"DQN_RL_54\", \"v28\", \"./video\")\n",
    "\n",
    "# env_str = \"MultiCarRacing-v0\"\n",
    "# env_kwargs_dict = {\"num_agents\": 1, \"verbose\": 0}\n",
    "\n",
    "# env_eval = make_vec_env(env_str, n_envs=1, env_kwargs=env_kwargs_dict, wrapper_class=WarpFrame)\n",
    "# env_eval = VecFrameStack(env_eval, n_stack=4)\n",
    "# env_eval = VecTransposeImage(env_eval)\n",
    "\n",
    "env = gym.make('MultiCarRacing-v0', num_agents=1, continuous_actions=[True],\n",
    "               use_ego_color=True)\n",
    "evaluate_version(PPO, env, \"PPO_RL_1M\", \"./video\")"
   ],
   "id": "5b7a35478f4c0438",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model PPO_RL_1M loaded successfully\n",
      "Track generation: 1124..1409 -> 285-tiles track\n",
      "Observation shape:  (96, 96, 3)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:43:34.969665Z",
     "start_time": "2024-11-18T19:24:10.465523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "\n",
    "model = PPO.load(\"PPO_RL_1M.zip\")\n",
    "\n",
    "env = gym.make('MultiCarRacing-v0', num_agents=1, continuous_actions=[True])\n",
    "\n",
    "num_episodes = 100\n",
    "\n",
    "episode_rewards = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "\n",
    "    while not done:\n",
    "        obs = np.copy(obs)\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_rewards += reward\n",
    "\n",
    "    episode_rewards.append(total_rewards)\n",
    "\n",
    "end_time = time.time()\n",
    "evaluation_time = end_time - start_time\n",
    "print(f\"Total evaluation time: {evaluation_time:.2f} seconds\")\n",
    "\n",
    "episode_rewards = np.array(episode_rewards)\n",
    "\n",
    "window_size = 10\n",
    "rewards_smoothed = pd.Series(episode_rewards).rolling(window=window_size).mean()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rewards_smoothed, label=f'Smoothed Rewards (window={window_size})')\n",
    "\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Rewards\")\n",
    "plt.title(f\"Performance on {env.spec.id}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "5ddd79323ee7b3a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "Track generation: 1187..1488 -> 301-tiles track\n",
      "Track generation: 1197..1501 -> 304-tiles track\n",
      "Track generation: 1200..1504 -> 304-tiles track\n",
      "Track generation: 1153..1445 -> 292-tiles track\n",
      "Track generation: 1040..1304 -> 264-tiles track\n",
      "Track generation: 1243..1558 -> 315-tiles track\n",
      "Track generation: 1255..1573 -> 318-tiles track\n",
      "Track generation: 1283..1613 -> 330-tiles track\n",
      "Track generation: 1079..1353 -> 274-tiles track\n",
      "Track generation: 1247..1563 -> 316-tiles track\n",
      "Track generation: 1160..1454 -> 294-tiles track\n",
      "Track generation: 1101..1387 -> 286-tiles track\n",
      "Track generation: 1207..1513 -> 306-tiles track\n",
      "Track generation: 1115..1406 -> 291-tiles track\n",
      "Track generation: 1259..1578 -> 319-tiles track\n",
      "Track generation: 1123..1408 -> 285-tiles track\n",
      "Track generation: 1085..1361 -> 276-tiles track\n",
      "Track generation: 1124..1409 -> 285-tiles track\n",
      "Track generation: 1098..1376 -> 278-tiles track\n",
      "Track generation: 1062..1337 -> 275-tiles track\n",
      "Track generation: 1119..1409 -> 290-tiles track\n",
      "Track generation: 1060..1329 -> 269-tiles track\n",
      "Track generation: 914..1148 -> 234-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1345..1685 -> 340-tiles track\n",
      "Track generation: 1044..1316 -> 272-tiles track\n",
      "Track generation: 995..1248 -> 253-tiles track\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "Track generation: 1294..1620 -> 326-tiles track\n",
      "Track generation: 1004..1263 -> 259-tiles track\n",
      "Track generation: 1060..1329 -> 269-tiles track\n",
      "Track generation: 1160..1454 -> 294-tiles track\n",
      "Track generation: 1268..1591 -> 323-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1017..1275 -> 258-tiles track\n",
      "Track generation: 1243..1558 -> 315-tiles track\n",
      "Track generation: 1072..1344 -> 272-tiles track\n",
      "Track generation: 991..1248 -> 257-tiles track\n",
      "Track generation: 1124..1409 -> 285-tiles track\n",
      "Track generation: 1096..1374 -> 278-tiles track\n",
      "Track generation: 1016..1279 -> 263-tiles track\n",
      "Track generation: 1090..1376 -> 286-tiles track\n",
      "Track generation: 1135..1431 -> 296-tiles track\n",
      "Track generation: 1073..1345 -> 272-tiles track\n",
      "Track generation: 1055..1327 -> 272-tiles track\n",
      "Track generation: 1068..1343 -> 275-tiles track\n",
      "Track generation: 1109..1390 -> 281-tiles track\n",
      "Track generation: 1287..1613 -> 326-tiles track\n",
      "Track generation: 1117..1400 -> 283-tiles track\n",
      "Track generation: 1010..1272 -> 262-tiles track\n",
      "Track generation: 1108..1389 -> 281-tiles track\n",
      "Track generation: 1223..1533 -> 310-tiles track\n",
      "Track generation: 1347..1695 -> 348-tiles track\n",
      "Track generation: 1140..1429 -> 289-tiles track\n",
      "Track generation: 1095..1377 -> 282-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1052..1319 -> 267-tiles track\n",
      "Track generation: 1078..1355 -> 277-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1055..1328 -> 273-tiles track\n",
      "Track generation: 969..1223 -> 254-tiles track\n",
      "Track generation: 972..1225 -> 253-tiles track\n",
      "Track generation: 1247..1563 -> 316-tiles track\n",
      "Track generation: 1228..1538 -> 310-tiles track\n",
      "Track generation: 1123..1408 -> 285-tiles track\n",
      "Track generation: 1215..1523 -> 308-tiles track\n",
      "Track generation: 1180..1479 -> 299-tiles track\n",
      "Track generation: 1368..1714 -> 346-tiles track\n",
      "Track generation: 1366..1711 -> 345-tiles track\n",
      "Track generation: 1112..1394 -> 282-tiles track\n",
      "Track generation: 1185..1485 -> 300-tiles track\n",
      "Track generation: 1149..1444 -> 295-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1089..1365 -> 276-tiles track\n",
      "Track generation: 1187..1488 -> 301-tiles track\n",
      "Track generation: 1215..1523 -> 308-tiles track\n",
      "Track generation: 1099..1378 -> 279-tiles track\n",
      "Track generation: 1240..1554 -> 314-tiles track\n",
      "Track generation: 1072..1344 -> 272-tiles track\n",
      "Track generation: 1072..1349 -> 277-tiles track\n",
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "Track generation: 1180..1479 -> 299-tiles track\n",
      "Track generation: 1217..1525 -> 308-tiles track\n",
      "Track generation: 1155..1448 -> 293-tiles track\n",
      "Track generation: 1375..1723 -> 348-tiles track\n",
      "Track generation: 1204..1509 -> 305-tiles track\n",
      "Track generation: 1087..1364 -> 277-tiles track\n",
      "Track generation: 1064..1334 -> 270-tiles track\n",
      "Track generation: 1075..1348 -> 273-tiles track\n",
      "Track generation: 970..1222 -> 252-tiles track\n",
      "Track generation: 1121..1411 -> 290-tiles track\n",
      "Track generation: 1040..1310 -> 270-tiles track\n",
      "Track generation: 1121..1405 -> 284-tiles track\n",
      "Track generation: 1019..1283 -> 264-tiles track\n",
      "Track generation: 1200..1510 -> 310-tiles track\n",
      "Track generation: 1091..1368 -> 277-tiles track\n",
      "Track generation: 1102..1382 -> 280-tiles track\n",
      "Track generation: 1248..1564 -> 316-tiles track\n",
      "Track generation: 1309..1640 -> 331-tiles track\n",
      "Track generation: 1187..1493 -> 306-tiles track\n",
      "Track generation: 1131..1427 -> 296-tiles track\n",
      "Track generation: 1263..1583 -> 320-tiles track\n",
      "Track generation: 1070..1345 -> 275-tiles track\n",
      "Track generation: 1097..1382 -> 285-tiles track\n",
      "Track generation: 1111..1396 -> 285-tiles track\n",
      "retry to generate track (normal if there are not many of this messages)\n",
      "Track generation: 1136..1424 -> 288-tiles track\n",
      "Track generation: 1210..1517 -> 307-tiles track\n",
      "Track generation: 1055..1323 -> 268-tiles track\n",
      "Track generation: 1272..1594 -> 322-tiles track\n",
      "Track generation: 1038..1306 -> 268-tiles track\n",
      "Track generation: 1184..1484 -> 300-tiles track\n",
      "Total evaluation time: 1164.07 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e2014ab004bc00aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
