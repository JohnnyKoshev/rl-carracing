{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-10T12:00:00.965462Z",
     "start_time": "2024-11-10T12:00:00.891676Z"
    }
   },
   "source": [
    "import gymnasium\n",
    "import stable_baselines3\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecVideoRecorder\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import VecTransposeImage\n",
    "from stable_baselines3.common.atari_wrappers import WarpFrame\n",
    "\n",
    "import os\n",
    "import numpy\n",
    "import platform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import torch\n",
    "from importlib.metadata import version"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:00:01.056809Z",
     "start_time": "2024-11-10T12:00:00.998918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "print(f\"Torch Version: {version('torch')}\")\n",
    "print(f\"Is Cuda Available: {torch.cuda.is_available()}\")\n",
    "print(f\"Cuda Version: {torch.version.cuda}\")\n",
    "print(f\"Gymnasium Version: {version('gymnasium')}\")\n",
    "print(f\"Numpy Version: {version('numpy')}\")\n",
    "print(f\"Scipy Version: {version('scipy')}\")\n",
    "print(f\"Swig Version: {version('swig')}\")\n",
    "print(f\"Stable Baselines3 Version: {version('stable_baselines3')}\")\n",
    "print(f\"IPython Version: {version('ipython')}\")"
   ],
   "id": "8ebddc20bbf66f8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.9.0\n",
      "Torch Version: 2.5.1\n",
      "Is Cuda Available: False\n",
      "Cuda Version: None\n",
      "Gymnasium Version: 0.29.1\n",
      "Numpy Version: 2.0.2\n",
      "Scipy Version: 1.13.1\n",
      "Swig Version: 4.2.1.post0\n",
      "Stable Baselines3 Version: 2.3.2\n",
      "IPython Version: 8.18.1\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:00:01.350393Z",
     "start_time": "2024-11-10T12:00:01.327999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = gymnasium.make('CarRacing-v2')\n",
    "print(\"Observation Space Size: \", env.observation_space.shape)\n",
    "print(\"Action Space Size: \", env.action_space.shape)\n",
    "env.close()"
   ],
   "id": "cfe6a5f5fe2a69e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space Size:  (96, 96, 3)\n",
      "Action Space Size:  (3,)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:00:01.895370Z",
     "start_time": "2024-11-10T12:00:01.877591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env_str = \"CarRacing-v2\"\n",
    "log_dir = \"./logs/{}\".format(env_str)\n",
    "env_kwargs_dict = {\"continuous\": True}\n",
    "gray_scale = True\n",
    "\n",
    "# If gray_scale True, convert obs to gray scale 84 x 84 image\n",
    "wrapper_class = WarpFrame if gray_scale else None"
   ],
   "id": "51cc4da7553b05e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T12:04:44.683644Z",
     "start_time": "2024-11-10T12:04:42.438777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Training CarRacing environment\n",
    "env = make_vec_env(env_str,\n",
    "                   n_envs=1,\n",
    "                   env_kwargs=env_kwargs_dict,\n",
    "                   wrapper_class=wrapper_class)\n",
    "env = VecFrameStack(env, n_stack=1)\n",
    "env = VecTransposeImage(env)\n",
    "\n",
    "# Create Evaluation CarRacing environment\n",
    "env_val = make_vec_env(env_str,\n",
    "                       n_envs=1,\n",
    "                       env_kwargs=env_kwargs_dict,\n",
    "                       wrapper_class=wrapper_class)\n",
    "env_val = VecFrameStack(env_val, n_stack=1)\n",
    "env_val = VecTransposeImage(env_val)\n",
    "\n",
    "# Create Evaluation Callback\n",
    "eval_callback = EvalCallback(env_val,\n",
    "                             best_model_save_path=log_dir,\n",
    "                             log_path=log_dir,\n",
    "                             eval_freq=25_000,\n",
    "                             render=False,\n",
    "                             n_eval_episodes=20)\n",
    "\n",
    "# Initialize SAC model\n",
    "model = SAC('CnnPolicy',\n",
    "            env,\n",
    "            verbose=1,\n",
    "            buffer_size=1_000_000,  # SAC generally uses larger buffer sizes than DQN\n",
    "            learning_starts=10000,  # Number of steps before training starts\n",
    "            batch_size=256,  # A typical batch size for SAC\n",
    "            tau=0.005,  # Target smoothing coefficient\n",
    "            gamma=0.99,  # Discount factor\n",
    "            train_freq=1,\n",
    "            gradient_steps=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=300000,\n",
    "            progress_bar=True,\n",
    "            callback=eval_callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(os.path.join(log_dir, \"sac_car_racing\"))\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=20)\n",
    "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "env.close()\n",
    "env_val.close()"
   ],
   "id": "941dfd03409d765e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 14.13GB > 5.54GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "D:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">D:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "in method 'b2RevoluteJoint___SetMotorSpeed', argument 2 of type 'float32'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 38\u001B[0m\n\u001B[0;32m     26\u001B[0m model \u001B[38;5;241m=\u001B[39m SAC(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCnnPolicy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     27\u001B[0m             env,\n\u001B[0;32m     28\u001B[0m             verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     34\u001B[0m             train_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m     35\u001B[0m             gradient_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_callback\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Save the model\u001B[39;00m\n\u001B[0;32m     43\u001B[0m model\u001B[38;5;241m.\u001B[39msave(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(log_dir, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msac_car_racing\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\sac\\sac.py:307\u001B[0m, in \u001B[0;36mSAC.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    298\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28mself\u001B[39m: SelfSAC,\n\u001B[0;32m    300\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    305\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    306\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SelfSAC:\n\u001B[1;32m--> 307\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:328\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_freq, TrainFreq)  \u001B[38;5;66;03m# check done in _setup_learn()\u001B[39;00m\n\u001B[0;32m    327\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m<\u001B[39m total_timesteps:\n\u001B[1;32m--> 328\u001B[0m     rollout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m        \u001B[49m\u001B[43maction_noise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maction_noise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlearning_starts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_starts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreplay_buffer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplay_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m rollout\u001B[38;5;241m.\u001B[39mcontinue_training:\n\u001B[0;32m    339\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:560\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.collect_rollouts\u001B[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001B[0m\n\u001B[0;32m    557\u001B[0m actions, buffer_actions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample_action(learning_starts, action_noise, env\u001B[38;5;241m.\u001B[39mnum_envs)\n\u001B[0;32m    559\u001B[0m \u001B[38;5;66;03m# Rescale and perform action\u001B[39;00m\n\u001B[1;32m--> 560\u001B[0m new_obs, rewards, dones, infos \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    562\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mnum_envs\n\u001B[0;32m    563\u001B[0m num_collected_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001B[0m, in \u001B[0;36mVecEnv.step\u001B[1;34m(self, actions)\u001B[0m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;124;03mStep the environments with the given action\u001B[39;00m\n\u001B[0;32m    201\u001B[0m \n\u001B[0;32m    202\u001B[0m \u001B[38;5;124;03m:param actions: the action\u001B[39;00m\n\u001B[0;32m    203\u001B[0m \u001B[38;5;124;03m:return: observation, reward, done, information\u001B[39;00m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_async(actions)\n\u001B[1;32m--> 206\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_transpose.py:97\u001B[0m, in \u001B[0;36mVecTransposeImage.step_wait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep_wait\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m VecEnvStepReturn:\n\u001B[1;32m---> 97\u001B[0m     observations, rewards, dones, infos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvenv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;66;03m# Transpose the terminal observations\u001B[39;00m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx, done \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dones):\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_frame_stack.py:38\u001B[0m, in \u001B[0;36mVecFrameStack.step_wait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep_wait\u001B[39m(\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     32\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     36\u001B[0m     List[Dict[\u001B[38;5;28mstr\u001B[39m, Any]],\n\u001B[0;32m     37\u001B[0m ]:\n\u001B[1;32m---> 38\u001B[0m     observations, rewards, dones, infos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvenv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m     observations, infos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstacked_obs\u001B[38;5;241m.\u001B[39mupdate(observations, dones, infos)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m observations, rewards, dones, infos\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001B[0m, in \u001B[0;36mDummyVecEnv.step_wait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep_wait\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m VecEnvStepReturn:\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;66;03m# Avoid circular imports\u001B[39;00m\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m env_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_envs):\n\u001B[1;32m---> 58\u001B[0m         obs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_rews[env_idx], terminated, truncated, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_infos[env_idx] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menvs\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactions\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m         \u001B[38;5;66;03m# convert to SB3 VecEnv api\u001B[39;00m\n\u001B[0;32m     62\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_dones[env_idx] \u001B[38;5;241m=\u001B[39m terminated \u001B[38;5;129;01mor\u001B[39;00m truncated\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\gymnasium\\core.py:522\u001B[0m, in \u001B[0;36mObservationWrapper.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    518\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\n\u001B[0;32m    519\u001B[0m     \u001B[38;5;28mself\u001B[39m, action: ActType\n\u001B[0;32m    520\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[WrapperObsType, SupportsFloat, \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]]:\n\u001B[0;32m    521\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 522\u001B[0m     observation, reward, terminated, truncated, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    523\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobservation(observation), reward, terminated, truncated, info\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001B[0m, in \u001B[0;36mMonitor.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneeds_reset:\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTried to step environment that needs reset\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 94\u001B[0m observation, reward, terminated, truncated, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrewards\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mfloat\u001B[39m(reward))\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m terminated \u001B[38;5;129;01mor\u001B[39;00m truncated:\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001B[0m, in \u001B[0;36mTimeLimit.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[0;32m     47\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \n\u001B[0;32m     49\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     55\u001B[0m \n\u001B[0;32m     56\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 57\u001B[0m     observation, reward, terminated, truncated, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_episode_steps:\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001B[0m, in \u001B[0;36mOrderEnforcing.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_reset:\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ResetNeeded(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot call env.step() before calling env.reset()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:49\u001B[0m, in \u001B[0;36mPassiveEnvChecker.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchecked_step:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchecked_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43menv_step_passive_checker\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv\u001B[38;5;241m.\u001B[39mstep(action)\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:208\u001B[0m, in \u001B[0;36menv_step_passive_checker\u001B[1;34m(env, action)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[0;32m    210\u001B[0m     result, \u001B[38;5;28mtuple\u001B[39m\n\u001B[0;32m    211\u001B[0m ), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpects step result to be a tuple, actual type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(result)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(result) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m4\u001B[39m:\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:549\u001B[0m, in \u001B[0;36mCarRacing.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    546\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcar\u001B[38;5;241m.\u001B[39mgas(\u001B[38;5;241m0.2\u001B[39m \u001B[38;5;241m*\u001B[39m (action \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m))\n\u001B[0;32m    547\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcar\u001B[38;5;241m.\u001B[39mbrake(\u001B[38;5;241m0.8\u001B[39m \u001B[38;5;241m*\u001B[39m (action \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m--> 549\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mFPS\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    550\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworld\u001B[38;5;241m.\u001B[39mStep(\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m FPS, \u001B[38;5;241m6\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m30\u001B[39m)\n\u001B[0;32m    551\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mt \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m FPS\n",
      "File \u001B[1;32mD:\\Programming\\IUT\\rl-carracing\\.venv\\lib\\site-packages\\gymnasium\\envs\\box2d\\car_dynamics.py:177\u001B[0m, in \u001B[0;36mCar.step\u001B[1;34m(self, dt)\u001B[0m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28mdir\u001B[39m \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msign(w\u001B[38;5;241m.\u001B[39msteer \u001B[38;5;241m-\u001B[39m w\u001B[38;5;241m.\u001B[39mjoint\u001B[38;5;241m.\u001B[39mangle)\n\u001B[0;32m    176\u001B[0m val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mabs\u001B[39m(w\u001B[38;5;241m.\u001B[39msteer \u001B[38;5;241m-\u001B[39m w\u001B[38;5;241m.\u001B[39mjoint\u001B[38;5;241m.\u001B[39mangle)\n\u001B[1;32m--> 177\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoint\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmotorSpeed\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdir\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;241m50.0\u001B[39m \u001B[38;5;241m*\u001B[39m val, \u001B[38;5;241m3.0\u001B[39m)\n\u001B[0;32m    179\u001B[0m \u001B[38;5;66;03m# Position => friction_limit\u001B[39;00m\n\u001B[0;32m    180\u001B[0m grass \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: in method 'b2RevoluteJoint___SetMotorSpeed', argument 2 of type 'float32'"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env = make_vec_env(env_str,\n",
    "                   n_envs=1,\n",
    "                   seed=0,\n",
    "                   env_kwargs=env_kwargs_dict,\n",
    "                   wrapper_class=wrapper_class)\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "env = VecTransposeImage(env)\n",
    "\n",
    "# Load the best model\n",
    "best_model_path = os.path.join(log_dir, \"best_model.zip\")\n",
    "best_model = SAC.load(best_model_path, env=env)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(best_model, env, n_eval_episodes=20)\n",
    "print(f\"Best Model - Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# Record video of the best model playing CarRacing\n",
    "env = VecVideoRecorder(env, \"./videos/\",\n",
    "                       video_length=10000,\n",
    "                       record_video_trigger=lambda x: x == 0,\n",
    "                       name_prefix=\"best_model_car_racing_sac\")\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(10000):\n",
    "    action, _states = best_model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "    if dones:\n",
    "        break\n",
    "\n",
    "env.close()"
   ],
   "id": "abae6ab46ca88853"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the evaluations.npz file\n",
    "data = numpy.load(os.path.join(log_dir, \"evaluations.npz\"))\n",
    "\n",
    "# Extract the relevant data\n",
    "timesteps = data['timesteps']\n",
    "results = data['results']\n",
    "\n",
    "# Calculate the mean and standard deviation of the results\n",
    "mean_results = numpy.mean(results, axis=1)\n",
    "std_results = numpy.std(results, axis=1)\n",
    "\n",
    "# Plot the results\n",
    "matplotlib.pyplot.figure()\n",
    "matplotlib.pyplot.plot(timesteps, mean_results)\n",
    "matplotlib.pyplot.fill_between(timesteps,\n",
    "                               mean_results - std_results,\n",
    "                               mean_results + std_results,\n",
    "                               alpha=0.3)\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"Timesteps\")\n",
    "matplotlib.pyplot.ylabel(\"Mean Reward\")\n",
    "matplotlib.pyplot.title(f\"SAC Performance on {env_str}\")\n",
    "matplotlib.pyplot.show()"
   ],
   "id": "2f6d187bc0b26f88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
